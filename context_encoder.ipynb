{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "daf0c4b5",
   "metadata": {},
   "source": [
    "# Imports and Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b63fd00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re, time, pickle, collections, importlib, datetime, torch\n",
    "import pandas as pd, numpy as np, pickle\n",
    "from chardet import detect\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from collections import defaultdict, Counter\n",
    "from wordebd import WORDEBD\n",
    "from vocab import Vocab, Vectors\n",
    "from munch import Munch\n",
    "from cnnlstmseq import CNNLSTMseq\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8e3efa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_encoding_type(file):\n",
    "    with open(file, 'rb') as f:\n",
    "        rawdata = f.read(),\n",
    "    return detect(rawdata['encoding'])\n",
    "\n",
    "def detect_misspelling(source):\n",
    "    pass\n",
    "def replace_spelling(source):\n",
    "    return re.sub(\"Åf\", \"'\", source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b9072d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# referenced from DialogueGCN, mastodon code\n",
    "def preprocess_text(x):\n",
    "    for punct in '!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~\\'':\n",
    "        x = x.replace(punct, ' ')\n",
    "    x = ' '.join(x.split())\n",
    "    x = x.lower()\n",
    "\n",
    "    return x\n",
    "\n",
    "def load_pretrained_glove():\n",
    "    print(\"Loading GloVe...\")\n",
    "    glv_vector = {}\n",
    "    f = open('/embed/glove/glove.840B.300d.txt', encoding='utf-8')\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word, coefs = values[0], np.asarray(values[1:], dtype='float')\n",
    "        try:\n",
    "            glv_vector[word] = coefs\n",
    "\n",
    "        except ValueError:\n",
    "            continue\n",
    "    f.close()\n",
    "    start_time = time.time()\n",
    "    print(f\"Took {time.time() - start_time} seconds to load pretrained GloVe model.\")\n",
    "    return glv_vector\n",
    "\n",
    "\n",
    "def encode_labels(encoder, l):\n",
    "    return encoder[l]\n",
    "\n",
    "def load_data_from_npy(file_path):\n",
    "    try:\n",
    "        data = np.load(file_path, allow_pickle=True)\n",
    "        if isinstance(data, np.ndarray):\n",
    "            if data.ndim == 2:\n",
    "                return pd.DataFrame(data)\n",
    "            else:\n",
    "                raise ValueError(\"The loaded array is not two-dimensional.\")\n",
    "        else:\n",
    "            raise TypeError(\"The loaded object is not a NumPy array.\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File not found at {file_path}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error: An exception occurred - {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def _read_words(data, convmode=None):\n",
    "    '''    \n",
    "        Count the occurrences of all words\n",
    "        @param convmode: str, None for non conversational scope, 'naive' for classic or naive approach, 'conv' for conversation depth into account (one additional dim and nested values)\n",
    "        @param data: list of examples\n",
    "        @return words: list of words (with duplicates)\n",
    "    '''    \n",
    "    words = []\n",
    "    if convmode is None:\n",
    "        for example in data:\n",
    "            words += example.split()     \n",
    "    return words\n",
    "\n",
    "def _data_to_nparray(data, vocab, args):\n",
    "    '''\n",
    "        Convert the data into a dictionary of np arrays for speed.\n",
    "    '''\n",
    "    raw = np.array([e for e in data[\"Utterance\"]], dtype=object)\n",
    "    doc_label = np.array([x for x in data[\"Emotion\"]], dtype=np.int64)\n",
    "\n",
    "    # compute the max text length\n",
    "    text_len = np.array([len(e) for e in data[\"Utterance\"]])\n",
    "    max_text_len = max(text_len)\n",
    "    ids = np.array([e for e in data['Dialogue_ID']])\n",
    "    ids2 = np.array([e for e in data['Utterance_ID']])\n",
    "\n",
    "    # initialize the big numpy array by <pad>\n",
    "    text = vocab.stoi['<pad>'] * np.ones([len(data), max_text_len],\n",
    "                                     dtype=np.int64)\n",
    "\n",
    "    del_idx = []\n",
    "    # convert each token to its corresponding id\n",
    "    for i in range(len(X_train)):\n",
    "        text[i, :len(X_train['Utterance'][i])] = [vocab.stoi[x] if x in vocab.stoi else vocab.stoi['<unk>']\n",
    "                for x in X_train['Utterance'][i]]\n",
    "\n",
    "        # filter out document with only unk and pad\n",
    "        if np.max(text[i]) < 2:\n",
    "            del_idx.append(i)\n",
    "\n",
    "    vocab_size = vocab.vectors.size()[0]\n",
    "\n",
    "\n",
    "    ## Curation for padding (string instead of list of list)\n",
    "    raw = [ [\"<pad>\" if m == [\"<pad>\", \"<pad>\", \"<pad>\", \"<pad>\", \"<pad>\"] else m for m in c ] for c in raw ]\n",
    "\n",
    "    ids, ids2, text_len, text, doc_label, raw = _del_by_idx( [ids, ids2, text_len, text, doc_label, raw], del_idx, 0)\n",
    "    new_data = {\n",
    "        'ids': ids,\n",
    "        'ids2': ids2,\n",
    "        'text': text,\n",
    "        'text_len': text_len,\n",
    "        'label': doc_label,\n",
    "#         'raw': raw,\n",
    "        'vocab_size': vocab_size,\n",
    "    }\n",
    "\n",
    "    return new_data\n",
    "\n",
    "def _del_by_idx(array_list, idx, axis):\n",
    "\n",
    "    '''        \n",
    "        Delete the specified index for each array in the array_lists\",\n",
    "\n",
    "        @params: array_list: list of np arrays\n",
    "        @params: idx: list of int\n",
    "        @params: axis: int\n",
    "\n",
    "        @return: res: tuple of pruned np arrays\n",
    "    '''\n",
    "    if type(array_list) is not list:\n",
    "        array_list = [array_list]\n",
    "\n",
    "    # modified to perform operations in place\n",
    "    for i, array in enumerate(array_list):\n",
    "        array_list[i] = np.delete(array, idx, axis)\n",
    "\n",
    "    if len(array_list) == 1:\n",
    "        return array_list[0]\n",
    "    else:\n",
    "        return array_list\n",
    "\n",
    "def find_value_ranges(lst):\n",
    "    value_ranges = []\n",
    "    start_index = 0\n",
    "\n",
    "    for i in range(1, len(lst)):\n",
    "        if lst[i] != lst[i - 1]:\n",
    "            value_ranges.append((start_index, i - 1))\n",
    "            start_index = i\n",
    "\n",
    "    # Add the last range\n",
    "    value_ranges.append((start_index, len(lst) - 1))\n",
    "\n",
    "    return value_ranges\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94282feb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.git',\n",
       " '.gitignore',\n",
       " 'cnnlstmseq.py',\n",
       " 'context_encoder - with classifier.ipynb',\n",
       " 'context_encoder.ipynb',\n",
       " 'data',\n",
       " 'embed',\n",
       " 'emotionClassifier.ipynb',\n",
       " 'GAT.py',\n",
       " 'graph.html',\n",
       " 'lib',\n",
       " 'LICENSE',\n",
       " 'README.md',\n",
       " 'relationtype_encoder.ipynb',\n",
       " 'runs',\n",
       " 'utils',\n",
       " 'vocab.py',\n",
       " 'wordebd.py',\n",
       " '__pycache__']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9605dc2d",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c64abc06",
   "metadata": {},
   "source": [
    "## Initial data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d6411a1",
   "metadata": {},
   "source": [
    "Get X_train via the CSV file in data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7147d96d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Utterance</th>\n",
       "      <th>Speaker</th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Dialogue_ID</th>\n",
       "      <th>Utterance_ID</th>\n",
       "      <th>Old_Dialogue_ID</th>\n",
       "      <th>Old_Utterance_ID</th>\n",
       "      <th>Season</th>\n",
       "      <th>Episode</th>\n",
       "      <th>StartTime</th>\n",
       "      <th>EndTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>also I was the point person on my companyÅfs t...</td>\n",
       "      <td>Chandler</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>21</td>\n",
       "      <td>00:16:16,059</td>\n",
       "      <td>00:16:21,731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>You mustÅfve had your hands full.</td>\n",
       "      <td>The Interviewer</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>21</td>\n",
       "      <td>00:16:21,940</td>\n",
       "      <td>00:16:23,442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>That I did. That I did.</td>\n",
       "      <td>Chandler</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>21</td>\n",
       "      <td>00:16:23,442</td>\n",
       "      <td>00:16:26,389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>So letÅfs talk a little bit about your duties.</td>\n",
       "      <td>The Interviewer</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>21</td>\n",
       "      <td>00:16:26,820</td>\n",
       "      <td>00:16:29,572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>My duties?  All right.</td>\n",
       "      <td>Chandler</td>\n",
       "      <td>surprise</td>\n",
       "      <td>positive</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>21</td>\n",
       "      <td>00:16:34,452</td>\n",
       "      <td>00:16:40,917</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Utterance          Speaker  \\\n",
       "0  also I was the point person on my companyÅfs t...         Chandler   \n",
       "1                  You mustÅfve had your hands full.  The Interviewer   \n",
       "2                            That I did. That I did.         Chandler   \n",
       "3     So letÅfs talk a little bit about your duties.  The Interviewer   \n",
       "4                             My duties?  All right.         Chandler   \n",
       "\n",
       "    Emotion Sentiment  Dialogue_ID  Utterance_ID  Old_Dialogue_ID  \\\n",
       "0   neutral   neutral            0             0                0   \n",
       "1   neutral   neutral            0             1                0   \n",
       "2   neutral   neutral            0             2                0   \n",
       "3   neutral   neutral            0             3                0   \n",
       "4  surprise  positive            0             4                0   \n",
       "\n",
       "   Old_Utterance_ID  Season  Episode     StartTime       EndTime  \n",
       "0                 0       8       21  00:16:16,059  00:16:21,731  \n",
       "1                 1       8       21  00:16:21,940  00:16:23,442  \n",
       "2                 2       8       21  00:16:23,442  00:16:26,389  \n",
       "3                 3       8       21  00:16:26,820  00:16:29,572  \n",
       "4                 4       8       21  00:16:34,452  00:16:40,917  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = pd.read_csv('data/train_sent_emo_dya.csv', encoding='MacRoman')\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a8b4826",
   "metadata": {},
   "source": [
    "Drop Old_Dialogue_ID, Old_Utterance_ID, Season, Episode, StarTime, and EndTime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4a470f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Utterance</th>\n",
       "      <th>Speaker</th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Dialogue_ID</th>\n",
       "      <th>Utterance_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>also I was the point person on my companyÅfs t...</td>\n",
       "      <td>Chandler</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>You mustÅfve had your hands full.</td>\n",
       "      <td>The Interviewer</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>That I did. That I did.</td>\n",
       "      <td>Chandler</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>So letÅfs talk a little bit about your duties.</td>\n",
       "      <td>The Interviewer</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>My duties?  All right.</td>\n",
       "      <td>Chandler</td>\n",
       "      <td>surprise</td>\n",
       "      <td>positive</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Utterance          Speaker  \\\n",
       "0  also I was the point person on my companyÅfs t...         Chandler   \n",
       "1                  You mustÅfve had your hands full.  The Interviewer   \n",
       "2                            That I did. That I did.         Chandler   \n",
       "3     So letÅfs talk a little bit about your duties.  The Interviewer   \n",
       "4                             My duties?  All right.         Chandler   \n",
       "\n",
       "    Emotion Sentiment  Dialogue_ID  Utterance_ID  \n",
       "0   neutral   neutral            0             0  \n",
       "1   neutral   neutral            0             1  \n",
       "2   neutral   neutral            0             2  \n",
       "3   neutral   neutral            0             3  \n",
       "4  surprise  positive            0             4  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop_features = list(X_train.keys()[6:])\n",
    "drop_features\n",
    "y_train = pd.DataFrame()\n",
    "y_train[\"Emotion\"] = X_train[\"Emotion\"].copy()\n",
    "y_train[\"Dialogue_ID\"] = X_train[\"Dialogue_ID\"].copy()\n",
    "X_train = X_train.drop(drop_features, axis=1)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd8ac980",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Dialogue_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>surprise</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Emotion  Dialogue_ID\n",
       "0   neutral            0\n",
       "1   neutral            0\n",
       "2   neutral            0\n",
       "3   neutral            0\n",
       "4  surprise            0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e1381d96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Utterance</th>\n",
       "      <th>Speaker</th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Dialogue_ID</th>\n",
       "      <th>Utterance_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>also I was the point person on my company's tr...</td>\n",
       "      <td>Chandler</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>You must've had your hands full.</td>\n",
       "      <td>The Interviewer</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>That I did. That I did.</td>\n",
       "      <td>Chandler</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>So let's talk a little bit about your duties.</td>\n",
       "      <td>The Interviewer</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>My duties?  All right.</td>\n",
       "      <td>Chandler</td>\n",
       "      <td>surprise</td>\n",
       "      <td>positive</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Utterance          Speaker  \\\n",
       "0  also I was the point person on my company's tr...         Chandler   \n",
       "1                   You must've had your hands full.  The Interviewer   \n",
       "2                            That I did. That I did.         Chandler   \n",
       "3      So let's talk a little bit about your duties.  The Interviewer   \n",
       "4                             My duties?  All right.         Chandler   \n",
       "\n",
       "    Emotion Sentiment  Dialogue_ID  Utterance_ID  \n",
       "0   neutral   neutral            0             0  \n",
       "1   neutral   neutral            0             1  \n",
       "2   neutral   neutral            0             2  \n",
       "3   neutral   neutral            0             3  \n",
       "4  surprise  positive            0             4  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[\"Utterance\"] = X_train[\"Utterance\"].apply(lambda x: replace_spelling(x))\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b18f9539",
   "metadata": {},
   "source": [
    "## Getting label encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e90851d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files exist: opening label_encoder and label_decoder\n"
     ]
    }
   ],
   "source": [
    "File1Exists = os.path.isfile(\"data/dump/label_encoder.pkl\")\n",
    "File2Exists = os.path.isfile(\"data/dump/label_decoder.pkl\")\n",
    "MakeNewFiles = False\n",
    "\n",
    "if not(File1Exists) or not(File2Exists) or MakeNewFiles is True:\n",
    "    print(\"Files do not exist: Making label_encoder and label_decoder files\")\n",
    "    labels = y_train[\"Emotion\"].unique()\n",
    "    label_encoder = {label: i for i, label in enumerate(labels)}\n",
    "    label_decoder = {i: label for i, label in enumerate(labels)}\n",
    "\n",
    "    pickle.dump(label_encoder, open('data/dump/label_encoder.pkl', 'wb'))\n",
    "    pickle.dump(label_decoder, open('data/dump/label_decoder.pkl', 'wb'))\n",
    "    \n",
    "else:\n",
    "    print(\"Files exist: opening label_encoder and label_decoder\")\n",
    "    file1 = open('data/dump/label_encoder.pkl', 'rb')\n",
    "    file2 = open('data/dump/label_decoder.pkl', 'rb')\n",
    "    label_encoder = pickle.load(file1)\n",
    "    label_decoder = pickle.load(file2)\n",
    "    file1.close()\n",
    "    file2.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a47c7a",
   "metadata": {},
   "source": [
    "Get the label encoders for each emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0503247d",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m y_train[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEmotion\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m y_train[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEmotion\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: encode_labels(label_encoder, x))\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\series.py:4630\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[0;32m   4520\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[0;32m   4521\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4522\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4525\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   4526\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[0;32m   4527\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4528\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4529\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4628\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4629\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4630\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m SeriesApply(\u001b[38;5;28mself\u001b[39m, func, convert_dtype, args, kwargs)\u001b[38;5;241m.\u001b[39mapply()\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\apply.py:1025\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_str()\n\u001b[0;32m   1024\u001b[0m \u001b[38;5;66;03m# self.f is Callable\u001b[39;00m\n\u001b[1;32m-> 1025\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_standard()\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\apply.py:1076\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1074\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1075\u001b[0m         values \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m)\u001b[38;5;241m.\u001b[39m_values\n\u001b[1;32m-> 1076\u001b[0m         mapped \u001b[38;5;241m=\u001b[39m lib\u001b[38;5;241m.\u001b[39mmap_infer(\n\u001b[0;32m   1077\u001b[0m             values,\n\u001b[0;32m   1078\u001b[0m             f,\n\u001b[0;32m   1079\u001b[0m             convert\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvert_dtype,\n\u001b[0;32m   1080\u001b[0m         )\n\u001b[0;32m   1082\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1083\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1084\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1085\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\lib.pyx:2834\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "Cell \u001b[1;32mIn[28], line 1\u001b[0m, in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[1;32m----> 1\u001b[0m y_train[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEmotion\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m y_train[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEmotion\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: encode_labels(label_encoder, x))\n",
      "Cell \u001b[1;32mIn[3], line 29\u001b[0m, in \u001b[0;36mencode_labels\u001b[1;34m(encoder, l)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mencode_labels\u001b[39m(encoder, l):\n\u001b[1;32m---> 29\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m encoder[l]\n",
      "\u001b[1;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "y_train[\"Emotion\"] = y_train[\"Emotion\"].apply(lambda x: encode_labels(label_encoder, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "11d67d52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Encoder Mapping (Emotion -> Encoded Label):\n",
      "neutral: 0\n",
      "surprise: 1\n",
      "fear: 2\n",
      "sadness: 3\n",
      "joy: 4\n",
      "disgust: 5\n",
      "anger: 6\n"
     ]
    }
   ],
   "source": [
    "# Print the label_encoder dictionary to see the mapping\n",
    "print(\"Label Encoder Mapping (Emotion -> Encoded Label):\")\n",
    "for label, encoded_label in label_encoder.items():\n",
    "    print(f\"{label}: {encoded_label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda41537",
   "metadata": {},
   "source": [
    "From 0 to 14, the Dialogue ID is 0. Emotions are shown as label encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "03d0ac1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Dialogue_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Emotion  Dialogue_ID\n",
       "0         0            0\n",
       "1         0            0\n",
       "2         0            0\n",
       "3         0            0\n",
       "4         1            0\n",
       "5         0            0\n",
       "6         0            0\n",
       "7         0            0\n",
       "8         0            0\n",
       "9         0            0\n",
       "10        2            0\n",
       "11        0            0\n",
       "12        1            0\n",
       "13        0            0\n",
       "14        1            1"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "442f7678",
   "metadata": {},
   "source": [
    "Apply the encoded emotion in X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2df87a48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Utterance</th>\n",
       "      <th>Speaker</th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Dialogue_ID</th>\n",
       "      <th>Utterance_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>also I was the point person on my company's tr...</td>\n",
       "      <td>Chandler</td>\n",
       "      <td>0</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>You must've had your hands full.</td>\n",
       "      <td>The Interviewer</td>\n",
       "      <td>0</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>That I did. That I did.</td>\n",
       "      <td>Chandler</td>\n",
       "      <td>0</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>So let's talk a little bit about your duties.</td>\n",
       "      <td>The Interviewer</td>\n",
       "      <td>0</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>My duties?  All right.</td>\n",
       "      <td>Chandler</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Utterance          Speaker  \\\n",
       "0  also I was the point person on my company's tr...         Chandler   \n",
       "1                   You must've had your hands full.  The Interviewer   \n",
       "2                            That I did. That I did.         Chandler   \n",
       "3      So let's talk a little bit about your duties.  The Interviewer   \n",
       "4                             My duties?  All right.         Chandler   \n",
       "\n",
       "   Emotion Sentiment  Dialogue_ID  Utterance_ID  \n",
       "0        0   neutral            0             0  \n",
       "1        0   neutral            0             1  \n",
       "2        0   neutral            0             2  \n",
       "3        0   neutral            0             3  \n",
       "4        1  positive            0             4  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[\"Emotion\"] = y_train[\"Emotion\"].copy()\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e1cc4d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "## save the data in pickle format ##\n",
    "checkFile = os.path.isfile(\"data/dump/train_labels.pkl\")\n",
    "if checkFile is False:\n",
    "    X_train[\"Emotion\"]\n",
    "\n",
    "    pickle.dump(X_train[\"Emotion\"],\n",
    "                open('data/dump/train_labels.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d506d5c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0\n",
       "1        0\n",
       "2        0\n",
       "3        0\n",
       "4        1\n",
       "        ..\n",
       "12835    5\n",
       "12836    5\n",
       "12837    1\n",
       "12838    0\n",
       "12839    4\n",
       "Name: Emotion, Length: 12840, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[\"Emotion\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae01afc",
   "metadata": {},
   "source": [
    "## Importing Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a539fab3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\School Files\\23-24 T2\\THS-ST2\\ER_GAT\\data/wiki-news-300d-1M.vec exists\n"
     ]
    }
   ],
   "source": [
    "file_path = os.path.join(os.getcwd(), \"data/wiki-news-300d-1M.vec\")\n",
    "if os.path.isfile(file_path):\n",
    "    print(f\"{file_path} exists\")\n",
    "else:\n",
    "    print(f\"The file does not exist in the current directory.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c74680f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = Vectors(name=\"wiki-news-300d-1M.vec\", url=\"data/\", cache=\"data/\")\n",
    "vectors.cache(name=\"data/wiki-news-300d-1M.vec\", url=\"data/\", cache=\"data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "89ca952d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([999994, 300])\n"
     ]
    }
   ],
   "source": [
    "print(vectors.vectors.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b27c37d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = Vocab(counter=collections.Counter(_read_words(X_train.Utterance)),\n",
    "                  vectors=vectors,\n",
    "                  specials=['<pad>', '<unk>'],\n",
    "                  min_freq=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f41e9829",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total num. of words: 2120, word vector dimension: 300\n"
     ]
    }
   ],
   "source": [
    "# print word embedding statistics \n",
    "wv_size = vocab.vectors.size() \n",
    "print('Total num. of words: {}, word vector dimension: {}'.format( \n",
    "   wv_size[0], \n",
    "   wv_size[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d7c0f2",
   "metadata": {},
   "source": [
    "# Creating an embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0db604a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WORDEBD(\n",
       "  (embedding_layer): Embedding(2120, 300)\n",
       ")"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ebd = WORDEBD(vocab, False)\n",
    "ebd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5238db3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Munch({\n",
    "    \"cnn_filter_sizes\":[3,4,5],\n",
    "    \"cnn_num_filters\":100,\n",
    "    \"cuda\":-1,\n",
    "    \"mode\":\"train\",\n",
    "    \"snapshot\":'',\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "87436c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNNLSTMseq(ebd, args) # ProtoSeq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8f3a4969",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/03/06 00:08:10, Building embedding\n"
     ]
    }
   ],
   "source": [
    "print(\"{}, Building embedding\".format(\n",
    "    datetime.datetime.now().strftime('%y/%m/%d %H:%M:%S')), flush=True),\n",
    "if args.snapshot != '':\n",
    "    if args.multitask:\n",
    "        print(\"{}, Loading pretrained embedding from {}\".format(\n",
    "            datetime.datetime.now().strftime('%y/%m/%d %H:%M:%S'),\n",
    "            '%s_%s.ebd' % (args.snapshot, args.task),\n",
    "            ))\n",
    "        model.load_state_dict(  torch.load( '%s_%s.ebd' % (args.snapshot, args.task) ), strict=False  )\n",
    "    \n",
    "    # Load pretrained models,\n",
    "    else:   \n",
    "        print(\"{}, Loading pretrained embedding from {}\".format(\n",
    "            datetime.datetime.now().strftime('%y/%m/%d %H:%M:%S'),\n",
    "            '{}.ebd'.format(args.snapshot)\n",
    "            ))\n",
    "        model.load_state_dict(  torch.load( '{}.ebd'.format(args.snapshot) ), strict=False  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "481c95c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNNLSTMseq(\n",
       "  (ebd): WORDEBD(\n",
       "    (embedding_layer): Embedding(2120, 300)\n",
       "  )\n",
       "  (convs): ModuleList(\n",
       "    (0): Conv1d(300, 100, kernel_size=(3,), stride=(1,))\n",
       "    (1): Conv1d(300, 100, kernel_size=(4,), stride=(1,))\n",
       "    (2): Conv1d(300, 100, kernel_size=(5,), stride=(1,))\n",
       "  )\n",
       "  (lstm): LSTM(300, 150, bidirectional=True)\n",
       ")"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d87fc320",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNNLSTMseq(\n",
       "  (ebd): WORDEBD(\n",
       "    (embedding_layer): Embedding(2120, 300)\n",
       "  )\n",
       "  (convs): ModuleList(\n",
       "    (0): Conv1d(300, 100, kernel_size=(3,), stride=(1,))\n",
       "    (1): Conv1d(300, 100, kernel_size=(4,), stride=(1,))\n",
       "    (2): Conv1d(300, 100, kernel_size=(5,), stride=(1,))\n",
       "  )\n",
       "  (lstm): LSTM(300, 150, bidirectional=True)\n",
       ")"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f9a4783",
   "metadata": {},
   "source": [
    "# Updated Representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "22c69a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ranges = find_value_ranges(X_train[\"Dialogue_ID\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "200bbb7c",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "updated_representations = [] \n",
    " \n",
    "checkFile = os.path.isfile(\"embed/updated_representation_list.pkl\") \n",
    " \n",
    "if checkFile is False: \n",
    "    for range_pair in ranges: \n",
    "        start_idx, end_idx = range_pair \n",
    "        conversation = X_train['Utterance'][start_idx:end_idx+1] \n",
    " \n",
    "        turn_indices = [torch.tensor([vocab.stoi[word] if word in vocab.stoi else vocab.stoi['<unk>'] for word in turn]) \n",
    "                    for turn in conversation] \n",
    "        max_seq_len = max(max(len(turn), 5) for turn in turn_indices) \n",
    "        padded_turns = [torch.nn.functional.pad(turn, pad=(0, max_seq_len - len(turn))) for turn in turn_indices] \n",
    " \n",
    "        # Stack the padded turns along a new dimension \n",
    "        batched_input = torch.stack(padded_turns) \n",
    "        input_data = {'Utterance': batched_input} \n",
    "        output_representation = model(input_data) \n",
    " \n",
    "        updated_representations.append(output_representation) \n",
    "     \n",
    "     \n",
    "    file_path = 'embed/updated_representation_list.pkl' \n",
    "    # Save the list to a file using pickle \n",
    "    with open(file_path, 'wb') as file: \n",
    "        pickle.dump(updated_representations, file) \n",
    "     \n",
    "else: \n",
    "    file_path = 'embed/updated_representation_list.pkl' \n",
    " \n",
    "    # Load the list from the file using pickle \n",
    "    with open(file_path, 'rb') as file: \n",
    "        updated_representations = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5c3d1152",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19528"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "updated_representations.__sizeof__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a1821fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkFile = False\n",
    "encoded_speaker_list = [] \n",
    "if checkFile is False: \n",
    "    for range_pair in ranges: \n",
    "        start_idx, end_idx = range_pair \n",
    "        speaker_per_dialog = X_train['Speaker'][start_idx:end_idx+1].copy() \n",
    "        speaker_feature = set(speaker_per_dialog) \n",
    "        speaker_encoder = {feature: i for i, feature in enumerate(speaker_feature)} \n",
    "        speaker_decoder = {i: feature for i, feature in enumerate(speaker_feature)} \n",
    "\n",
    " \n",
    "        encoded_speaker = speaker_per_dialog.replace(speaker_encoder) \n",
    "        encoded_speaker_list.append(encoded_speaker) \n",
    " \n",
    "    file_path = 'data/dump/speaker_encoder.pkl' \n",
    "    with open(file_path, 'wb') as file: \n",
    "        pickle.dump([encoded_speaker_list, ranges], file) \n",
    "\n",
    "else: \n",
    "    file = open('data/dump/speaker_encoder.pkl',  \"rb\") \n",
    "    encoded_speaker_list = pickle.load(file) \n",
    "    file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b63fd00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re, time, pickle, collections, importlib, datetime, torch\n",
    "import pandas as pd, numpy as np, pickle\n",
    "from chardet import detect\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from collections import defaultdict, Counter\n",
    "from wordebd import WORDEBD\n",
    "from vocab import Vocab, Vectors\n",
    "from munch import Munch\n",
    "from cnnlstmseq import CNNLSTMseq\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8e3efa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_encoding_type(file):\n",
    "    with open(file, 'rb') as f:\n",
    "        rawdata = f.read(),\n",
    "    return detect(rawdata['encoding'])\n",
    "\n",
    "def detect_misspelling(source):\n",
    "    pass\n",
    "def replace_spelling(source):\n",
    "    return re.sub(\"Åf\", \"'\", source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b9072d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# referenced from DialogueGCN, mastodon code\n",
    "def preprocess_text(x):\n",
    "    for punct in '!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~\\'':\n",
    "        x = x.replace(punct, ' ')\n",
    "    x = ' '.join(x.split())\n",
    "    x = x.lower()\n",
    "\n",
    "    return x\n",
    "\n",
    "def load_pretrained_glove():\n",
    "    print(\"Loading GloVe...\")\n",
    "    glv_vector = {}\n",
    "    f = open('/embed/glove/glove.840B.300d.txt', encoding='utf-8')\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word, coefs = values[0], np.asarray(values[1:], dtype='float')\n",
    "        try:\n",
    "            glv_vector[word] = coefs\n",
    "\n",
    "        except ValueError:\n",
    "            continue\n",
    "    f.close()\n",
    "    start_time = time.time()\n",
    "    print(f\"Took {time.time() - start_time} seconds to load pretrained GloVe model.\")\n",
    "    return glv_vector\n",
    "\n",
    "\n",
    "def encode_labels(encoder, l):\n",
    "    return encoder[l]\n",
    "\n",
    "def load_data_from_npy(file_path):\n",
    "    try:\n",
    "        data = np.load(file_path, allow_pickle=True)\n",
    "        if isinstance(data, np.ndarray):\n",
    "            if data.ndim == 2:\n",
    "                return pd.DataFrame(data)\n",
    "            else:\n",
    "                raise ValueError(\"The loaded array is not two-dimensional.\")\n",
    "        else:\n",
    "            raise TypeError(\"The loaded object is not a NumPy array.\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File not found at {file_path}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error: An exception occurred - {str(e)}\")\n",
    "        return None\n",
    "    \n",
    "# def sentence_embedding(sentence, embeddings):\n",
    "#     words = sentence.split()\n",
    "#     vectors = [embeddings.get(word, np.zeros(300)) for word in words]\n",
    "#     mean_vector = np.mean(vectors, axis=0)\n",
    "#     return mean_vector\n",
    "\n",
    "def _read_words(data, convmode=None):\n",
    "    '''    \n",
    "        Count the occurrences of all words\n",
    "        @param convmode: str, None for non conversational scope, 'naive' for classic or naive approach, 'conv' for conversation depth into account (one additional dim and nested values)\n",
    "        @param data: list of examples\n",
    "        @return words: list of words (with duplicates)\n",
    "    '''    \n",
    "    words = []\n",
    "    if convmode is None:\n",
    "        for example in data:\n",
    "            words += example.split()     \n",
    "    return words\n",
    "\n",
    "def _data_to_nparray(data, vocab, args):\n",
    "    '''\n",
    "        Convert the data into a dictionary of np arrays for speed.\n",
    "    '''\n",
    "    raw = np.array([e for e in data[\"Utterance\"]], dtype=object)\n",
    "    doc_label = np.array([x for x in data[\"Emotion\"]], dtype=np.int64)\n",
    "\n",
    "    # compute the max text length\n",
    "    text_len = np.array([len(e) for e in data[\"Utterance\"]])\n",
    "    max_text_len = max(text_len)\n",
    "    ids = np.array([e for e in data['Dialogue_ID']])\n",
    "    ids2 = np.array([e for e in data['Utterance_ID']])\n",
    "\n",
    "    # initialize the big numpy array by <pad>\n",
    "    text = vocab.stoi['<pad>'] * np.ones([len(data), max_text_len],\n",
    "                                     dtype=np.int64)\n",
    "\n",
    "    del_idx = []\n",
    "    # convert each token to its corresponding id\n",
    "    for i in range(len(X_train)):\n",
    "        text[i, :len(X_train['Utterance'][i])] = [vocab.stoi[x] if x in vocab.stoi else vocab.stoi['<unk>']\n",
    "                for x in X_train['Utterance'][i]]\n",
    "\n",
    "        # filter out document with only unk and pad\n",
    "        if np.max(text[i]) < 2:\n",
    "            del_idx.append(i)\n",
    "\n",
    "    vocab_size = vocab.vectors.size()[0]\n",
    "\n",
    "\n",
    "    ## Curation for padding (string instead of list of list)\n",
    "    raw = [ [\"<pad>\" if m == [\"<pad>\", \"<pad>\", \"<pad>\", \"<pad>\", \"<pad>\"] else m for m in c ] for c in raw ]\n",
    "\n",
    "    ids, ids2, text_len, text, doc_label, raw = _del_by_idx( [ids, ids2, text_len, text, doc_label, raw], del_idx, 0)\n",
    "    new_data = {\n",
    "        'ids': ids,\n",
    "        'ids2': ids2,\n",
    "        'text': text,\n",
    "        'text_len': text_len,\n",
    "        'label': doc_label,\n",
    "#         'raw': raw,\n",
    "        'vocab_size': vocab_size,\n",
    "    }\n",
    "\n",
    "    return new_data\n",
    "\n",
    "def _del_by_idx(array_list, idx, axis):\n",
    "\n",
    "    '''        \n",
    "        Delete the specified index for each array in the array_lists\",\n",
    "\n",
    "        @params: array_list: list of np arrays\n",
    "        @params: idx: list of int\n",
    "        @params: axis: int\n",
    "\n",
    "        @return: res: tuple of pruned np arrays\n",
    "    '''\n",
    "    if type(array_list) is not list:\n",
    "        array_list = [array_list]\n",
    "\n",
    "    # modified to perform operations in place\n",
    "    for i, array in enumerate(array_list):\n",
    "        array_list[i] = np.delete(array, idx, axis)\n",
    "\n",
    "    if len(array_list) == 1:\n",
    "        return array_list[0]\n",
    "    else:\n",
    "        return array_list\n",
    "\n",
    "def find_value_ranges(lst):\n",
    "    value_ranges = []\n",
    "    start_index = 0\n",
    "\n",
    "    for i in range(1, len(lst)):\n",
    "        if lst[i] != lst[i - 1]:\n",
    "            value_ranges.append((start_index, i - 1))\n",
    "            start_index = i\n",
    "\n",
    "    # Add the last range\n",
    "    value_ranges.append((start_index, len(lst) - 1))\n",
    "\n",
    "    return value_ranges\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94282feb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.git',\n",
       " '.gitignore',\n",
       " 'cnnlstmseq.py',\n",
       " 'context_encoder.ipynb',\n",
       " 'data',\n",
       " 'embed',\n",
       " 'emotionClassifier.ipynb',\n",
       " 'GAT.py',\n",
       " 'LICENSE',\n",
       " 'README.md',\n",
       " 'relationtype_encoder.ipynb',\n",
       " 'runs',\n",
       " 'utils',\n",
       " 'vocab.py',\n",
       " 'wordebd.py',\n",
       " '__pycache__']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7147d96d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12840, 12)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = pd.read_csv('data/train_sent_emo_dya.csv', encoding='MacRoman')\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4a470f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Utterance</th>\n",
       "      <th>Speaker</th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Dialogue_ID</th>\n",
       "      <th>Utterance_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>also I was the point person on my companyÅfs t...</td>\n",
       "      <td>Chandler</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>You mustÅfve had your hands full.</td>\n",
       "      <td>The Interviewer</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>That I did. That I did.</td>\n",
       "      <td>Chandler</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Utterance          Speaker  \\\n",
       "0  also I was the point person on my companyÅfs t...         Chandler   \n",
       "1                  You mustÅfve had your hands full.  The Interviewer   \n",
       "2                            That I did. That I did.         Chandler   \n",
       "\n",
       "   Emotion Sentiment  Dialogue_ID  Utterance_ID  \n",
       "0  neutral   neutral            0             0  \n",
       "1  neutral   neutral            0             1  \n",
       "2  neutral   neutral            0             2  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop_features = list(X_train.keys()[6:])\n",
    "# drop_features.append(\"Emotion\")\n",
    "drop_features\n",
    "y_train = pd.DataFrame()\n",
    "y_train[\"Emotion\"] = X_train[\"Emotion\"].copy()\n",
    "y_train[\"Dialogue_ID\"] = X_train[\"Dialogue_ID\"].copy()\n",
    "X_train = X_train.drop(drop_features, axis=1)\n",
    "X_train[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd8ac980",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12840, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e1381d96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Utterance</th>\n",
       "      <th>Speaker</th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Dialogue_ID</th>\n",
       "      <th>Utterance_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>also I was the point person on my company's tr...</td>\n",
       "      <td>Chandler</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>You must've had your hands full.</td>\n",
       "      <td>The Interviewer</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>That I did. That I did.</td>\n",
       "      <td>Chandler</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>So let's talk a little bit about your duties.</td>\n",
       "      <td>The Interviewer</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>My duties?  All right.</td>\n",
       "      <td>Chandler</td>\n",
       "      <td>surprise</td>\n",
       "      <td>positive</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Now you'll be heading a whole division, so you...</td>\n",
       "      <td>The Interviewer</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>I see.</td>\n",
       "      <td>Chandler</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>But there'll be perhaps 30 people under you so...</td>\n",
       "      <td>The Interviewer</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Good to know.</td>\n",
       "      <td>Chandler</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>We can go into detail</td>\n",
       "      <td>The Interviewer</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>No don't I beg of you!</td>\n",
       "      <td>Chandler</td>\n",
       "      <td>fear</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>All right then, we'll have a definite answer f...</td>\n",
       "      <td>The Interviewer</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Really?!</td>\n",
       "      <td>Chandler</td>\n",
       "      <td>surprise</td>\n",
       "      <td>positive</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Absolutely.  You can relax</td>\n",
       "      <td>The Interviewer</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Utterance          Speaker  \\\n",
       "0   also I was the point person on my company's tr...         Chandler   \n",
       "1                    You must've had your hands full.  The Interviewer   \n",
       "2                             That I did. That I did.         Chandler   \n",
       "3       So let's talk a little bit about your duties.  The Interviewer   \n",
       "4                              My duties?  All right.         Chandler   \n",
       "5   Now you'll be heading a whole division, so you...  The Interviewer   \n",
       "6                                              I see.         Chandler   \n",
       "7   But there'll be perhaps 30 people under you so...  The Interviewer   \n",
       "8                                       Good to know.         Chandler   \n",
       "9                               We can go into detail  The Interviewer   \n",
       "10                             No don't I beg of you!         Chandler   \n",
       "11  All right then, we'll have a definite answer f...  The Interviewer   \n",
       "12                                           Really?!         Chandler   \n",
       "13                         Absolutely.  You can relax  The Interviewer   \n",
       "\n",
       "     Emotion Sentiment  Dialogue_ID  Utterance_ID  \n",
       "0    neutral   neutral            0             0  \n",
       "1    neutral   neutral            0             1  \n",
       "2    neutral   neutral            0             2  \n",
       "3    neutral   neutral            0             3  \n",
       "4   surprise  positive            0             4  \n",
       "5    neutral   neutral            0             5  \n",
       "6    neutral   neutral            0             6  \n",
       "7    neutral   neutral            0             7  \n",
       "8    neutral   neutral            0             8  \n",
       "9    neutral   neutral            0             9  \n",
       "10      fear  negative            0            10  \n",
       "11   neutral   neutral            0            11  \n",
       "12  surprise  positive            0            12  \n",
       "13   neutral   neutral            0            13  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[\"Utterance\"] = X_train[\"Utterance\"].apply(lambda x: replace_spelling(x))\n",
    "X_train[:14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab33f245",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12840, 6)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e90851d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkFile1 = os.path.isfile(\"data/dump/label_encoder.pkl\")\n",
    "checkFile2 = os.path.isfile(\"data/dump/label_decoder.pkl\")\n",
    "\n",
    "if checkFile1 or checkFile2 is False:\n",
    "    labels = set(y_train.Emotion)\n",
    "    label_encoder = {label: i for i, label in enumerate(labels)}\n",
    "    label_decoder = {i: label for i, label in enumerate(labels)}\n",
    "\n",
    "    pickle.dump(label_encoder, open('data/dump/label_encoder.pkl', 'wb'))\n",
    "    pickle.dump(label_decoder, open('data/dump/label_decoder.pkl', 'wb'))\n",
    "    \n",
    "else:\n",
    "    file1 = open('data/dump/label_encoder.pkl', 'rb')\n",
    "    file2 = open('data/dump/label_decoder.pkl', 'rb')\n",
    "    label_encoder = pickle.load(file1)\n",
    "    label_decoder = pickle.load(file2)\n",
    "    file1.close()\n",
    "    file2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0503247d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train[\"Emotion\"] = y_train[\"Emotion\"].apply(lambda x: encode_labels(label_encoder, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "543f0bc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Encoder Mapping (Emotion -> Encoded Label):\n",
      "fear: 0\n",
      "anger: 1\n",
      "surprise: 2\n",
      "joy: 3\n",
      "sadness: 4\n",
      "disgust: 5\n",
      "neutral: 6\n"
     ]
    }
   ],
   "source": [
    "# Print the label_encoder dictionary to see the mapping\n",
    "print(\"Label Encoder Mapping (Emotion -> Encoded Label):\")\n",
    "for label, encoded_label in label_encoder.items():\n",
    "    print(f\"{label}: {encoded_label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "613834a8",
   "metadata": {},
   "source": [
    "### This is what each emotion represents\n",
    "neutral: 0\n",
    "\n",
    "anger: 1\n",
    "\n",
    "sadness: 2\n",
    "\n",
    "surprise: 3\n",
    "\n",
    "disgust: 4\n",
    "\n",
    "joy: 5\n",
    "\n",
    "fear: 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2df87a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[\"Emotion\"] = y_train[\"Emotion\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e1cc4d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "## save the data in pickle format ##\n",
    "checkFile = os.path.isfile(\"data/dump/train_labels.pkl\")\n",
    "if checkFile is False:\n",
    "    X_train[\"Emotion\"]\n",
    "\n",
    "    pickle.dump(X_train[\"Emotion\"],\n",
    "                open('data/dump/train_labels.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8f38cf3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkFile = os.path.isfile(\"data/dump/dialog_ids.pkl\")\n",
    "# if checkFile is False:\n",
    "#     dialogSpeakers, dialogInputSeq, dialogInputMaxSeqLen, dialogLabels = {}, {}, {}, {}\n",
    "#     X_train_dialog_ids = set(X_train.Dialogue_ID)\n",
    "#     all_data = X_train.copy()\n",
    "#     # all_data = X_train.append(X_test, ignore_index=True).append(X_valid, ignore_index=True)\n",
    "\n",
    "#     for item in list(X_train_dialog_ids):\n",
    "#         X_df = all_data[all_data.Dialogue_ID == item]\n",
    "#         y_df = y_train[y_train[\"Dialogue_ID\"] == item] \n",
    "\n",
    "#         dialogSpeakers[item] = list(X_df.Speaker)\n",
    "#         dialogInputSeq[item] = list(X_df.sequence)\n",
    "#         dialogInputMaxSeqLen[item] = max(list(X_df.sentence_length))\n",
    "#         dialogLabels[item] = list(y_df.Emotion)\n",
    "\n",
    "#     pickle.dump([dialogSpeakers, dialogInputSeq, dialogInputMaxSeqLen, dialogLabels, X_train_dialog_ids],\n",
    "#                 open('data/dump/per_dialog_ids.pkl', 'wb'))\n",
    "# else:\n",
    "#     file = open('data/dump/per_dialog_ids.pkl', \"rb\")\n",
    "#     dialogSpeakers, dialogInputSeq, dialogInputMaxSeqLen, dialogLabels, X_train_dialog_ids = pickle.load(file)\n",
    "#     file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f71baeda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## tokenize all sentences ##\n",
    "# checkFile = os.path.isfile(\"data/dump/tokenizer.pkl\")\n",
    "\n",
    "# if checkFile is False:\n",
    "#     all_text = list(X_train.Utterance)\n",
    "#     tokenizer = Tokenizer()\n",
    "#     tokenizer.fit_on_texts(all_text)\n",
    "#     pickle.dump(tokenizer, open('data/dump/tokenizer.pkl', 'wb'))\n",
    "# else:\n",
    "#     file = open('data/dump/tokenizer.pkl', 'rb')\n",
    "#     tokenizer = pickle.load(file)\n",
    "#     file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "96268d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## convert the sentences into sequences ## \n",
    "# train_sequence = tokenizer.texts_to_sequences(list(X_train.Utterance)) \n",
    "# X_train['sentence_length'] = [len(item) for item in train_sequence] \n",
    " \n",
    "# max_num_tokens = 250 \n",
    "\n",
    "# train_sequence = pad_sequences(train_sequence, maxlen=max_num_tokens, padding='post') \n",
    " \n",
    "# X_train['sequence'] = list(train_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cad434c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer.word_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "169ca725",
   "metadata": {},
   "source": [
    "Idk why glove embeddings and toknizers were used in the orig source code..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2911056b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## save the data in pickle format ##\n",
    "# checkFile = os.path.isfile(\"data/dump/per_dialog_ids.pkl\")\n",
    "# if checkFile is False:\n",
    "#     dialogSpeakers, dialogInputSeq, dialogInputMaxSeqLen, dialogLabels = {}, {}, {}, {}\n",
    "#     X_train_dialog_ids = set(X_train.Dialogue_ID)\n",
    "#     all_data = X_train.copy()\n",
    "#     # all_data = X_train.append(X_test, ignore_index=True).append(X_valid, ignore_index=True)\n",
    "\n",
    "#     for item in list(X_train_dialog_ids):\n",
    "#         X_df = all_data[all_data.Dialogue_ID == item]\n",
    "#         y_df = y_train[y_train[\"Dialogue_ID\"] == item] \n",
    "\n",
    "#         dialogSpeakers[item] = list(X_df.Speaker)\n",
    "#         dialogInputSeq[item] = list(X_df.sequence)\n",
    "#         dialogInputMaxSeqLen[item] = max(list(X_df.sentence_length))\n",
    "#         dialogLabels[item] = list(y_df.Emotion)\n",
    "\n",
    "#     pickle.dump([dialogSpeakers, dialogInputSeq, dialogInputMaxSeqLen, dialogLabels, X_train_dialog_ids],\n",
    "#                 open('data/dump/per_dialog_ids.pkl', 'wb'))\n",
    "# else:\n",
    "#     file = open('data/dump/per_dialog_ids.pkl', \"rb\")\n",
    "#     dialogSpeakers, dialogInputSeq, dialogInputMaxSeqLen, dialogLabels, X_train_dialog_ids = pickle.load(file)\n",
    "#     file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3849c0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## save pretrained embedding matrix ## \n",
    "# file = open('data/dump/glv_embedding_matrix.npy', \"rb\") \n",
    "# if file is None: \n",
    "#     glv_vector = load_pretrained_glove() \n",
    "#     word_vector_length = len(glv_vector['the'])#dim=300 \n",
    "#     word_index = tokenizer.word_index \n",
    "#     inv_word_index = {v: k for k, v in word_index.items()} \n",
    "#     num_unique_words = len(word_index) \n",
    "#     glv_embedding_matrix = np.zeros((num_unique_words + 1, word_vector_length)) \n",
    " \n",
    "#     for j in range(1, num_unique_words + 1): \n",
    "#         glv_embedding_matrix[j] = glv_vector.get(inv_word_index[j], np.random.randn(word_vector_length) / 200) \n",
    " \n",
    "#     np.save('data/dump/glv_embedding_matrix.npy', glv_embedding_matrix) \n",
    "#     print('Done. Completed preprocessing.') \n",
    "# else: \n",
    "#     glv_embedding_matrix = np.load('data/dump/glv_embedding_matrix.npy', allow_pickle=True) \n",
    "#     file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "367963a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocab_size, embedding_dim = glv_embedding_matrix.shape\n",
    "# vocab_size, embedding_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a539fab3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\School Files\\23-24 T2\\THS-ST2\\ER_GAT\\data/wiki-news-300d-1M.vec exists\n"
     ]
    }
   ],
   "source": [
    "file_path = os.path.join(os.getcwd(), \"data/wiki-news-300d-1M.vec\")\n",
    "if os.path.isfile(file_path):\n",
    "    print(f\"{file_path} exists\")\n",
    "else:\n",
    "    print(f\"The file does not exist in the current directory.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c74680f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = Vectors(name=\"wiki-news-300d-1M.vec\", url=\"data/\", cache=\"data/\")\n",
    "vectors.cache(name=\"data/wiki-news-300d-1M.vec\", url=\"data/\", cache=\"data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "89ca952d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([999994, 300])\n"
     ]
    }
   ],
   "source": [
    "print(vectors.vectors.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b27c37d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = Vocab(counter=collections.Counter(_read_words(X_train.Utterance)),\n",
    "                  vectors=vectors,\n",
    "                  specials=['<pad>', '<unk>'],\n",
    "                  min_freq=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f41e9829",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total num. of words: 2120, word vector dimension: 300\n"
     ]
    }
   ],
   "source": [
    "# print word embedding statistics \n",
    "wv_size = vocab.vectors.size() \n",
    "print('Total num. of words: {}, word vector dimension: {}'.format( \n",
    "   wv_size[0], \n",
    "   wv_size[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0db604a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WORDEBD(\n",
       "  (embedding_layer): Embedding(2120, 300)\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ebd = WORDEBD(vocab, False)\n",
    "ebd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5238db3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Munch({\n",
    "    \"cnn_filter_sizes\":[3,4,5],\n",
    "    \"cnn_num_filters\":100,\n",
    "    \"cuda\":-1,\n",
    "    \"mode\":\"train\",\n",
    "    \"snapshot\":'',\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d7c0f2",
   "metadata": {},
   "source": [
    "Creating an embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "87436c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNNLSTMseq(ebd, args) # ProtoSeq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8f3a4969",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/03/01 01:03:37, Building embedding\n"
     ]
    }
   ],
   "source": [
    "print(\"{}, Building embedding\".format(\n",
    "    datetime.datetime.now().strftime('%y/%m/%d %H:%M:%S')), flush=True),\n",
    "if args.snapshot != '':\n",
    "    if args.multitask:\n",
    "        print(\"{}, Loading pretrained embedding from {}\".format(\n",
    "            datetime.datetime.now().strftime('%y/%m/%d %H:%M:%S'),\n",
    "            '%s_%s.ebd' % (args.snapshot, args.task),\n",
    "            ))\n",
    "        model.load_state_dict(  torch.load( '%s_%s.ebd' % (args.snapshot, args.task) ), strict=False  )\n",
    "    else:   \n",
    "        # load pretrained models,\n",
    "        print(\"{}, Loading pretrained embedding from {}\".format(\n",
    "            datetime.datetime.now().strftime('%y/%m/%d %H:%M:%S'),\n",
    "            '{}.ebd'.format(args.snapshot)\n",
    "            ))\n",
    "        model.load_state_dict(  torch.load( '{}.ebd'.format(args.snapshot) ), strict=False  )\n",
    "# if args.cuda != -1: ,\n",
    "#     model.cuda(args.cuda),\n",
    "# else: ,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "481c95c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNNLSTMseq(\n",
       "  (ebd): WORDEBD(\n",
       "    (embedding_layer): Embedding(2120, 300)\n",
       "  )\n",
       "  (convs): ModuleList(\n",
       "    (0): Conv1d(300, 100, kernel_size=(3,), stride=(1,))\n",
       "    (1): Conv1d(300, 100, kernel_size=(4,), stride=(1,))\n",
       "    (2): Conv1d(300, 100, kernel_size=(5,), stride=(1,))\n",
       "  )\n",
       "  (lstm): LSTM(300, 150, bidirectional=True)\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "705921fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert everything into np array for fast data loading\n",
    "# _X_train = _data_to_nparray(X_train, vocab, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ff983f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d87fc320",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNNLSTMseq(\n",
       "  (ebd): WORDEBD(\n",
       "    (embedding_layer): Embedding(2120, 300)\n",
       "  )\n",
       "  (convs): ModuleList(\n",
       "    (0): Conv1d(300, 100, kernel_size=(3,), stride=(1,))\n",
       "    (1): Conv1d(300, 100, kernel_size=(4,), stride=(1,))\n",
       "    (2): Conv1d(300, 100, kernel_size=(5,), stride=(1,))\n",
       "  )\n",
       "  (lstm): LSTM(300, 150, bidirectional=True)\n",
       ")"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5246b15",
   "metadata": {},
   "source": [
    "Testing on smaller data. Uncomment to see the size of updated representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d9000ec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 5, 300])\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# sample data \n",
    "data = [ \n",
    "#     [\"how are you\", \"I am great how about you\", \"good too\"], \n",
    "    [\"hes\"], \n",
    "    # ... more conversations ... \n",
    "] \n",
    "tmp_in = []         \n",
    "for conversation in data: \n",
    "    turn_indices = [torch.tensor([vocab.stoi[word] if word in vocab.stoi else vocab.stoi['<unk>'] for word in turn]) \n",
    "                for turn in conversation] \n",
    "#     print((turn_indices)) \n",
    "    # Pad sequences to a fixed length (adjust this based on your model requirements) \n",
    "    max_seq_len = max(max(len(turn), 5) for turn in turn_indices) \n",
    " \n",
    "    padded_turns = [torch.nn.functional.pad(turn, pad=(0, max_seq_len - len(turn))) for turn in turn_indices] \n",
    " \n",
    "    # Stack the padded turns along a new dimension \n",
    "    batched_input = torch.stack(padded_turns) \n",
    "    input_data = {'Utterance': batched_input} \n",
    "    tmp_in = max_seq_len \n",
    "    print(model.ebd(input_data[\"Utterance\"], None).size()) \n",
    "    print(len(model.ebd(input_data[\"Utterance\"], None))) \n",
    " \n",
    "    model(input_data) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d75d57",
   "metadata": {},
   "source": [
    "This is just a duplicate of code above. Using this on train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6c46de26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12840, 6)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1c77dcdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     0\n",
       "1     0\n",
       "2     0\n",
       "3     0\n",
       "4     0\n",
       "5     0\n",
       "6     0\n",
       "7     0\n",
       "8     0\n",
       "9     0\n",
       "10    0\n",
       "11    0\n",
       "12    0\n",
       "13    0\n",
       "14    1\n",
       "Name: Dialogue_ID, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[\"Dialogue_ID\"][:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "22c69a9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2160"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranges = find_value_ranges(X_train[\"Dialogue_ID\"])\n",
    "len(ranges)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce05d7f7",
   "metadata": {},
   "source": [
    "Range in index 0 is (0,13) because in X_train[\"Dialogue_ID\"] 0 is present from index 0 to 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0a996dcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 13), (14, 20), (21, 33), (34, 41), (42, 48)]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranges[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "200bbb7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_representations = [] \n",
    " \n",
    "# checkFile = os.path.isfile(\"embed/updated_representation_list.pkl\") \n",
    "checkFile = False\n",
    "\n",
    "if checkFile is False: \n",
    "    for range_pair in ranges: \n",
    "        start_idx, end_idx = range_pair \n",
    "        conversation = X_train['Utterance'][start_idx:end_idx+1] \n",
    " \n",
    "        turn_indices = [torch.tensor([vocab.stoi[word] if word in vocab.stoi else vocab.stoi['<unk>'] for word in turn]) \n",
    "                    for turn in conversation] \n",
    "        max_seq_len = max(max(len(turn), 5) for turn in turn_indices) \n",
    "        padded_turns = [torch.nn.functional.pad(turn, pad=(0, max_seq_len - len(turn))) for turn in turn_indices] \n",
    " \n",
    "        # Stack the padded turns along a new dimension \n",
    "        batched_input = torch.stack(padded_turns) \n",
    "        input_data = {'Utterance': batched_input} \n",
    "        output_representation = model(input_data) \n",
    " \n",
    "        updated_representations.append(output_representation) \n",
    "     \n",
    "     \n",
    "    file_path = 'embed/updated_representation_list.pkl' \n",
    "    # Save the list to a file using pickle \n",
    "    with open(file_path, 'wb') as file: \n",
    "        pickle.dump(updated_representations, file) \n",
    "     \n",
    "else: \n",
    "    file_path = 'embed/updated_representation_list.pkl' \n",
    " \n",
    "    # Load the list from the file using pickle \n",
    "    with open(file_path, 'rb') as file: \n",
    "        updated_representations = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4aea66e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of updated_representation: 2160\n"
     ]
    }
   ],
   "source": [
    "print(f\"Length of updated_representation: \" + str(len(updated_representations)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16177aa6",
   "metadata": {},
   "source": [
    "Checking the length of updated_representation[0]. Expected is 14 which we got. This is because it uses the range from (0, 13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2817b383",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(updated_representations[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a1821fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkFile = os.path.isfile( \"data/dump/speaker_encoder.pkl\") \n",
    "encoded_speaker_list = [] \n",
    "if checkFile is False: \n",
    "    for range_pair in ranges: \n",
    "        start_idx, end_idx = range_pair \n",
    "        speaker_per_dialog = X_train['Speaker'][start_idx:end_idx+1].copy() \n",
    "        speaker_feature = set(speaker_per_dialog) \n",
    "        speaker_encoder = {feature: i for i, feature in enumerate(speaker_feature)} \n",
    "        speaker_decoder = {i: feature for i, feature in enumerate(speaker_feature)} \n",
    "        # print( \"ID:  \",  range_pair,    \", speaker_encoder) \n",
    "        # print( \"ID:  \",  speaker_per_dialog) \n",
    " \n",
    "        encoded_speaker = speaker_per_dialog.replace(speaker_encoder) \n",
    "        encoded_speaker_list.append(encoded_speaker) \n",
    " \n",
    "    file_path = 'data/dump/speaker_encoder.pkl' \n",
    "    with open(file_path, 'wb') as file: \n",
    "        pickle.dump([encoded_speaker_list, ranges], file) \n",
    "#     pickle.dump([encoded_speaker_list, ranges], open('data/dump/speaker_encoder.pkl')) \n",
    "else: \n",
    "    file = open('data/dump/speaker_encoder.pkl',  \"rb\") \n",
    "    encoded_speaker_list = pickle.load(file) \n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86604bb2",
   "metadata": {},
   "source": [
    "I may be wrong but this shows which speaker is talking? Speaker 1 or 2? @Elijah please help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6c026c6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42    1\n",
       "43    1\n",
       "44    1\n",
       "45    1\n",
       "46    1\n",
       "47    1\n",
       "48    0\n",
       "Name: Speaker, dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_speaker_list[0][4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53400cc5",
   "metadata": {},
   "source": [
    "To check if there are 2 speakers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fa2f5daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for range_pair in ranges: \n",
    "#     start_idx, end_idx = range_pair \n",
    "#     speaker_per_dialog = X_train[['Dialogue_ID','Speaker']][start_idx:end_idx+1].copy() \n",
    "#     speaker_feature = set(speaker_per_dialog[\"Speaker\"])\n",
    "#     print(start_idx, end_idx ,speaker_feature)\n",
    "#     print(list(speaker_per_dialog[\"Dialogue_ID\"]))\n",
    "#     speaker_encoder = {feature: i for i, feature in enumerate(speaker_feature)} \n",
    "#     speaker_decoder = {i: feature for i, feature in enumerate(speaker_feature)} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fd6c294c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoded_speaker_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d24aafaa",
   "metadata": {},
   "source": [
    "# Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c95bc3fe",
   "metadata": {},
   "source": [
    "Flatten out updated_representation. Currently they are divided per ranges. We want them flatten out so that len(updated_representation) = len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4212181d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12840, 300])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flattened_representation = torch.cat(updated_representations, dim=0)\n",
    "flattened_representation.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5b783ac8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12840"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f9f993f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1207,  0.2335, -0.3596,  ...,  0.0478,  0.0169,  0.0097],\n",
       "        [ 0.0687,  0.0382, -0.1634,  ...,  0.0445,  0.0121,  0.0091],\n",
       "        [ 0.0600, -0.0379, -0.0687,  ...,  0.0462,  0.0148,  0.0130],\n",
       "        ...,\n",
       "        [ 0.0562, -0.0685, -0.0008,  ...,  0.0221,  0.1638,  0.1174],\n",
       "        [ 0.0610, -0.0635,  0.0052,  ...,  0.0314,  0.1855,  0.2346],\n",
       "        [ 0.0559, -0.0667,  0.0065,  ...,  0.0409,  0.2184,  0.3835]],\n",
       "       grad_fn=<CatBackward0>)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flattened_representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2e5b08d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Dialogue_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12835</th>\n",
       "      <td>5</td>\n",
       "      <td>2159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12836</th>\n",
       "      <td>5</td>\n",
       "      <td>2159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12837</th>\n",
       "      <td>2</td>\n",
       "      <td>2159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12838</th>\n",
       "      <td>6</td>\n",
       "      <td>2159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12839</th>\n",
       "      <td>3</td>\n",
       "      <td>2159</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12840 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Emotion  Dialogue_ID\n",
       "0            6            0\n",
       "1            6            0\n",
       "2            6            0\n",
       "3            6            0\n",
       "4            2            0\n",
       "...        ...          ...\n",
       "12835        5         2159\n",
       "12836        5         2159\n",
       "12837        2         2159\n",
       "12838        6         2159\n",
       "12839        3         2159\n",
       "\n",
       "[12840 rows x 2 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c240fb22",
   "metadata": {},
   "source": [
    "This is just here to make sure they have the same length. If it is not the same check please delete the necessary files in embed/ or dump/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8aacf07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert flattened_representation.shape[0] == len(y_train), \"The flattened representation must have the same length as y_train.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f56b503f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB # Gaussian Naive Bayes\n",
    "from sklearn.svm import SVC  # Support Vector Classifier\n",
    "from sklearn.ensemble import RandomForestClassifier # Random Forest Classifier\n",
    "import xgboost as xgb # Gradient Boosting Machines\n",
    "from sklearn.neighbors import KNeighborsClassifier # KNN\n",
    "from sklearn.linear_model import LogisticRegression # Logistic Regression\n",
    "from sklearn.tree import DecisionTreeClassifier # Decision Trees\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# For the fully connected layers\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ad54e71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = flattened_representation.detach().numpy()  # Detach and then convert to NumPy array\n",
    "y = np.array(y_train['Emotion'])  \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db6ec1d",
   "metadata": {},
   "source": [
    "### Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "75e95135",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.12071651090342679\n",
      "Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.03      0.51      0.06        70\n",
      "           1       0.12      0.12      0.12       269\n",
      "           2       0.00      0.00      0.00       297\n",
      "           3       0.20      0.20      0.20       476\n",
      "           4       0.00      0.00      0.00       173\n",
      "           5       0.05      0.26      0.08        78\n",
      "           6       0.49      0.11      0.18      1205\n",
      "\n",
      "    accuracy                           0.12      2568\n",
      "   macro avg       0.13      0.17      0.09      2568\n",
      "weighted avg       0.28      0.12      0.14      2568\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Initialize and train the Gaussian Naive Bayes classifier\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = gnb.predict(X_test)\n",
    "\n",
    "# Evaluate the classifier\n",
    "print(\"Accuracy: \", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report: \")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "27b68fa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:  {'var_smoothing': 1.0}\n",
      "Best Score:  0.24601364141417728\n",
      "Accuracy on Test Set:  0.2340342679127726\n",
      "Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.03      0.19      0.06        70\n",
      "           1       0.11      0.42      0.18       269\n",
      "           2       0.00      0.00      0.00       297\n",
      "           3       0.22      0.10      0.14       476\n",
      "           4       0.00      0.00      0.00       173\n",
      "           5       0.05      0.04      0.05        78\n",
      "           6       0.47      0.35      0.40      1205\n",
      "\n",
      "    accuracy                           0.23      2568\n",
      "   macro avg       0.13      0.16      0.12      2568\n",
      "weighted avg       0.27      0.23      0.24      2568\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Initialize the Gaussian Naive Bayes classifier\n",
    "gnb = GaussianNB()\n",
    "\n",
    "# Define the parameter grid for 'var_smoothing'\n",
    "param_grid = {'var_smoothing': np.logspace(0,-9, num=100)}\n",
    "\n",
    "# Initialize the GridSearchCV object with GaussianNB classifier and the parameter grid\n",
    "grid_search = GridSearchCV(estimator=gnb, param_grid=param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "# Fit the model with the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters and the best score\n",
    "print(\"Best Parameters: \", grid_search.best_params_)\n",
    "print(\"Best Score: \", grid_search.best_score_)\n",
    "\n",
    "# Predict on the test set with the best parameters\n",
    "y_pred = grid_search.predict(X_test)\n",
    "\n",
    "# Evaluate the classifier with the best parameters\n",
    "print(\"Accuracy on Test Set: \", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report: \")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61fa0679",
   "metadata": {},
   "source": [
    "### Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b946cb00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4692367601246106\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        70\n",
      "           1       0.00      0.00      0.00       269\n",
      "           2       0.00      0.00      0.00       297\n",
      "           3       0.00      0.00      0.00       476\n",
      "           4       0.00      0.00      0.00       173\n",
      "           5       0.00      0.00      0.00        78\n",
      "           6       0.47      1.00      0.64      1205\n",
      "\n",
      "    accuracy                           0.47      2568\n",
      "   macro avg       0.07      0.14      0.09      2568\n",
      "weighted avg       0.22      0.47      0.30      2568\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Initialize the SVM classifier\n",
    "# The default kernel for SVC is 'rbf' (Radial Basis Function), but you can experiment with other kernels like 'linear', 'poly', etc.\n",
    "svm = SVC(kernel='rbf', C=1.0, random_state=42)  # C is the regularization parameter\n",
    "\n",
    "# Train the classifier\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = svm.predict(X_test)\n",
    "\n",
    "# Evaluate the classifier\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "62cc1433",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 96 candidates, totalling 480 fits\n",
      "[CV] END ...........C=0.1, degree=2, gamma=scale, kernel=rbf; total time=   9.7s\n",
      "[CV] END ...........C=0.1, degree=2, gamma=scale, kernel=rbf; total time=   8.5s\n",
      "[CV] END ...........C=0.1, degree=2, gamma=scale, kernel=rbf; total time=   8.8s\n",
      "[CV] END ...........C=0.1, degree=2, gamma=scale, kernel=rbf; total time=   8.4s\n",
      "[CV] END ...........C=0.1, degree=2, gamma=scale, kernel=rbf; total time=   8.5s\n",
      "[CV] END ........C=0.1, degree=2, gamma=scale, kernel=linear; total time=   7.0s\n",
      "[CV] END ........C=0.1, degree=2, gamma=scale, kernel=linear; total time=   7.0s\n",
      "[CV] END ........C=0.1, degree=2, gamma=scale, kernel=linear; total time=   7.0s\n",
      "[CV] END ........C=0.1, degree=2, gamma=scale, kernel=linear; total time=   6.9s\n",
      "[CV] END ........C=0.1, degree=2, gamma=scale, kernel=linear; total time=   7.0s\n",
      "[CV] END ..........C=0.1, degree=2, gamma=scale, kernel=poly; total time=   7.5s\n",
      "[CV] END ..........C=0.1, degree=2, gamma=scale, kernel=poly; total time=  10.3s\n",
      "[CV] END ..........C=0.1, degree=2, gamma=scale, kernel=poly; total time=  10.6s\n",
      "[CV] END ..........C=0.1, degree=2, gamma=scale, kernel=poly; total time=  10.3s\n",
      "[CV] END ..........C=0.1, degree=2, gamma=scale, kernel=poly; total time=   9.8s\n",
      "[CV] END .......C=0.1, degree=2, gamma=scale, kernel=sigmoid; total time=  11.5s\n",
      "[CV] END .......C=0.1, degree=2, gamma=scale, kernel=sigmoid; total time=  10.5s\n",
      "[CV] END .......C=0.1, degree=2, gamma=scale, kernel=sigmoid; total time=  10.3s\n",
      "[CV] END .......C=0.1, degree=2, gamma=scale, kernel=sigmoid; total time=   9.9s\n",
      "[CV] END .......C=0.1, degree=2, gamma=scale, kernel=sigmoid; total time=   9.0s\n",
      "[CV] END ............C=0.1, degree=2, gamma=auto, kernel=rbf; total time=   9.9s\n",
      "[CV] END ............C=0.1, degree=2, gamma=auto, kernel=rbf; total time=  10.4s\n",
      "[CV] END ............C=0.1, degree=2, gamma=auto, kernel=rbf; total time=  10.9s\n",
      "[CV] END ............C=0.1, degree=2, gamma=auto, kernel=rbf; total time=  10.7s\n",
      "[CV] END ............C=0.1, degree=2, gamma=auto, kernel=rbf; total time=  10.0s\n",
      "[CV] END .........C=0.1, degree=2, gamma=auto, kernel=linear; total time=   9.4s\n",
      "[CV] END .........C=0.1, degree=2, gamma=auto, kernel=linear; total time=   7.9s\n",
      "[CV] END .........C=0.1, degree=2, gamma=auto, kernel=linear; total time=   9.7s\n",
      "[CV] END .........C=0.1, degree=2, gamma=auto, kernel=linear; total time=  10.0s\n",
      "[CV] END .........C=0.1, degree=2, gamma=auto, kernel=linear; total time=   9.5s\n",
      "[CV] END ...........C=0.1, degree=2, gamma=auto, kernel=poly; total time=   8.9s\n",
      "[CV] END ...........C=0.1, degree=2, gamma=auto, kernel=poly; total time=   7.1s\n",
      "[CV] END ...........C=0.1, degree=2, gamma=auto, kernel=poly; total time=   7.8s\n",
      "[CV] END ...........C=0.1, degree=2, gamma=auto, kernel=poly; total time=   7.1s\n",
      "[CV] END ...........C=0.1, degree=2, gamma=auto, kernel=poly; total time=   7.8s\n",
      "[CV] END ........C=0.1, degree=2, gamma=auto, kernel=sigmoid; total time=   7.0s\n",
      "[CV] END ........C=0.1, degree=2, gamma=auto, kernel=sigmoid; total time=   7.0s\n",
      "[CV] END ........C=0.1, degree=2, gamma=auto, kernel=sigmoid; total time=   7.0s\n",
      "[CV] END ........C=0.1, degree=2, gamma=auto, kernel=sigmoid; total time=   7.1s\n",
      "[CV] END ........C=0.1, degree=2, gamma=auto, kernel=sigmoid; total time=   6.6s\n",
      "[CV] END ...........C=0.1, degree=3, gamma=scale, kernel=rbf; total time=   9.6s\n",
      "[CV] END ...........C=0.1, degree=3, gamma=scale, kernel=rbf; total time=   9.9s\n",
      "[CV] END ...........C=0.1, degree=3, gamma=scale, kernel=rbf; total time=  10.6s\n",
      "[CV] END ...........C=0.1, degree=3, gamma=scale, kernel=rbf; total time=  10.2s\n",
      "[CV] END ...........C=0.1, degree=3, gamma=scale, kernel=rbf; total time=   9.3s\n",
      "[CV] END ........C=0.1, degree=3, gamma=scale, kernel=linear; total time=   9.7s\n",
      "[CV] END ........C=0.1, degree=3, gamma=scale, kernel=linear; total time=   9.0s\n",
      "[CV] END ........C=0.1, degree=3, gamma=scale, kernel=linear; total time=   7.7s\n",
      "[CV] END ........C=0.1, degree=3, gamma=scale, kernel=linear; total time=   7.6s\n",
      "[CV] END ........C=0.1, degree=3, gamma=scale, kernel=linear; total time=   7.6s\n",
      "[CV] END ..........C=0.1, degree=3, gamma=scale, kernel=poly; total time=   7.7s\n",
      "[CV] END ..........C=0.1, degree=3, gamma=scale, kernel=poly; total time=   7.8s\n",
      "[CV] END ..........C=0.1, degree=3, gamma=scale, kernel=poly; total time=   7.7s\n",
      "[CV] END ..........C=0.1, degree=3, gamma=scale, kernel=poly; total time=   8.9s\n",
      "[CV] END ..........C=0.1, degree=3, gamma=scale, kernel=poly; total time=  10.3s\n",
      "[CV] END .......C=0.1, degree=3, gamma=scale, kernel=sigmoid; total time=  11.4s\n",
      "[CV] END .......C=0.1, degree=3, gamma=scale, kernel=sigmoid; total time=   9.5s\n",
      "[CV] END .......C=0.1, degree=3, gamma=scale, kernel=sigmoid; total time=  10.2s\n",
      "[CV] END .......C=0.1, degree=3, gamma=scale, kernel=sigmoid; total time=  11.3s\n",
      "[CV] END .......C=0.1, degree=3, gamma=scale, kernel=sigmoid; total time=   9.2s\n",
      "[CV] END ............C=0.1, degree=3, gamma=auto, kernel=rbf; total time=   8.8s\n",
      "[CV] END ............C=0.1, degree=3, gamma=auto, kernel=rbf; total time=   9.0s\n",
      "[CV] END ............C=0.1, degree=3, gamma=auto, kernel=rbf; total time=   9.3s\n",
      "[CV] END ............C=0.1, degree=3, gamma=auto, kernel=rbf; total time=   9.2s\n",
      "[CV] END ............C=0.1, degree=3, gamma=auto, kernel=rbf; total time=   9.2s\n",
      "[CV] END .........C=0.1, degree=3, gamma=auto, kernel=linear; total time=   8.3s\n",
      "[CV] END .........C=0.1, degree=3, gamma=auto, kernel=linear; total time=   8.5s\n",
      "[CV] END .........C=0.1, degree=3, gamma=auto, kernel=linear; total time=   7.9s\n",
      "[CV] END .........C=0.1, degree=3, gamma=auto, kernel=linear; total time=   8.1s\n",
      "[CV] END .........C=0.1, degree=3, gamma=auto, kernel=linear; total time=   8.2s\n",
      "[CV] END ...........C=0.1, degree=3, gamma=auto, kernel=poly; total time=   6.7s\n",
      "[CV] END ...........C=0.1, degree=3, gamma=auto, kernel=poly; total time=   6.7s\n",
      "[CV] END ...........C=0.1, degree=3, gamma=auto, kernel=poly; total time=   7.3s\n",
      "[CV] END ...........C=0.1, degree=3, gamma=auto, kernel=poly; total time=   8.2s\n",
      "[CV] END ...........C=0.1, degree=3, gamma=auto, kernel=poly; total time=   7.7s\n",
      "[CV] END ........C=0.1, degree=3, gamma=auto, kernel=sigmoid; total time=   7.8s\n",
      "[CV] END ........C=0.1, degree=3, gamma=auto, kernel=sigmoid; total time=   7.3s\n",
      "[CV] END ........C=0.1, degree=3, gamma=auto, kernel=sigmoid; total time=   7.0s\n",
      "[CV] END ........C=0.1, degree=3, gamma=auto, kernel=sigmoid; total time=   7.3s\n",
      "[CV] END ........C=0.1, degree=3, gamma=auto, kernel=sigmoid; total time=   8.9s\n",
      "[CV] END ...........C=0.1, degree=4, gamma=scale, kernel=rbf; total time=  12.6s\n",
      "[CV] END ...........C=0.1, degree=4, gamma=scale, kernel=rbf; total time=  11.1s\n",
      "[CV] END ...........C=0.1, degree=4, gamma=scale, kernel=rbf; total time=  11.4s\n",
      "[CV] END ...........C=0.1, degree=4, gamma=scale, kernel=rbf; total time=   9.5s\n",
      "[CV] END ...........C=0.1, degree=4, gamma=scale, kernel=rbf; total time=  10.4s\n",
      "[CV] END ........C=0.1, degree=4, gamma=scale, kernel=linear; total time=   8.3s\n",
      "[CV] END ........C=0.1, degree=4, gamma=scale, kernel=linear; total time=  10.2s\n",
      "[CV] END ........C=0.1, degree=4, gamma=scale, kernel=linear; total time=   9.0s\n",
      "[CV] END ........C=0.1, degree=4, gamma=scale, kernel=linear; total time=  10.8s\n",
      "[CV] END ........C=0.1, degree=4, gamma=scale, kernel=linear; total time=  10.7s\n",
      "[CV] END ..........C=0.1, degree=4, gamma=scale, kernel=poly; total time=   9.0s\n",
      "[CV] END ..........C=0.1, degree=4, gamma=scale, kernel=poly; total time=  10.1s\n",
      "[CV] END ..........C=0.1, degree=4, gamma=scale, kernel=poly; total time=   9.9s\n",
      "[CV] END ..........C=0.1, degree=4, gamma=scale, kernel=poly; total time=  10.4s\n",
      "[CV] END ..........C=0.1, degree=4, gamma=scale, kernel=poly; total time=   9.0s\n",
      "[CV] END .......C=0.1, degree=4, gamma=scale, kernel=sigmoid; total time=  11.3s\n",
      "[CV] END .......C=0.1, degree=4, gamma=scale, kernel=sigmoid; total time=  10.7s\n",
      "[CV] END .......C=0.1, degree=4, gamma=scale, kernel=sigmoid; total time=  11.8s\n",
      "[CV] END .......C=0.1, degree=4, gamma=scale, kernel=sigmoid; total time=   9.9s\n",
      "[CV] END .......C=0.1, degree=4, gamma=scale, kernel=sigmoid; total time=  12.5s\n",
      "[CV] END ............C=0.1, degree=4, gamma=auto, kernel=rbf; total time=   9.2s\n",
      "[CV] END ............C=0.1, degree=4, gamma=auto, kernel=rbf; total time=  10.1s\n",
      "[CV] END ............C=0.1, degree=4, gamma=auto, kernel=rbf; total time=   9.2s\n",
      "[CV] END ............C=0.1, degree=4, gamma=auto, kernel=rbf; total time=   9.7s\n",
      "[CV] END ............C=0.1, degree=4, gamma=auto, kernel=rbf; total time=   9.2s\n",
      "[CV] END .........C=0.1, degree=4, gamma=auto, kernel=linear; total time=   9.0s\n",
      "[CV] END .........C=0.1, degree=4, gamma=auto, kernel=linear; total time=   8.5s\n",
      "[CV] END .........C=0.1, degree=4, gamma=auto, kernel=linear; total time=   8.7s\n",
      "[CV] END .........C=0.1, degree=4, gamma=auto, kernel=linear; total time=   9.4s\n",
      "[CV] END .........C=0.1, degree=4, gamma=auto, kernel=linear; total time=   8.2s\n",
      "[CV] END ...........C=0.1, degree=4, gamma=auto, kernel=poly; total time=   7.6s\n",
      "[CV] END ...........C=0.1, degree=4, gamma=auto, kernel=poly; total time=   7.0s\n",
      "[CV] END ...........C=0.1, degree=4, gamma=auto, kernel=poly; total time=   7.5s\n",
      "[CV] END ...........C=0.1, degree=4, gamma=auto, kernel=poly; total time=   8.0s\n",
      "[CV] END ...........C=0.1, degree=4, gamma=auto, kernel=poly; total time=   8.1s\n",
      "[CV] END ........C=0.1, degree=4, gamma=auto, kernel=sigmoid; total time=   7.5s\n",
      "[CV] END ........C=0.1, degree=4, gamma=auto, kernel=sigmoid; total time=   7.4s\n",
      "[CV] END ........C=0.1, degree=4, gamma=auto, kernel=sigmoid; total time=   6.8s\n",
      "[CV] END ........C=0.1, degree=4, gamma=auto, kernel=sigmoid; total time=   6.9s\n",
      "[CV] END ........C=0.1, degree=4, gamma=auto, kernel=sigmoid; total time=   6.7s\n",
      "[CV] END .............C=1, degree=2, gamma=scale, kernel=rbf; total time=  12.0s\n",
      "[CV] END .............C=1, degree=2, gamma=scale, kernel=rbf; total time=  11.9s\n",
      "[CV] END .............C=1, degree=2, gamma=scale, kernel=rbf; total time=  11.5s\n",
      "[CV] END .............C=1, degree=2, gamma=scale, kernel=rbf; total time=  12.2s\n",
      "[CV] END .............C=1, degree=2, gamma=scale, kernel=rbf; total time=  11.5s\n",
      "[CV] END ..........C=1, degree=2, gamma=scale, kernel=linear; total time=   9.9s\n",
      "[CV] END ..........C=1, degree=2, gamma=scale, kernel=linear; total time=  10.2s\n",
      "[CV] END ..........C=1, degree=2, gamma=scale, kernel=linear; total time=   9.8s\n",
      "[CV] END ..........C=1, degree=2, gamma=scale, kernel=linear; total time=   9.8s\n",
      "[CV] END ..........C=1, degree=2, gamma=scale, kernel=linear; total time=  10.3s\n",
      "[CV] END ............C=1, degree=2, gamma=scale, kernel=poly; total time=  10.4s\n",
      "[CV] END ............C=1, degree=2, gamma=scale, kernel=poly; total time=  10.6s\n",
      "[CV] END ............C=1, degree=2, gamma=scale, kernel=poly; total time=  10.1s\n",
      "[CV] END ............C=1, degree=2, gamma=scale, kernel=poly; total time=   9.9s\n",
      "[CV] END ............C=1, degree=2, gamma=scale, kernel=poly; total time=  10.0s\n",
      "[CV] END .........C=1, degree=2, gamma=scale, kernel=sigmoid; total time=   9.5s\n",
      "[CV] END .........C=1, degree=2, gamma=scale, kernel=sigmoid; total time=  12.2s\n",
      "[CV] END .........C=1, degree=2, gamma=scale, kernel=sigmoid; total time=   8.4s\n",
      "[CV] END .........C=1, degree=2, gamma=scale, kernel=sigmoid; total time=  10.1s\n",
      "[CV] END .........C=1, degree=2, gamma=scale, kernel=sigmoid; total time=   9.9s\n",
      "[CV] END ..............C=1, degree=2, gamma=auto, kernel=rbf; total time=   9.8s\n",
      "[CV] END ..............C=1, degree=2, gamma=auto, kernel=rbf; total time=  11.0s\n",
      "[CV] END ..............C=1, degree=2, gamma=auto, kernel=rbf; total time=  10.6s\n",
      "[CV] END ..............C=1, degree=2, gamma=auto, kernel=rbf; total time=   9.9s\n",
      "[CV] END ..............C=1, degree=2, gamma=auto, kernel=rbf; total time=  10.5s\n",
      "[CV] END ...........C=1, degree=2, gamma=auto, kernel=linear; total time=  10.4s\n",
      "[CV] END ...........C=1, degree=2, gamma=auto, kernel=linear; total time=  12.3s\n",
      "[CV] END ...........C=1, degree=2, gamma=auto, kernel=linear; total time=  11.0s\n",
      "[CV] END ...........C=1, degree=2, gamma=auto, kernel=linear; total time=  11.3s\n",
      "[CV] END ...........C=1, degree=2, gamma=auto, kernel=linear; total time=  10.6s\n",
      "[CV] END .............C=1, degree=2, gamma=auto, kernel=poly; total time=   8.3s\n",
      "[CV] END .............C=1, degree=2, gamma=auto, kernel=poly; total time=   7.4s\n",
      "[CV] END .............C=1, degree=2, gamma=auto, kernel=poly; total time=   7.3s\n",
      "[CV] END .............C=1, degree=2, gamma=auto, kernel=poly; total time=   6.9s\n",
      "[CV] END .............C=1, degree=2, gamma=auto, kernel=poly; total time=   7.0s\n",
      "[CV] END ..........C=1, degree=2, gamma=auto, kernel=sigmoid; total time=   7.8s\n",
      "[CV] END ..........C=1, degree=2, gamma=auto, kernel=sigmoid; total time=   7.7s\n",
      "[CV] END ..........C=1, degree=2, gamma=auto, kernel=sigmoid; total time=   8.8s\n",
      "[CV] END ..........C=1, degree=2, gamma=auto, kernel=sigmoid; total time=   8.1s\n",
      "[CV] END ..........C=1, degree=2, gamma=auto, kernel=sigmoid; total time=   9.1s\n",
      "[CV] END .............C=1, degree=3, gamma=scale, kernel=rbf; total time=  12.8s\n",
      "[CV] END .............C=1, degree=3, gamma=scale, kernel=rbf; total time=  11.7s\n",
      "[CV] END .............C=1, degree=3, gamma=scale, kernel=rbf; total time=  12.1s\n",
      "[CV] END .............C=1, degree=3, gamma=scale, kernel=rbf; total time=  12.1s\n",
      "[CV] END .............C=1, degree=3, gamma=scale, kernel=rbf; total time=  12.6s\n",
      "[CV] END ..........C=1, degree=3, gamma=scale, kernel=linear; total time=  10.1s\n",
      "[CV] END ..........C=1, degree=3, gamma=scale, kernel=linear; total time=  10.7s\n",
      "[CV] END ..........C=1, degree=3, gamma=scale, kernel=linear; total time=  10.1s\n",
      "[CV] END ..........C=1, degree=3, gamma=scale, kernel=linear; total time=   9.9s\n",
      "[CV] END ..........C=1, degree=3, gamma=scale, kernel=linear; total time=   9.8s\n",
      "[CV] END ............C=1, degree=3, gamma=scale, kernel=poly; total time=  10.2s\n",
      "[CV] END ............C=1, degree=3, gamma=scale, kernel=poly; total time=  11.8s\n",
      "[CV] END ............C=1, degree=3, gamma=scale, kernel=poly; total time=  11.1s\n",
      "[CV] END ............C=1, degree=3, gamma=scale, kernel=poly; total time=  11.7s\n",
      "[CV] END ............C=1, degree=3, gamma=scale, kernel=poly; total time=  11.5s\n",
      "[CV] END .........C=1, degree=3, gamma=scale, kernel=sigmoid; total time=   8.7s\n",
      "[CV] END .........C=1, degree=3, gamma=scale, kernel=sigmoid; total time=  10.3s\n",
      "[CV] END .........C=1, degree=3, gamma=scale, kernel=sigmoid; total time=  10.4s\n",
      "[CV] END .........C=1, degree=3, gamma=scale, kernel=sigmoid; total time=   9.9s\n",
      "[CV] END .........C=1, degree=3, gamma=scale, kernel=sigmoid; total time=   9.1s\n",
      "[CV] END ..............C=1, degree=3, gamma=auto, kernel=rbf; total time=  10.5s\n",
      "[CV] END ..............C=1, degree=3, gamma=auto, kernel=rbf; total time=  11.6s\n",
      "[CV] END ..............C=1, degree=3, gamma=auto, kernel=rbf; total time=   9.6s\n",
      "[CV] END ..............C=1, degree=3, gamma=auto, kernel=rbf; total time=  10.2s\n",
      "[CV] END ..............C=1, degree=3, gamma=auto, kernel=rbf; total time=  10.1s\n",
      "[CV] END ...........C=1, degree=3, gamma=auto, kernel=linear; total time=  10.4s\n",
      "[CV] END ...........C=1, degree=3, gamma=auto, kernel=linear; total time=   9.7s\n",
      "[CV] END ...........C=1, degree=3, gamma=auto, kernel=linear; total time=  10.3s\n",
      "[CV] END ...........C=1, degree=3, gamma=auto, kernel=linear; total time=   9.9s\n",
      "[CV] END ...........C=1, degree=3, gamma=auto, kernel=linear; total time=  10.2s\n",
      "[CV] END .............C=1, degree=3, gamma=auto, kernel=poly; total time=   6.9s\n",
      "[CV] END .............C=1, degree=3, gamma=auto, kernel=poly; total time=   7.1s\n",
      "[CV] END .............C=1, degree=3, gamma=auto, kernel=poly; total time=   7.0s\n",
      "[CV] END .............C=1, degree=3, gamma=auto, kernel=poly; total time=   7.6s\n",
      "[CV] END .............C=1, degree=3, gamma=auto, kernel=poly; total time=   7.7s\n",
      "[CV] END ..........C=1, degree=3, gamma=auto, kernel=sigmoid; total time=   7.4s\n",
      "[CV] END ..........C=1, degree=3, gamma=auto, kernel=sigmoid; total time=   7.5s\n",
      "[CV] END ..........C=1, degree=3, gamma=auto, kernel=sigmoid; total time=   7.8s\n",
      "[CV] END ..........C=1, degree=3, gamma=auto, kernel=sigmoid; total time=   7.1s\n",
      "[CV] END ..........C=1, degree=3, gamma=auto, kernel=sigmoid; total time=   7.0s\n",
      "[CV] END .............C=1, degree=4, gamma=scale, kernel=rbf; total time=  12.0s\n",
      "[CV] END .............C=1, degree=4, gamma=scale, kernel=rbf; total time=  11.2s\n",
      "[CV] END .............C=1, degree=4, gamma=scale, kernel=rbf; total time=  11.1s\n",
      "[CV] END .............C=1, degree=4, gamma=scale, kernel=rbf; total time=  11.1s\n",
      "[CV] END .............C=1, degree=4, gamma=scale, kernel=rbf; total time=  11.7s\n",
      "[CV] END ..........C=1, degree=4, gamma=scale, kernel=linear; total time=  10.8s\n",
      "[CV] END ..........C=1, degree=4, gamma=scale, kernel=linear; total time=   9.8s\n",
      "[CV] END ..........C=1, degree=4, gamma=scale, kernel=linear; total time=  10.3s\n",
      "[CV] END ..........C=1, degree=4, gamma=scale, kernel=linear; total time=  10.5s\n",
      "[CV] END ..........C=1, degree=4, gamma=scale, kernel=linear; total time=  10.1s\n",
      "[CV] END ............C=1, degree=4, gamma=scale, kernel=poly; total time=  10.9s\n",
      "[CV] END ............C=1, degree=4, gamma=scale, kernel=poly; total time=  10.4s\n",
      "[CV] END ............C=1, degree=4, gamma=scale, kernel=poly; total time=  11.3s\n",
      "[CV] END ............C=1, degree=4, gamma=scale, kernel=poly; total time=  10.3s\n",
      "[CV] END ............C=1, degree=4, gamma=scale, kernel=poly; total time=  10.7s\n",
      "[CV] END .........C=1, degree=4, gamma=scale, kernel=sigmoid; total time=   8.7s\n",
      "[CV] END .........C=1, degree=4, gamma=scale, kernel=sigmoid; total time=   9.6s\n",
      "[CV] END .........C=1, degree=4, gamma=scale, kernel=sigmoid; total time=   8.4s\n",
      "[CV] END .........C=1, degree=4, gamma=scale, kernel=sigmoid; total time=   9.4s\n",
      "[CV] END .........C=1, degree=4, gamma=scale, kernel=sigmoid; total time=  10.1s\n",
      "[CV] END ..............C=1, degree=4, gamma=auto, kernel=rbf; total time=  10.1s\n",
      "[CV] END ..............C=1, degree=4, gamma=auto, kernel=rbf; total time=  10.3s\n",
      "[CV] END ..............C=1, degree=4, gamma=auto, kernel=rbf; total time=  10.0s\n",
      "[CV] END ..............C=1, degree=4, gamma=auto, kernel=rbf; total time=   9.4s\n",
      "[CV] END ..............C=1, degree=4, gamma=auto, kernel=rbf; total time=  10.1s\n",
      "[CV] END ...........C=1, degree=4, gamma=auto, kernel=linear; total time=  10.8s\n",
      "[CV] END ...........C=1, degree=4, gamma=auto, kernel=linear; total time=  10.9s\n",
      "[CV] END ...........C=1, degree=4, gamma=auto, kernel=linear; total time=  11.2s\n",
      "[CV] END ...........C=1, degree=4, gamma=auto, kernel=linear; total time=   9.9s\n",
      "[CV] END ...........C=1, degree=4, gamma=auto, kernel=linear; total time=  11.5s\n",
      "[CV] END .............C=1, degree=4, gamma=auto, kernel=poly; total time=   6.4s\n",
      "[CV] END .............C=1, degree=4, gamma=auto, kernel=poly; total time=   6.6s\n",
      "[CV] END .............C=1, degree=4, gamma=auto, kernel=poly; total time=   6.5s\n",
      "[CV] END .............C=1, degree=4, gamma=auto, kernel=poly; total time=   5.9s\n",
      "[CV] END .............C=1, degree=4, gamma=auto, kernel=poly; total time=   6.8s\n",
      "[CV] END ..........C=1, degree=4, gamma=auto, kernel=sigmoid; total time=   6.4s\n",
      "[CV] END ..........C=1, degree=4, gamma=auto, kernel=sigmoid; total time=   6.4s\n",
      "[CV] END ..........C=1, degree=4, gamma=auto, kernel=sigmoid; total time=   6.3s\n",
      "[CV] END ..........C=1, degree=4, gamma=auto, kernel=sigmoid; total time=   6.3s\n",
      "[CV] END ..........C=1, degree=4, gamma=auto, kernel=sigmoid; total time=   6.3s\n",
      "[CV] END ............C=10, degree=2, gamma=scale, kernel=rbf; total time=  11.6s\n",
      "[CV] END ............C=10, degree=2, gamma=scale, kernel=rbf; total time=  11.3s\n",
      "[CV] END ............C=10, degree=2, gamma=scale, kernel=rbf; total time=  11.4s\n",
      "[CV] END ............C=10, degree=2, gamma=scale, kernel=rbf; total time=  11.3s\n",
      "[CV] END ............C=10, degree=2, gamma=scale, kernel=rbf; total time=  12.3s\n",
      "[CV] END .........C=10, degree=2, gamma=scale, kernel=linear; total time=  12.2s\n",
      "[CV] END .........C=10, degree=2, gamma=scale, kernel=linear; total time=  12.3s\n",
      "[CV] END .........C=10, degree=2, gamma=scale, kernel=linear; total time=  14.9s\n",
      "[CV] END .........C=10, degree=2, gamma=scale, kernel=linear; total time=  16.5s\n",
      "[CV] END .........C=10, degree=2, gamma=scale, kernel=linear; total time=  15.6s\n",
      "[CV] END ...........C=10, degree=2, gamma=scale, kernel=poly; total time=  11.5s\n",
      "[CV] END ...........C=10, degree=2, gamma=scale, kernel=poly; total time=  11.3s\n",
      "[CV] END ...........C=10, degree=2, gamma=scale, kernel=poly; total time=  11.0s\n",
      "[CV] END ...........C=10, degree=2, gamma=scale, kernel=poly; total time=  11.6s\n",
      "[CV] END ...........C=10, degree=2, gamma=scale, kernel=poly; total time=  12.3s\n",
      "[CV] END ........C=10, degree=2, gamma=scale, kernel=sigmoid; total time=   7.4s\n",
      "[CV] END ........C=10, degree=2, gamma=scale, kernel=sigmoid; total time=   7.5s\n",
      "[CV] END ........C=10, degree=2, gamma=scale, kernel=sigmoid; total time=   7.4s\n",
      "[CV] END ........C=10, degree=2, gamma=scale, kernel=sigmoid; total time=   7.6s\n",
      "[CV] END ........C=10, degree=2, gamma=scale, kernel=sigmoid; total time=   8.0s\n",
      "[CV] END .............C=10, degree=2, gamma=auto, kernel=rbf; total time=  10.7s\n",
      "[CV] END .............C=10, degree=2, gamma=auto, kernel=rbf; total time=  11.4s\n",
      "[CV] END .............C=10, degree=2, gamma=auto, kernel=rbf; total time=  10.7s\n",
      "[CV] END .............C=10, degree=2, gamma=auto, kernel=rbf; total time=  10.1s\n",
      "[CV] END .............C=10, degree=2, gamma=auto, kernel=rbf; total time=  10.7s\n",
      "[CV] END ..........C=10, degree=2, gamma=auto, kernel=linear; total time=  13.8s\n",
      "[CV] END ..........C=10, degree=2, gamma=auto, kernel=linear; total time=  13.0s\n",
      "[CV] END ..........C=10, degree=2, gamma=auto, kernel=linear; total time=  13.4s\n",
      "[CV] END ..........C=10, degree=2, gamma=auto, kernel=linear; total time=  13.8s\n",
      "[CV] END ..........C=10, degree=2, gamma=auto, kernel=linear; total time=  14.4s\n",
      "[CV] END ............C=10, degree=2, gamma=auto, kernel=poly; total time=   7.3s\n",
      "[CV] END ............C=10, degree=2, gamma=auto, kernel=poly; total time=   7.4s\n",
      "[CV] END ............C=10, degree=2, gamma=auto, kernel=poly; total time=   7.5s\n",
      "[CV] END ............C=10, degree=2, gamma=auto, kernel=poly; total time=   7.4s\n",
      "[CV] END ............C=10, degree=2, gamma=auto, kernel=poly; total time=   7.2s\n",
      "[CV] END .........C=10, degree=2, gamma=auto, kernel=sigmoid; total time=   7.6s\n",
      "[CV] END .........C=10, degree=2, gamma=auto, kernel=sigmoid; total time=   7.9s\n",
      "[CV] END .........C=10, degree=2, gamma=auto, kernel=sigmoid; total time=   8.0s\n",
      "[CV] END .........C=10, degree=2, gamma=auto, kernel=sigmoid; total time=   7.5s\n",
      "[CV] END .........C=10, degree=2, gamma=auto, kernel=sigmoid; total time=   8.1s\n",
      "[CV] END ............C=10, degree=3, gamma=scale, kernel=rbf; total time=  14.4s\n",
      "[CV] END ............C=10, degree=3, gamma=scale, kernel=rbf; total time=  13.3s\n",
      "[CV] END ............C=10, degree=3, gamma=scale, kernel=rbf; total time=  13.1s\n",
      "[CV] END ............C=10, degree=3, gamma=scale, kernel=rbf; total time=  15.4s\n",
      "[CV] END ............C=10, degree=3, gamma=scale, kernel=rbf; total time=  14.2s\n",
      "[CV] END .........C=10, degree=3, gamma=scale, kernel=linear; total time=  15.4s\n",
      "[CV] END .........C=10, degree=3, gamma=scale, kernel=linear; total time=  13.7s\n",
      "[CV] END .........C=10, degree=3, gamma=scale, kernel=linear; total time=  14.7s\n",
      "[CV] END .........C=10, degree=3, gamma=scale, kernel=linear; total time=  15.1s\n",
      "[CV] END .........C=10, degree=3, gamma=scale, kernel=linear; total time=  15.0s\n",
      "[CV] END ...........C=10, degree=3, gamma=scale, kernel=poly; total time=  12.5s\n",
      "[CV] END ...........C=10, degree=3, gamma=scale, kernel=poly; total time=  12.8s\n",
      "[CV] END ...........C=10, degree=3, gamma=scale, kernel=poly; total time=  12.6s\n",
      "[CV] END ...........C=10, degree=3, gamma=scale, kernel=poly; total time=  13.6s\n",
      "[CV] END ...........C=10, degree=3, gamma=scale, kernel=poly; total time=  13.5s\n",
      "[CV] END ........C=10, degree=3, gamma=scale, kernel=sigmoid; total time=   8.3s\n",
      "[CV] END ........C=10, degree=3, gamma=scale, kernel=sigmoid; total time=   9.1s\n",
      "[CV] END ........C=10, degree=3, gamma=scale, kernel=sigmoid; total time=   8.9s\n",
      "[CV] END ........C=10, degree=3, gamma=scale, kernel=sigmoid; total time=   7.8s\n",
      "[CV] END ........C=10, degree=3, gamma=scale, kernel=sigmoid; total time=   8.9s\n",
      "[CV] END .............C=10, degree=3, gamma=auto, kernel=rbf; total time=   9.9s\n",
      "[CV] END .............C=10, degree=3, gamma=auto, kernel=rbf; total time=  10.0s\n",
      "[CV] END .............C=10, degree=3, gamma=auto, kernel=rbf; total time=  10.2s\n",
      "[CV] END .............C=10, degree=3, gamma=auto, kernel=rbf; total time=   9.5s\n",
      "[CV] END .............C=10, degree=3, gamma=auto, kernel=rbf; total time=  10.5s\n",
      "[CV] END ..........C=10, degree=3, gamma=auto, kernel=linear; total time=  13.2s\n",
      "[CV] END ..........C=10, degree=3, gamma=auto, kernel=linear; total time=  13.9s\n",
      "[CV] END ..........C=10, degree=3, gamma=auto, kernel=linear; total time=  13.1s\n",
      "[CV] END ..........C=10, degree=3, gamma=auto, kernel=linear; total time=  13.7s\n",
      "[CV] END ..........C=10, degree=3, gamma=auto, kernel=linear; total time=  12.5s\n",
      "[CV] END ............C=10, degree=3, gamma=auto, kernel=poly; total time=   5.9s\n",
      "[CV] END ............C=10, degree=3, gamma=auto, kernel=poly; total time=   6.0s\n",
      "[CV] END ............C=10, degree=3, gamma=auto, kernel=poly; total time=   5.9s\n",
      "[CV] END ............C=10, degree=3, gamma=auto, kernel=poly; total time=   6.2s\n",
      "[CV] END ............C=10, degree=3, gamma=auto, kernel=poly; total time=   6.5s\n",
      "[CV] END .........C=10, degree=3, gamma=auto, kernel=sigmoid; total time=   8.3s\n",
      "[CV] END .........C=10, degree=3, gamma=auto, kernel=sigmoid; total time=   7.3s\n",
      "[CV] END .........C=10, degree=3, gamma=auto, kernel=sigmoid; total time=   6.8s\n",
      "[CV] END .........C=10, degree=3, gamma=auto, kernel=sigmoid; total time=   6.9s\n",
      "[CV] END .........C=10, degree=3, gamma=auto, kernel=sigmoid; total time=   6.9s\n",
      "[CV] END ............C=10, degree=4, gamma=scale, kernel=rbf; total time=  11.4s\n",
      "[CV] END ............C=10, degree=4, gamma=scale, kernel=rbf; total time=  11.6s\n",
      "[CV] END ............C=10, degree=4, gamma=scale, kernel=rbf; total time=  11.5s\n",
      "[CV] END ............C=10, degree=4, gamma=scale, kernel=rbf; total time=  11.7s\n",
      "[CV] END ............C=10, degree=4, gamma=scale, kernel=rbf; total time=  12.8s\n",
      "[CV] END .........C=10, degree=4, gamma=scale, kernel=linear; total time=  11.9s\n",
      "[CV] END .........C=10, degree=4, gamma=scale, kernel=linear; total time=  11.7s\n",
      "[CV] END .........C=10, degree=4, gamma=scale, kernel=linear; total time=  11.5s\n",
      "[CV] END .........C=10, degree=4, gamma=scale, kernel=linear; total time=  12.1s\n",
      "[CV] END .........C=10, degree=4, gamma=scale, kernel=linear; total time=  12.0s\n",
      "[CV] END ...........C=10, degree=4, gamma=scale, kernel=poly; total time=  10.2s\n",
      "[CV] END ...........C=10, degree=4, gamma=scale, kernel=poly; total time=  11.3s\n",
      "[CV] END ...........C=10, degree=4, gamma=scale, kernel=poly; total time=  11.4s\n",
      "[CV] END ...........C=10, degree=4, gamma=scale, kernel=poly; total time=  10.6s\n",
      "[CV] END ...........C=10, degree=4, gamma=scale, kernel=poly; total time=  10.5s\n",
      "[CV] END ........C=10, degree=4, gamma=scale, kernel=sigmoid; total time=   6.8s\n",
      "[CV] END ........C=10, degree=4, gamma=scale, kernel=sigmoid; total time=   6.9s\n",
      "[CV] END ........C=10, degree=4, gamma=scale, kernel=sigmoid; total time=   7.1s\n",
      "[CV] END ........C=10, degree=4, gamma=scale, kernel=sigmoid; total time=   6.9s\n",
      "[CV] END ........C=10, degree=4, gamma=scale, kernel=sigmoid; total time=   7.0s\n",
      "[CV] END .............C=10, degree=4, gamma=auto, kernel=rbf; total time=   8.8s\n",
      "[CV] END .............C=10, degree=4, gamma=auto, kernel=rbf; total time=   8.8s\n",
      "[CV] END .............C=10, degree=4, gamma=auto, kernel=rbf; total time=   8.8s\n",
      "[CV] END .............C=10, degree=4, gamma=auto, kernel=rbf; total time=   8.8s\n",
      "[CV] END .............C=10, degree=4, gamma=auto, kernel=rbf; total time=   8.8s\n",
      "[CV] END ..........C=10, degree=4, gamma=auto, kernel=linear; total time=  11.9s\n",
      "[CV] END ..........C=10, degree=4, gamma=auto, kernel=linear; total time=  11.8s\n",
      "[CV] END ..........C=10, degree=4, gamma=auto, kernel=linear; total time=  11.6s\n",
      "[CV] END ..........C=10, degree=4, gamma=auto, kernel=linear; total time=  12.1s\n",
      "[CV] END ..........C=10, degree=4, gamma=auto, kernel=linear; total time=  12.0s\n",
      "[CV] END ............C=10, degree=4, gamma=auto, kernel=poly; total time=   5.9s\n",
      "[CV] END ............C=10, degree=4, gamma=auto, kernel=poly; total time=   5.9s\n",
      "[CV] END ............C=10, degree=4, gamma=auto, kernel=poly; total time=   6.7s\n",
      "[CV] END ............C=10, degree=4, gamma=auto, kernel=poly; total time=   6.1s\n",
      "[CV] END ............C=10, degree=4, gamma=auto, kernel=poly; total time=   7.0s\n",
      "[CV] END .........C=10, degree=4, gamma=auto, kernel=sigmoid; total time=   6.8s\n",
      "[CV] END .........C=10, degree=4, gamma=auto, kernel=sigmoid; total time=   6.9s\n",
      "[CV] END .........C=10, degree=4, gamma=auto, kernel=sigmoid; total time=   6.8s\n",
      "[CV] END .........C=10, degree=4, gamma=auto, kernel=sigmoid; total time=   6.8s\n",
      "[CV] END .........C=10, degree=4, gamma=auto, kernel=sigmoid; total time=   6.8s\n",
      "[CV] END ...........C=100, degree=2, gamma=scale, kernel=rbf; total time=  12.2s\n",
      "[CV] END ...........C=100, degree=2, gamma=scale, kernel=rbf; total time=  12.0s\n",
      "[CV] END ...........C=100, degree=2, gamma=scale, kernel=rbf; total time=  12.2s\n",
      "[CV] END ...........C=100, degree=2, gamma=scale, kernel=rbf; total time=  12.2s\n",
      "[CV] END ...........C=100, degree=2, gamma=scale, kernel=rbf; total time=  12.2s\n",
      "[CV] END ........C=100, degree=2, gamma=scale, kernel=linear; total time=  22.6s\n",
      "[CV] END ........C=100, degree=2, gamma=scale, kernel=linear; total time=  21.8s\n",
      "[CV] END ........C=100, degree=2, gamma=scale, kernel=linear; total time=  22.5s\n",
      "[CV] END ........C=100, degree=2, gamma=scale, kernel=linear; total time=  24.6s\n",
      "[CV] END ........C=100, degree=2, gamma=scale, kernel=linear; total time=  22.7s\n",
      "[CV] END ..........C=100, degree=2, gamma=scale, kernel=poly; total time=  11.7s\n",
      "[CV] END ..........C=100, degree=2, gamma=scale, kernel=poly; total time=  11.5s\n",
      "[CV] END ..........C=100, degree=2, gamma=scale, kernel=poly; total time=  12.1s\n",
      "[CV] END ..........C=100, degree=2, gamma=scale, kernel=poly; total time=  11.8s\n",
      "[CV] END ..........C=100, degree=2, gamma=scale, kernel=poly; total time=  11.7s\n",
      "[CV] END .......C=100, degree=2, gamma=scale, kernel=sigmoid; total time=   6.8s\n",
      "[CV] END .......C=100, degree=2, gamma=scale, kernel=sigmoid; total time=   6.4s\n",
      "[CV] END .......C=100, degree=2, gamma=scale, kernel=sigmoid; total time=   6.6s\n",
      "[CV] END .......C=100, degree=2, gamma=scale, kernel=sigmoid; total time=   6.3s\n",
      "[CV] END .......C=100, degree=2, gamma=scale, kernel=sigmoid; total time=   6.5s\n",
      "[CV] END ............C=100, degree=2, gamma=auto, kernel=rbf; total time=  10.3s\n",
      "[CV] END ............C=100, degree=2, gamma=auto, kernel=rbf; total time=  10.3s\n",
      "[CV] END ............C=100, degree=2, gamma=auto, kernel=rbf; total time=  10.6s\n",
      "[CV] END ............C=100, degree=2, gamma=auto, kernel=rbf; total time=  10.1s\n",
      "[CV] END ............C=100, degree=2, gamma=auto, kernel=rbf; total time=  10.3s\n",
      "[CV] END .........C=100, degree=2, gamma=auto, kernel=linear; total time=  22.4s\n",
      "[CV] END .........C=100, degree=2, gamma=auto, kernel=linear; total time=  21.8s\n",
      "[CV] END .........C=100, degree=2, gamma=auto, kernel=linear; total time=  22.4s\n",
      "[CV] END .........C=100, degree=2, gamma=auto, kernel=linear; total time=  24.2s\n",
      "[CV] END .........C=100, degree=2, gamma=auto, kernel=linear; total time=  22.8s\n",
      "[CV] END ...........C=100, degree=2, gamma=auto, kernel=poly; total time=   6.3s\n",
      "[CV] END ...........C=100, degree=2, gamma=auto, kernel=poly; total time=   6.3s\n",
      "[CV] END ...........C=100, degree=2, gamma=auto, kernel=poly; total time=   6.2s\n",
      "[CV] END ...........C=100, degree=2, gamma=auto, kernel=poly; total time=   6.3s\n",
      "[CV] END ...........C=100, degree=2, gamma=auto, kernel=poly; total time=   6.4s\n",
      "[CV] END ........C=100, degree=2, gamma=auto, kernel=sigmoid; total time=   7.9s\n",
      "[CV] END ........C=100, degree=2, gamma=auto, kernel=sigmoid; total time=   8.4s\n",
      "[CV] END ........C=100, degree=2, gamma=auto, kernel=sigmoid; total time=   8.2s\n",
      "[CV] END ........C=100, degree=2, gamma=auto, kernel=sigmoid; total time=   8.0s\n",
      "[CV] END ........C=100, degree=2, gamma=auto, kernel=sigmoid; total time=   8.2s\n",
      "[CV] END ...........C=100, degree=3, gamma=scale, kernel=rbf; total time=  12.3s\n",
      "[CV] END ...........C=100, degree=3, gamma=scale, kernel=rbf; total time=  12.0s\n",
      "[CV] END ...........C=100, degree=3, gamma=scale, kernel=rbf; total time=  12.0s\n",
      "[CV] END ...........C=100, degree=3, gamma=scale, kernel=rbf; total time=  12.3s\n",
      "[CV] END ...........C=100, degree=3, gamma=scale, kernel=rbf; total time=  12.3s\n",
      "[CV] END ........C=100, degree=3, gamma=scale, kernel=linear; total time=  22.5s\n",
      "[CV] END ........C=100, degree=3, gamma=scale, kernel=linear; total time=  21.8s\n",
      "[CV] END ........C=100, degree=3, gamma=scale, kernel=linear; total time=  22.2s\n",
      "[CV] END ........C=100, degree=3, gamma=scale, kernel=linear; total time=  24.5s\n",
      "[CV] END ........C=100, degree=3, gamma=scale, kernel=linear; total time=  23.2s\n",
      "[CV] END ..........C=100, degree=3, gamma=scale, kernel=poly; total time=  12.3s\n",
      "[CV] END ..........C=100, degree=3, gamma=scale, kernel=poly; total time=  11.1s\n",
      "[CV] END ..........C=100, degree=3, gamma=scale, kernel=poly; total time=  11.6s\n",
      "[CV] END ..........C=100, degree=3, gamma=scale, kernel=poly; total time=  11.7s\n",
      "[CV] END ..........C=100, degree=3, gamma=scale, kernel=poly; total time=  11.8s\n",
      "[CV] END .......C=100, degree=3, gamma=scale, kernel=sigmoid; total time=   6.7s\n",
      "[CV] END .......C=100, degree=3, gamma=scale, kernel=sigmoid; total time=   6.6s\n",
      "[CV] END .......C=100, degree=3, gamma=scale, kernel=sigmoid; total time=   7.0s\n",
      "[CV] END .......C=100, degree=3, gamma=scale, kernel=sigmoid; total time=   6.2s\n",
      "[CV] END .......C=100, degree=3, gamma=scale, kernel=sigmoid; total time=   6.5s\n",
      "[CV] END ............C=100, degree=3, gamma=auto, kernel=rbf; total time=  10.3s\n",
      "[CV] END ............C=100, degree=3, gamma=auto, kernel=rbf; total time=  10.5s\n",
      "[CV] END ............C=100, degree=3, gamma=auto, kernel=rbf; total time=  10.4s\n",
      "[CV] END ............C=100, degree=3, gamma=auto, kernel=rbf; total time=  10.3s\n",
      "[CV] END ............C=100, degree=3, gamma=auto, kernel=rbf; total time=  10.3s\n",
      "[CV] END .........C=100, degree=3, gamma=auto, kernel=linear; total time=  22.6s\n",
      "[CV] END .........C=100, degree=3, gamma=auto, kernel=linear; total time=  21.7s\n",
      "[CV] END .........C=100, degree=3, gamma=auto, kernel=linear; total time=  22.1s\n",
      "[CV] END .........C=100, degree=3, gamma=auto, kernel=linear; total time=  24.2s\n",
      "[CV] END .........C=100, degree=3, gamma=auto, kernel=linear; total time=  22.7s\n",
      "[CV] END ...........C=100, degree=3, gamma=auto, kernel=poly; total time=   5.8s\n",
      "[CV] END ...........C=100, degree=3, gamma=auto, kernel=poly; total time=   5.9s\n",
      "[CV] END ...........C=100, degree=3, gamma=auto, kernel=poly; total time=   5.8s\n",
      "[CV] END ...........C=100, degree=3, gamma=auto, kernel=poly; total time=   5.8s\n",
      "[CV] END ...........C=100, degree=3, gamma=auto, kernel=poly; total time=   5.9s\n",
      "[CV] END ........C=100, degree=3, gamma=auto, kernel=sigmoid; total time=   8.1s\n",
      "[CV] END ........C=100, degree=3, gamma=auto, kernel=sigmoid; total time=   8.1s\n",
      "[CV] END ........C=100, degree=3, gamma=auto, kernel=sigmoid; total time=   7.9s\n",
      "[CV] END ........C=100, degree=3, gamma=auto, kernel=sigmoid; total time=   8.1s\n",
      "[CV] END ........C=100, degree=3, gamma=auto, kernel=sigmoid; total time=   8.1s\n",
      "[CV] END ...........C=100, degree=4, gamma=scale, kernel=rbf; total time=  12.0s\n",
      "[CV] END ...........C=100, degree=4, gamma=scale, kernel=rbf; total time=  11.8s\n",
      "[CV] END ...........C=100, degree=4, gamma=scale, kernel=rbf; total time=  12.0s\n",
      "[CV] END ...........C=100, degree=4, gamma=scale, kernel=rbf; total time=  12.2s\n",
      "[CV] END ...........C=100, degree=4, gamma=scale, kernel=rbf; total time=  12.1s\n",
      "[CV] END ........C=100, degree=4, gamma=scale, kernel=linear; total time=  22.5s\n",
      "[CV] END ........C=100, degree=4, gamma=scale, kernel=linear; total time=  21.8s\n",
      "[CV] END ........C=100, degree=4, gamma=scale, kernel=linear; total time=  22.3s\n",
      "[CV] END ........C=100, degree=4, gamma=scale, kernel=linear; total time=  24.1s\n",
      "[CV] END ........C=100, degree=4, gamma=scale, kernel=linear; total time=  22.7s\n",
      "[CV] END ..........C=100, degree=4, gamma=scale, kernel=poly; total time=  11.6s\n",
      "[CV] END ..........C=100, degree=4, gamma=scale, kernel=poly; total time=  11.5s\n",
      "[CV] END ..........C=100, degree=4, gamma=scale, kernel=poly; total time=  11.8s\n",
      "[CV] END ..........C=100, degree=4, gamma=scale, kernel=poly; total time=  12.1s\n",
      "[CV] END ..........C=100, degree=4, gamma=scale, kernel=poly; total time=  13.3s\n",
      "[CV] END .......C=100, degree=4, gamma=scale, kernel=sigmoid; total time=   7.9s\n",
      "[CV] END .......C=100, degree=4, gamma=scale, kernel=sigmoid; total time=   6.3s\n",
      "[CV] END .......C=100, degree=4, gamma=scale, kernel=sigmoid; total time=   6.6s\n",
      "[CV] END .......C=100, degree=4, gamma=scale, kernel=sigmoid; total time=   6.2s\n",
      "[CV] END .......C=100, degree=4, gamma=scale, kernel=sigmoid; total time=   6.5s\n",
      "[CV] END ............C=100, degree=4, gamma=auto, kernel=rbf; total time=  10.3s\n",
      "[CV] END ............C=100, degree=4, gamma=auto, kernel=rbf; total time=  10.3s\n",
      "[CV] END ............C=100, degree=4, gamma=auto, kernel=rbf; total time=  10.4s\n",
      "[CV] END ............C=100, degree=4, gamma=auto, kernel=rbf; total time=  10.3s\n",
      "[CV] END ............C=100, degree=4, gamma=auto, kernel=rbf; total time=  10.3s\n",
      "[CV] END .........C=100, degree=4, gamma=auto, kernel=linear; total time=  22.4s\n",
      "[CV] END .........C=100, degree=4, gamma=auto, kernel=linear; total time=  22.4s\n",
      "[CV] END .........C=100, degree=4, gamma=auto, kernel=linear; total time=  21.7s\n",
      "[CV] END .........C=100, degree=4, gamma=auto, kernel=linear; total time=  24.2s\n",
      "[CV] END .........C=100, degree=4, gamma=auto, kernel=linear; total time=  22.3s\n",
      "[CV] END ...........C=100, degree=4, gamma=auto, kernel=poly; total time=   5.5s\n",
      "[CV] END ...........C=100, degree=4, gamma=auto, kernel=poly; total time=   5.5s\n",
      "[CV] END ...........C=100, degree=4, gamma=auto, kernel=poly; total time=   5.5s\n",
      "[CV] END ...........C=100, degree=4, gamma=auto, kernel=poly; total time=   5.5s\n",
      "[CV] END ...........C=100, degree=4, gamma=auto, kernel=poly; total time=   5.5s\n",
      "[CV] END ........C=100, degree=4, gamma=auto, kernel=sigmoid; total time=   7.7s\n",
      "[CV] END ........C=100, degree=4, gamma=auto, kernel=sigmoid; total time=   7.8s\n",
      "[CV] END ........C=100, degree=4, gamma=auto, kernel=sigmoid; total time=   8.6s\n",
      "[CV] END ........C=100, degree=4, gamma=auto, kernel=sigmoid; total time=   8.7s\n",
      "[CV] END ........C=100, degree=4, gamma=auto, kernel=sigmoid; total time=   8.1s\n",
      "Best Parameters:  {'C': 100, 'degree': 4, 'gamma': 'scale', 'kernel': 'poly'}\n",
      "Best Score:  0.46894524244427227\n",
      "Accuracy on Test Set:  0.470404984423676\n",
      "Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        70\n",
      "           1       0.42      0.02      0.04       269\n",
      "           2       0.27      0.04      0.07       297\n",
      "           3       0.29      0.04      0.07       476\n",
      "           4       0.00      0.00      0.00       173\n",
      "           5       0.00      0.00      0.00        78\n",
      "           6       0.48      0.97      0.64      1205\n",
      "\n",
      "    accuracy                           0.47      2568\n",
      "   macro avg       0.21      0.15      0.12      2568\n",
      "weighted avg       0.35      0.47      0.33      2568\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Parameter grid for the GridSearchCV\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],  # Regularization parameter\n",
    "    'kernel': ['rbf', 'linear', 'poly', 'sigmoid'],  # Type of SVM kernel\n",
    "    'gamma': ['scale', 'auto'],  # Kernel coefficient for 'rbf', 'poly', and 'sigmoid'\n",
    "    'degree': [2, 3, 4]  # Degree of the polynomial kernel function ('poly'). Ignored by all other kernels.\n",
    "}\n",
    "\n",
    "# Initialize the SVM classifier\n",
    "svm = SVC(random_state=42)\n",
    "\n",
    "# Initialize the GridSearchCV object with SVM classifier and the parameter grid\n",
    "grid_search = GridSearchCV(estimator=svm, param_grid=param_grid, cv=5, scoring='accuracy', verbose=2)\n",
    "\n",
    "# Fit the model with the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters and the best score\n",
    "print(\"Best Parameters: \", grid_search.best_params_)\n",
    "print(\"Best Score: \", grid_search.best_score_)\n",
    "\n",
    "# Predict on the test set with the best parameters\n",
    "y_pred = grid_search.predict(X_test)\n",
    "\n",
    "# Evaluate the classifier with the best parameters\n",
    "print(\"Accuracy on Test Set: \", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report: \")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e523e7",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "92de9147",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5003894080996885\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.04      0.08        70\n",
      "           1       0.36      0.20      0.26       269\n",
      "           2       0.35      0.20      0.25       297\n",
      "           3       0.33      0.14      0.20       476\n",
      "           4       0.56      0.06      0.10       173\n",
      "           5       1.00      0.03      0.05        78\n",
      "           6       0.54      0.90      0.68      1205\n",
      "\n",
      "    accuracy                           0.50      2568\n",
      "   macro avg       0.56      0.22      0.23      2568\n",
      "weighted avg       0.48      0.50      0.42      2568\n",
      "\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Initialize the Random Forest classifier\n",
    "# n_estimators is the number of trees in the forest, the more, the better, but also the more computational cost.\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the classifier\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "# Evaluate the classifier\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "a5867904",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 216 candidates, totalling 1080 fits\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  26.5s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  27.7s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  27.5s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  25.2s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  25.8s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=  51.7s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=  52.6s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=  50.7s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=  50.7s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=  51.1s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time= 1.3min\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time= 1.3min\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time= 1.3min\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time= 1.3min\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time= 1.3min\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  25.3s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  25.6s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  25.4s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  25.0s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  29.0s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  53.2s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  51.7s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  50.4s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  49.9s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  50.2s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time= 1.3min\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time= 1.3min\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time= 1.3min\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time= 1.3min\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time= 1.3min\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=  24.8s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=  24.9s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=  24.4s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=  24.6s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=  24.5s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=  49.3s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=  49.4s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=  48.3s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=  48.7s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=  48.8s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time= 1.2min\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time= 1.3min\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time= 1.2min\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time= 1.2min\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time= 1.2min\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  24.8s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  24.4s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  23.3s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  23.5s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  23.9s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=  48.2s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=  48.1s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=  46.4s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=  47.5s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=  47.4s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time= 1.2min\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time= 1.2min\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time= 1.2min\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time= 1.2min\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time= 1.2min\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  23.8s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  23.9s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  23.4s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  23.4s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  23.8s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=  48.4s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=  47.7s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=  46.7s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=  46.9s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=  47.6s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time= 1.2min\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time= 1.2min\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time= 1.2min\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time= 1.2min\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time= 1.2min\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=  23.1s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=  23.5s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=  22.7s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=  22.8s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=  22.9s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=  46.0s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=  46.6s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=  45.3s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=  45.9s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=  45.8s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time= 1.2min\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time= 1.2min\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time= 1.1min\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time= 1.2min\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time= 1.2min\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=  21.3s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=  21.6s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=  20.9s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=  20.9s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=  21.1s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=  42.5s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=  42.8s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=  41.7s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=  41.6s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=  42.2s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time= 1.1min\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time= 1.1min\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time= 1.0min\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time= 1.0min\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time= 1.1min\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=  21.3s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=  21.6s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=  20.9s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=  20.9s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=  21.1s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=  42.6s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=  42.8s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=  41.6s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=  41.7s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=  42.3s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time= 1.1min\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time= 1.1min\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time= 1.0min\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time= 1.0min\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time= 1.1min\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  21.1s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  21.1s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  20.9s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  20.8s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  21.1s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=  41.8s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=  42.1s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=  41.5s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=  41.5s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=  42.1s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time= 1.1min\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time= 1.1min\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time= 1.0min\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time= 1.0min\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time= 1.1min\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  12.9s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  12.9s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  12.8s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  12.8s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  12.8s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=  25.8s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=  25.9s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=  25.8s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=  25.8s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=  25.8s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=  38.7s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=  38.9s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=  38.8s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=  38.8s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=  38.8s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  12.8s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  12.9s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  12.8s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  12.8s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  12.9s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  25.7s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  25.8s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  25.7s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  25.7s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  25.8s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=  38.6s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=  38.7s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=  38.7s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=  38.8s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=  38.8s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=  12.7s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=  12.8s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=  12.7s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=  12.8s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=  12.7s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=  25.6s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=  25.7s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=  25.5s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=  25.6s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=  25.6s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=  38.4s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=  38.5s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=  38.5s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=  38.4s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=  38.5s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  12.8s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  12.8s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  12.7s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  12.8s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  12.7s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=  25.6s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=  25.7s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=  25.6s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=  25.6s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=  25.6s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=  38.4s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=  38.4s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=  38.4s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=  38.5s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=  38.7s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  12.8s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  12.8s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  12.7s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  12.8s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  12.8s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=  25.6s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=  25.7s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=  25.6s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=  25.7s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=  25.7s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=  38.4s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=  38.5s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=  38.4s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=  38.5s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=  38.5s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=  12.7s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=  12.7s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=  12.7s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=  12.7s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=  12.7s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=  25.4s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=  25.6s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=  25.5s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=  25.5s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=  25.5s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=  38.2s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=  38.3s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=  38.2s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=  38.4s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=  38.3s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=  12.5s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=  12.6s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=  12.6s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=  12.6s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=  12.6s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=  25.1s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=  25.2s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=  25.2s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=  25.2s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=  25.3s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=  37.9s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=  37.9s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=  37.9s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=  38.0s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=  37.9s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=  12.6s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=  12.6s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=  12.6s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=  12.6s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=  12.6s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=  25.1s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=  25.3s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=  25.2s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=  25.4s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=  25.2s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=  37.8s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=  37.9s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=  37.8s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=  37.8s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=  37.9s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  12.5s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  12.6s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  12.5s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  12.5s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  12.6s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=  25.1s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=  25.2s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=  25.2s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=  25.2s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=  25.2s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=  37.8s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=  37.9s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=  37.9s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=  37.7s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=  37.8s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  21.1s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  21.1s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  21.0s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  21.0s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  21.1s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=  42.2s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=  42.4s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=  42.1s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=  42.0s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=  42.1s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time= 1.1min\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time= 1.1min\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time= 1.1min\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time= 1.1min\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time= 1.1min\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  20.9s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  20.9s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  20.7s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  20.7s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  20.7s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  41.7s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  41.8s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  41.4s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  41.4s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  41.6s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time= 1.0min\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time= 1.0min\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time= 1.0min\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time= 1.0min\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time= 1.0min\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=  20.4s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=  20.5s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=  20.3s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=  20.4s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=  20.3s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=  40.8s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=  40.9s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=  40.5s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=  40.5s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=  40.7s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time= 1.0min\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time= 1.0min\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time= 1.0min\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time= 1.0min\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time= 1.0min\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  20.4s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  20.3s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  23.6s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  20.1s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  20.3s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=  40.7s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=  40.6s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=  40.5s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=  40.3s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=  40.7s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time= 1.0min\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time= 1.0min\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time= 1.0min\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time= 1.0min\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time= 1.0min\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  20.4s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  20.3s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  20.1s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  20.2s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  20.2s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=  40.6s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=  40.6s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=  40.3s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=  40.3s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=  40.4s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time= 1.0min\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time= 1.0min\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time= 1.0min\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time= 1.0min\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time= 1.0min\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=  20.0s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=  19.9s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=  19.7s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=  19.8s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=  19.8s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=  39.6s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=  39.8s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=  39.5s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=  39.7s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=  39.6s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=  59.5s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=  59.8s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=  59.7s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=  59.8s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=  59.7s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=  19.3s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=  19.1s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=  19.0s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=  18.9s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=  19.0s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=  38.3s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=  38.0s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=  38.0s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=  38.1s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=  38.1s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=  57.5s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=  56.9s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=  57.0s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=  57.0s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=  57.1s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=  19.3s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=  19.1s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=  19.0s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=  18.9s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=  19.1s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=  38.3s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=  38.0s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=  37.9s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=  37.9s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=  38.0s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=  57.4s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=  56.9s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=  57.3s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=  57.0s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=  57.0s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  19.0s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  19.0s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  18.9s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  18.9s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  19.1s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=  37.9s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=  37.9s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=  37.5s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=  37.7s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=  37.8s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=  56.8s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=  56.7s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=  56.5s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=  56.5s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=  56.8s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  24.1s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  24.2s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  23.9s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  24.0s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  24.1s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=  47.9s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=  48.1s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=  47.8s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=  47.8s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=  48.2s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time= 1.2min\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time= 1.2min\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time= 1.2min\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time= 1.2min\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time= 1.2min\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  23.8s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  23.9s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  23.8s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  23.6s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  23.6s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  47.6s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  47.8s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  47.2s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  47.2s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  47.4s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time= 1.2min\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time= 1.2min\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time= 1.2min\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time= 1.2min\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time= 1.2min\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=  23.2s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=  23.5s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=  23.0s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=  23.1s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=  23.2s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=  46.1s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=  46.6s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=  46.1s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=  46.1s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=  46.4s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time= 1.2min\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time= 1.2min\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time= 1.2min\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time= 1.2min\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time= 1.2min\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  22.9s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  22.9s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  22.5s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  22.5s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  22.8s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=  45.7s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=  46.0s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=  45.1s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=  45.2s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=  45.2s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time= 1.1min\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time= 1.1min\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time= 1.1min\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time= 1.1min\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time= 1.1min\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  23.0s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  22.8s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  22.5s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  22.7s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  22.6s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=  45.7s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=  45.5s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=  45.1s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=  45.1s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=  45.3s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time= 1.1min\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time= 1.1min\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time= 1.1min\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time= 1.1min\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time= 1.1min\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=  22.3s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=  22.6s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=  22.1s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=  22.0s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=  22.0s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=  44.3s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=  44.9s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=  44.0s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=  44.2s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=  44.1s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time= 1.1min\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time= 1.1min\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time= 1.1min\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time= 1.1min\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time= 1.1min\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=  21.1s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=  21.1s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=  20.5s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=  20.7s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=  20.7s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=  41.9s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=  41.9s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=  41.0s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=  41.1s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=  41.5s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time= 1.0min\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time= 1.0min\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time= 1.0min\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time= 1.0min\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time= 1.0min\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=  21.0s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=  21.2s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=  20.5s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=  20.6s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=  20.7s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=  41.7s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=  41.9s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=  41.0s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=  41.0s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=  41.4s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time= 1.0min\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time= 1.0min\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time= 1.0min\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time= 1.0min\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time= 1.0min\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  20.7s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  20.6s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  20.4s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  20.5s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  20.7s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=  41.4s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=  41.3s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=  40.6s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=  41.0s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=  41.3s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time= 1.0min\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time= 1.0min\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time= 1.0min\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time= 1.0min\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time= 1.0min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  36.0s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  35.8s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  35.3s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  35.4s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  36.0s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time= 1.2min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time= 1.2min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time= 1.2min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time= 1.2min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time= 1.2min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time= 1.8min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time= 1.8min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time= 1.8min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time= 1.8min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time= 1.8min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  35.4s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  36.2s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  34.5s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  34.6s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  35.4s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time= 1.2min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time= 1.2min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time= 1.2min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time= 1.2min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time= 1.2min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time= 1.8min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time= 1.8min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time= 1.7min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time= 1.7min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time= 1.8min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=  34.2s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=  34.9s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=  34.3s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=  34.1s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=  34.8s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time= 1.1min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time= 1.2min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time= 1.1min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time= 1.1min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time= 1.2min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time= 1.7min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time= 1.7min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time= 1.7min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time= 1.7min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time= 1.7min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  34.0s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  34.7s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  33.4s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  33.6s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  34.0s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time= 1.1min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time= 1.1min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time= 1.1min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time= 1.1min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time= 1.1min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time= 1.7min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time= 1.7min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time= 1.7min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time= 1.7min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time= 1.7min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  33.7s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  34.7s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  33.0s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  33.3s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  34.0s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time= 1.1min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time= 1.1min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time= 1.1min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time= 1.1min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time= 1.1min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time= 1.7min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time= 1.7min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time= 1.7min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time= 1.6min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time= 1.7min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=  32.9s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=  33.7s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=  32.8s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=  32.6s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=  33.3s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time= 1.1min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time= 1.1min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time= 1.1min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time= 1.1min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time= 1.1min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time= 1.6min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time= 1.7min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time= 1.6min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time= 1.6min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time= 1.7min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=  30.6s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=  31.1s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=  30.2s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=  30.6s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=  31.0s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time= 1.0min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time= 1.0min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time= 1.0min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time= 1.0min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time= 1.0min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time= 1.5min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time= 1.6min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time= 1.5min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time= 1.5min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time= 1.5min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=  30.6s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=  31.2s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=  30.1s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=  30.5s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=  30.9s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time= 1.0min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time= 1.0min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time= 1.0min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time= 1.0min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time= 1.0min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time= 1.5min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time= 1.6min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time= 1.5min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time= 1.5min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time= 1.5min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  30.9s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  31.2s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  29.7s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  30.1s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  31.0s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time= 1.0min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time= 1.0min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=  59.6s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time= 1.0min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time= 1.0min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time= 1.5min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time= 1.5min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time= 1.5min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time= 1.5min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time= 1.5min\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  18.1s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  18.0s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  18.0s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  18.0s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  18.0s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=  36.1s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=  36.2s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=  36.1s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=  36.2s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=  36.1s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=  54.1s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=  54.3s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=  54.2s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=  54.1s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=  54.1s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  18.0s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  18.0s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  18.0s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  18.0s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  18.0s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  36.0s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  36.2s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  36.2s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  36.0s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  36.1s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=  54.0s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=  54.2s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=  54.0s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=  54.1s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=  54.1s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=  17.9s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=  18.0s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=  17.9s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=  17.9s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=  17.9s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=  35.8s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=  36.0s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=  35.9s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=  35.9s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=  35.9s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=  53.7s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=  54.0s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=  53.8s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=  53.9s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=  53.9s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  17.9s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  17.9s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  17.9s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  17.9s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  17.9s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=  36.0s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=  35.9s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=  36.0s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=  35.9s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=  36.0s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=  53.8s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=  54.7s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=  53.8s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=  54.0s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=  54.0s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  17.9s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  18.0s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  17.9s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  17.9s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  17.9s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=  35.8s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=  36.0s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=  35.9s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=  36.1s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=  35.9s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=  53.8s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=  54.0s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=  53.8s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=  53.9s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=  53.9s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=  17.8s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=  17.9s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=  17.8s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=  17.8s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=  17.8s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=  35.7s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=  35.9s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=  35.6s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=  35.8s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=  35.8s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=  53.6s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=  53.7s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=  53.7s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=  53.5s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=  53.7s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=  17.7s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=  17.8s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=  17.8s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=  17.8s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=  17.7s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=  35.4s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=  35.5s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=  35.5s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=  35.6s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=  35.5s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=  53.3s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=  53.5s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=  53.3s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=  53.3s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=  53.3s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=  17.6s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=  17.8s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=  17.7s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=  17.8s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=  17.7s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=  35.5s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=  35.6s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=  35.4s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=  35.6s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=  35.5s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=  53.2s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=  53.3s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=  53.3s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=  53.3s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=  53.3s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  17.7s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  17.7s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  17.7s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  17.7s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  17.8s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=  35.4s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=  35.5s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=  35.5s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=  35.5s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=  35.4s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=  53.1s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=  53.4s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=  53.2s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=  53.2s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=  53.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  29.6s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  29.6s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  29.6s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  29.8s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  29.7s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=  59.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=  59.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=  59.5s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=  59.4s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=  59.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time= 1.5min\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time= 1.5min\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time= 1.5min\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time= 1.5min\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time= 1.5min\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  29.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  29.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  29.4s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  29.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  29.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  58.9s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  59.1s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  58.6s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  58.7s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  58.6s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time= 1.5min\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time= 1.5min\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time= 1.5min\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time= 1.5min\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time= 1.5min\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=  28.9s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=  28.8s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=  28.8s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=  28.7s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=  28.8s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=  57.6s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=  57.6s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=  57.5s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=  57.4s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=  57.8s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time= 1.4min\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time= 1.4min\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time= 1.4min\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time= 1.4min\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time= 1.4min\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  28.9s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  28.9s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  28.8s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  28.8s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  28.9s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=  57.6s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=  57.8s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=  57.5s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=  57.5s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=  57.7s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time= 1.4min\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time= 1.4min\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time= 1.4min\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time= 1.4min\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time= 1.5min\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  28.7s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  28.8s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  28.7s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  28.8s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  28.7s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=  57.4s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=  57.5s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=  57.4s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=  57.5s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=  57.6s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time= 1.4min\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time= 1.4min\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time= 1.4min\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time= 1.4min\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time= 1.4min\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=  28.2s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=  28.4s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=  28.1s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=  28.2s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=  28.4s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=  56.5s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=  56.8s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=  56.5s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=  56.4s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=  56.7s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time= 1.4min\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time= 1.4min\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time= 1.4min\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time= 1.4min\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time= 1.4min\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=  27.5s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=  27.5s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=  27.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=  27.4s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=  27.4s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=  54.7s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=  55.0s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=  54.6s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=  54.7s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=  54.8s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time= 1.4min\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time= 1.4min\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time= 1.4min\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time= 1.4min\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time= 1.4min\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=  27.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=  27.5s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=  27.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=  27.4s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=  27.5s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=  54.8s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=  54.9s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=  54.4s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=  54.6s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=  54.8s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time= 1.4min\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time= 1.4min\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time= 1.4min\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time= 1.4min\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time= 1.4min\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  27.4s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  27.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  27.2s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  27.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  27.4s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=  54.5s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=  54.7s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=  54.5s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=  54.4s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=  54.6s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time= 1.4min\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time= 1.4min\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time= 1.4min\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time= 1.4min\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time= 1.4min\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  34.1s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  34.1s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  33.8s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  33.9s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  34.1s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time= 1.1min\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time= 1.1min\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time= 1.1min\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time= 1.1min\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time= 1.1min\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time= 1.7min\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time= 1.7min\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time= 1.7min\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time= 1.7min\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time= 1.7min\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  33.7s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  33.7s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  33.2s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  33.1s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  33.5s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time= 1.1min\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time= 1.1min\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time= 1.1min\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time= 1.1min\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time= 1.1min\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time= 1.7min\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time= 1.7min\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time= 1.7min\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time= 1.7min\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time= 1.7min\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=  32.4s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=  32.5s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=  32.3s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=  32.6s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=  32.7s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time= 1.1min\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time= 1.1min\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time= 1.1min\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time= 1.1min\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time= 1.1min\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time= 1.6min\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time= 1.6min\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time= 1.6min\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time= 1.6min\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time= 1.6min\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  32.6s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  32.8s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  32.1s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  32.1s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  32.6s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time= 1.1min\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time= 1.1min\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time= 1.1min\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time= 1.1min\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time= 1.1min\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time= 1.6min\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time= 1.6min\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time= 1.6min\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time= 1.6min\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time= 1.6min\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  32.5s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  32.6s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  31.9s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  32.2s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  32.4s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time= 1.1min\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time= 1.1min\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time= 1.1min\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time= 1.1min\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time= 1.1min\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time= 1.6min\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time= 1.6min\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time= 1.6min\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time= 1.6min\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time= 1.6min\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=  31.8s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=  32.1s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=  31.4s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=  31.6s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=  31.8s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time= 1.1min\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time= 1.1min\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time= 1.0min\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time= 1.0min\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time= 1.1min\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time= 1.6min\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time= 1.6min\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time= 1.6min\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time= 1.6min\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time= 1.6min\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=  29.9s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=  30.4s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=  29.8s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=  29.9s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=  30.1s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time= 1.0min\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time= 1.0min\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=  59.3s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=  59.4s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=  59.8s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time= 1.5min\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time= 1.5min\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time= 1.5min\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time= 1.5min\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time= 1.5min\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=  29.9s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=  30.4s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=  29.7s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=  29.9s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=  30.0s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time= 1.0min\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time= 1.0min\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=  59.4s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=  59.3s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=  59.8s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time= 1.5min\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time= 1.5min\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time= 1.5min\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time= 1.5min\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time= 1.5min\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  29.8s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  30.4s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  29.3s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  30.1s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  30.3s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=  59.5s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time= 1.0min\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=  58.9s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=  59.4s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time= 1.0min\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time= 1.5min\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time= 1.5min\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time= 1.5min\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time= 1.5min\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time= 1.5min\n",
      "Best Parameters:  {'bootstrap': False, 'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 200}\n",
      "Best Score:  0.48919418996107533\n",
      "Accuracy on Test Set:  0.5003894080996885\n",
      "Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.04      0.08        70\n",
      "           1       0.40      0.22      0.28       269\n",
      "           2       0.34      0.20      0.25       297\n",
      "           3       0.33      0.14      0.20       476\n",
      "           4       0.81      0.08      0.14       173\n",
      "           5       0.33      0.01      0.02        78\n",
      "           6       0.54      0.90      0.67      1205\n",
      "\n",
      "    accuracy                           0.50      2568\n",
      "   macro avg       0.50      0.23      0.24      2568\n",
      "weighted avg       0.48      0.50      0.42      2568\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Parameter grid for GridSearchCV\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],  # Number of trees in the forest\n",
    "    'max_depth': [None, 10, 20, 30],  # Maximum depth of the tree\n",
    "    'min_samples_split': [2, 5, 10],  # Minimum number of samples required to split an internal node\n",
    "    'min_samples_leaf': [1, 2, 4],  # Minimum number of samples required to be at a leaf node\n",
    "    'bootstrap': [True, False]  # Method of selecting samples for training each tree\n",
    "}\n",
    "\n",
    "# Initialize the Random Forest classifier\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Initialize GridSearchCV object with Random Forest classifier and the parameter grid\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=5, scoring='accuracy', verbose=2)\n",
    "\n",
    "# Fit the model with the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters and the best score\n",
    "print(\"Best Parameters: \", grid_search.best_params_)\n",
    "print(\"Best Score: \", grid_search.best_score_)\n",
    "\n",
    "# Predict on the test set with the best parameters\n",
    "y_pred = grid_search.predict(X_test)\n",
    "\n",
    "# Evaluate the classifier with the best parameters\n",
    "print(\"Accuracy on Test Set: \", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report: \")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "692c45bf",
   "metadata": {},
   "source": [
    "### Gradient Boosting Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "bae9e4f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttest-mlogloss:1.75195\n",
      "[1]\ttest-mlogloss:1.64727\n",
      "[2]\ttest-mlogloss:1.58192\n",
      "[3]\ttest-mlogloss:1.53740\n",
      "[4]\ttest-mlogloss:1.50640\n",
      "[5]\ttest-mlogloss:1.48556\n",
      "[6]\ttest-mlogloss:1.47137\n",
      "[7]\ttest-mlogloss:1.45901\n",
      "[8]\ttest-mlogloss:1.45201\n",
      "[9]\ttest-mlogloss:1.44636\n",
      "[10]\ttest-mlogloss:1.44285\n",
      "[11]\ttest-mlogloss:1.44028\n",
      "[12]\ttest-mlogloss:1.43839\n",
      "[13]\ttest-mlogloss:1.43835\n",
      "[14]\ttest-mlogloss:1.43903\n",
      "[15]\ttest-mlogloss:1.43802\n",
      "[16]\ttest-mlogloss:1.43881\n",
      "[17]\ttest-mlogloss:1.43870\n",
      "[18]\ttest-mlogloss:1.43848\n",
      "[19]\ttest-mlogloss:1.43943\n",
      "[20]\ttest-mlogloss:1.43935\n",
      "[21]\ttest-mlogloss:1.44028\n",
      "[22]\ttest-mlogloss:1.44092\n",
      "[23]\ttest-mlogloss:1.44202\n",
      "[24]\ttest-mlogloss:1.44287\n",
      "[25]\ttest-mlogloss:1.44265\n",
      "Accuracy: 0.4894859813084112\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.01      0.03        70\n",
      "           1       0.34      0.19      0.24       269\n",
      "           2       0.28      0.16      0.21       297\n",
      "           3       0.37      0.15      0.21       476\n",
      "           4       0.67      0.05      0.09       173\n",
      "           5       1.00      0.01      0.03        78\n",
      "           6       0.53      0.89      0.66      1205\n",
      "\n",
      "    accuracy                           0.49      2568\n",
      "   macro avg       0.53      0.21      0.21      2568\n",
      "weighted avg       0.47      0.49      0.41      2568\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "\n",
    "params = {\n",
    "    'max_depth': 6,  # Maximum depth of a tree\n",
    "    'eta': 0.3,  # Learning rate\n",
    "    'objective': 'multi:softmax',  # Multiclass classification and use softmax objective function\n",
    "    'num_class': len(set(y)),  # Number of classes\n",
    "    'eval_metric': 'mlogloss',  # Evaluation metrics for validation data\n",
    "}\n",
    "num_rounds = 100  # Number of boosting rounds\n",
    "\n",
    "bst = xgb.train(params, dtrain, num_rounds, evals=[(dtest, 'test')], early_stopping_rounds=10)\n",
    "\n",
    "y_pred = bst.predict(dtest)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "5c4acf66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 27 candidates, totalling 81 fits\n",
      "[CV] END eval_metric=mlogloss, learning_rate=0.01, max_depth=3, n_estimators=100, num_class=7, objective=multi:softmax; total time=   2.6s\n",
      "[CV] END eval_metric=mlogloss, learning_rate=0.01, max_depth=3, n_estimators=100, num_class=7, objective=multi:softmax; total time=   2.6s\n",
      "[CV] END eval_metric=mlogloss, learning_rate=0.01, max_depth=3, n_estimators=100, num_class=7, objective=multi:softmax; total time=   2.5s\n",
      "[CV] END eval_metric=mlogloss, learning_rate=0.01, max_depth=3, n_estimators=200, num_class=7, objective=multi:softmax; total time=   5.3s\n",
      "[CV] END eval_metric=mlogloss, learning_rate=0.01, max_depth=3, n_estimators=200, num_class=7, objective=multi:softmax; total time=   5.1s\n",
      "[CV] END eval_metric=mlogloss, learning_rate=0.01, max_depth=3, n_estimators=200, num_class=7, objective=multi:softmax; total time=   5.3s\n",
      "[CV] END eval_metric=mlogloss, learning_rate=0.01, max_depth=3, n_estimators=300, num_class=7, objective=multi:softmax; total time=   7.4s\n",
      "[CV] END eval_metric=mlogloss, learning_rate=0.01, max_depth=3, n_estimators=300, num_class=7, objective=multi:softmax; total time=   8.3s\n",
      "[CV] END eval_metric=mlogloss, learning_rate=0.01, max_depth=3, n_estimators=300, num_class=7, objective=multi:softmax; total time=   7.4s\n",
      "[CV] END eval_metric=mlogloss, learning_rate=0.01, max_depth=6, n_estimators=100, num_class=7, objective=multi:softmax; total time=  11.9s\n",
      "[CV] END eval_metric=mlogloss, learning_rate=0.01, max_depth=6, n_estimators=100, num_class=7, objective=multi:softmax; total time=  12.0s\n",
      "[CV] END eval_metric=mlogloss, learning_rate=0.01, max_depth=6, n_estimators=100, num_class=7, objective=multi:softmax; total time=  11.2s\n",
      "[CV] END eval_metric=mlogloss, learning_rate=0.01, max_depth=6, n_estimators=200, num_class=7, objective=multi:softmax; total time=  23.4s\n",
      "[CV] END eval_metric=mlogloss, learning_rate=0.01, max_depth=6, n_estimators=200, num_class=7, objective=multi:softmax; total time=  23.6s\n",
      "[CV] END eval_metric=mlogloss, learning_rate=0.01, max_depth=6, n_estimators=200, num_class=7, objective=multi:softmax; total time=  22.0s\n",
      "[CV] END eval_metric=mlogloss, learning_rate=0.01, max_depth=6, n_estimators=300, num_class=7, objective=multi:softmax; total time=  34.9s\n",
      "[CV] END eval_metric=mlogloss, learning_rate=0.01, max_depth=6, n_estimators=300, num_class=7, objective=multi:softmax; total time=  34.6s\n",
      "[CV] END eval_metric=mlogloss, learning_rate=0.01, max_depth=6, n_estimators=300, num_class=7, objective=multi:softmax; total time=  33.4s\n",
      "[CV] END eval_metric=mlogloss, learning_rate=0.01, max_depth=10, n_estimators=100, num_class=7, objective=multi:softmax; total time=  43.3s\n",
      "[CV] END eval_metric=mlogloss, learning_rate=0.01, max_depth=10, n_estimators=100, num_class=7, objective=multi:softmax; total time=  41.9s\n",
      "[CV] END eval_metric=mlogloss, learning_rate=0.01, max_depth=10, n_estimators=100, num_class=7, objective=multi:softmax; total time=  40.0s\n",
      "[CV] END eval_metric=mlogloss, learning_rate=0.01, max_depth=10, n_estimators=200, num_class=7, objective=multi:softmax; total time= 1.4min\n",
      "[CV] END eval_metric=mlogloss, learning_rate=0.01, max_depth=10, n_estimators=200, num_class=7, objective=multi:softmax; total time= 1.4min\n",
      "[CV] END eval_metric=mlogloss, learning_rate=0.01, max_depth=10, n_estimators=200, num_class=7, objective=multi:softmax; total time= 1.3min\n",
      "[CV] END eval_metric=mlogloss, learning_rate=0.01, max_depth=10, n_estimators=300, num_class=7, objective=multi:softmax; total time= 1.9min\n",
      "[CV] END eval_metric=mlogloss, learning_rate=0.01, max_depth=10, n_estimators=300, num_class=7, objective=multi:softmax; total time= 1.9min\n",
      "[CV] END eval_metric=mlogloss, learning_rate=0.01, max_depth=10, n_estimators=300, num_class=7, objective=multi:softmax; total time= 2.0min\n",
      "[CV] END eval_metric=mlogloss, learning_rate=0.1, max_depth=3, n_estimators=100, num_class=7, objective=multi:softmax; total time=   3.2s\n",
      "[CV] END eval_metric=mlogloss, learning_rate=0.1, max_depth=3, n_estimators=100, num_class=7, objective=multi:softmax; total time=   3.1s\n",
      "[CV] END eval_metric=mlogloss, learning_rate=0.1, max_depth=3, n_estimators=100, num_class=7, objective=multi:softmax; total time=   3.1s\n",
      "[CV] END eval_metric=mlogloss, learning_rate=0.1, max_depth=3, n_estimators=200, num_class=7, objective=multi:softmax; total time=   6.3s\n",
      "[CV] END eval_metric=mlogloss, learning_rate=0.1, max_depth=3, n_estimators=200, num_class=7, objective=multi:softmax; total time=   5.5s\n",
      "[CV] END eval_metric=mlogloss, learning_rate=0.1, max_depth=3, n_estimators=200, num_class=7, objective=multi:softmax; total time=   5.3s\n",
      "[CV] END eval_metric=mlogloss, learning_rate=0.1, max_depth=3, n_estimators=300, num_class=7, objective=multi:softmax; total time=   7.7s\n",
      "[CV] END eval_metric=mlogloss, learning_rate=0.1, max_depth=3, n_estimators=300, num_class=7, objective=multi:softmax; total time=   7.8s\n",
      "[CV] END eval_metric=mlogloss, learning_rate=0.1, max_depth=3, n_estimators=300, num_class=7, objective=multi:softmax; total time=   8.3s\n",
      "[CV] END eval_metric=mlogloss, learning_rate=0.1, max_depth=6, n_estimators=100, num_class=7, objective=multi:softmax; total time=   9.6s\n",
      "[CV] END eval_metric=mlogloss, learning_rate=0.1, max_depth=6, n_estimators=100, num_class=7, objective=multi:softmax; total time=   9.6s\n",
      "[CV] END eval_metric=mlogloss, learning_rate=0.1, max_depth=6, n_estimators=100, num_class=7, objective=multi:softmax; total time=   9.8s\n",
      "[CV] END eval_metric=mlogloss, learning_rate=0.1, max_depth=6, n_estimators=200, num_class=7, objective=multi:softmax; total time=  18.5s\n",
      "[CV] END eval_metric=mlogloss, learning_rate=0.1, max_depth=6, n_estimators=200, num_class=7, objective=multi:softmax; total time=  18.0s\n",
      "[CV] END eval_metric=mlogloss, learning_rate=0.1, max_depth=6, n_estimators=200, num_class=7, objective=multi:softmax; total time=  18.3s\n",
      "[CV] END eval_metric=mlogloss, learning_rate=0.1, max_depth=6, n_estimators=300, num_class=7, objective=multi:softmax; total time=  28.0s\n",
      "[CV] END eval_metric=mlogloss, learning_rate=0.1, max_depth=6, n_estimators=300, num_class=7, objective=multi:softmax; total time=  28.7s\n",
      "[CV] END eval_metric=mlogloss, learning_rate=0.1, max_depth=6, n_estimators=300, num_class=7, objective=multi:softmax; total time=  29.2s\n",
      "[CV] END eval_metric=mlogloss, learning_rate=0.1, max_depth=10, n_estimators=100, num_class=7, objective=multi:softmax; total time=  33.8s\n",
      "[CV] END eval_metric=mlogloss, learning_rate=0.1, max_depth=10, n_estimators=100, num_class=7, objective=multi:softmax; total time=  32.0s\n",
      "[CV] END eval_metric=mlogloss, learning_rate=0.1, max_depth=10, n_estimators=100, num_class=7, objective=multi:softmax; total time=  30.5s\n",
      "[CV] END eval_metric=mlogloss, learning_rate=0.1, max_depth=10, n_estimators=200, num_class=7, objective=multi:softmax; total time=  51.3s\n",
      "[CV] END eval_metric=mlogloss, learning_rate=0.1, max_depth=10, n_estimators=200, num_class=7, objective=multi:softmax; total time=  45.0s\n",
      "[CV] END eval_metric=mlogloss, learning_rate=0.1, max_depth=10, n_estimators=200, num_class=7, objective=multi:softmax; total time=  45.4s\n",
      "[CV] END eval_metric=mlogloss, learning_rate=0.1, max_depth=10, n_estimators=300, num_class=7, objective=multi:softmax; total time= 1.0min\n",
      "[CV] END eval_metric=mlogloss, learning_rate=0.1, max_depth=10, n_estimators=300, num_class=7, objective=multi:softmax; total time= 1.1min\n",
      "[CV] END eval_metric=mlogloss, learning_rate=0.1, max_depth=10, n_estimators=300, num_class=7, objective=multi:softmax; total time= 1.0min\n",
      "[CV] END eval_metric=mlogloss, learning_rate=0.3, max_depth=3, n_estimators=100, num_class=7, objective=multi:softmax; total time=   2.0s\n",
      "[CV] END eval_metric=mlogloss, learning_rate=0.3, max_depth=3, n_estimators=100, num_class=7, objective=multi:softmax; total time=   1.9s\n",
      "[CV] END eval_metric=mlogloss, learning_rate=0.3, max_depth=3, n_estimators=100, num_class=7, objective=multi:softmax; total time=   2.1s\n",
      "[CV] END eval_metric=mlogloss, learning_rate=0.3, max_depth=3, n_estimators=200, num_class=7, objective=multi:softmax; total time=   4.1s\n",
      "[CV] END eval_metric=mlogloss, learning_rate=0.3, max_depth=3, n_estimators=200, num_class=7, objective=multi:softmax; total time=   4.0s\n",
      "[CV] END eval_metric=mlogloss, learning_rate=0.3, max_depth=3, n_estimators=200, num_class=7, objective=multi:softmax; total time=   4.3s\n",
      "[CV] END eval_metric=mlogloss, learning_rate=0.3, max_depth=3, n_estimators=300, num_class=7, objective=multi:softmax; total time=   7.9s\n",
      "[CV] END eval_metric=mlogloss, learning_rate=0.3, max_depth=3, n_estimators=300, num_class=7, objective=multi:softmax; total time=   7.2s\n",
      "[CV] END eval_metric=mlogloss, learning_rate=0.3, max_depth=3, n_estimators=300, num_class=7, objective=multi:softmax; total time=   7.5s\n",
      "[CV] END eval_metric=mlogloss, learning_rate=0.3, max_depth=6, n_estimators=100, num_class=7, objective=multi:softmax; total time=  10.1s\n",
      "[CV] END eval_metric=mlogloss, learning_rate=0.3, max_depth=6, n_estimators=100, num_class=7, objective=multi:softmax; total time=   9.4s\n",
      "[CV] END eval_metric=mlogloss, learning_rate=0.3, max_depth=6, n_estimators=100, num_class=7, objective=multi:softmax; total time=   9.2s\n",
      "[CV] END eval_metric=mlogloss, learning_rate=0.3, max_depth=6, n_estimators=200, num_class=7, objective=multi:softmax; total time=  18.7s\n",
      "[CV] END eval_metric=mlogloss, learning_rate=0.3, max_depth=6, n_estimators=200, num_class=7, objective=multi:softmax; total time=  18.5s\n",
      "[CV] END eval_metric=mlogloss, learning_rate=0.3, max_depth=6, n_estimators=200, num_class=7, objective=multi:softmax; total time=  16.8s\n",
      "[CV] END eval_metric=mlogloss, learning_rate=0.3, max_depth=6, n_estimators=300, num_class=7, objective=multi:softmax; total time=  24.2s\n",
      "[CV] END eval_metric=mlogloss, learning_rate=0.3, max_depth=6, n_estimators=300, num_class=7, objective=multi:softmax; total time=  24.0s\n",
      "[CV] END eval_metric=mlogloss, learning_rate=0.3, max_depth=6, n_estimators=300, num_class=7, objective=multi:softmax; total time=  24.7s\n",
      "[CV] END eval_metric=mlogloss, learning_rate=0.3, max_depth=10, n_estimators=100, num_class=7, objective=multi:softmax; total time=  22.0s\n",
      "[CV] END eval_metric=mlogloss, learning_rate=0.3, max_depth=10, n_estimators=100, num_class=7, objective=multi:softmax; total time=  23.2s\n",
      "[CV] END eval_metric=mlogloss, learning_rate=0.3, max_depth=10, n_estimators=100, num_class=7, objective=multi:softmax; total time=  20.3s\n",
      "[CV] END eval_metric=mlogloss, learning_rate=0.3, max_depth=10, n_estimators=200, num_class=7, objective=multi:softmax; total time=  29.9s\n",
      "[CV] END eval_metric=mlogloss, learning_rate=0.3, max_depth=10, n_estimators=200, num_class=7, objective=multi:softmax; total time=  29.6s\n",
      "[CV] END eval_metric=mlogloss, learning_rate=0.3, max_depth=10, n_estimators=200, num_class=7, objective=multi:softmax; total time=  29.9s\n",
      "[CV] END eval_metric=mlogloss, learning_rate=0.3, max_depth=10, n_estimators=300, num_class=7, objective=multi:softmax; total time=  38.2s\n",
      "[CV] END eval_metric=mlogloss, learning_rate=0.3, max_depth=10, n_estimators=300, num_class=7, objective=multi:softmax; total time=  36.9s\n",
      "[CV] END eval_metric=mlogloss, learning_rate=0.3, max_depth=10, n_estimators=300, num_class=7, objective=multi:softmax; total time=  36.5s\n",
      "Best Parameters: {'eval_metric': 'mlogloss', 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 100, 'num_class': 7, 'objective': 'multi:softmax'}\n",
      "Best Score: 0.4832554517133956\n",
      "Accuracy on Test Set: 0.4945482866043614\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.04      0.08        70\n",
      "           1       0.32      0.19      0.24       269\n",
      "           2       0.30      0.20      0.24       297\n",
      "           3       0.35      0.18      0.23       476\n",
      "           4       0.60      0.05      0.10       173\n",
      "           5       1.00      0.01      0.03        78\n",
      "           6       0.54      0.88      0.67      1205\n",
      "\n",
      "    accuracy                           0.49      2568\n",
      "   macro avg       0.55      0.22      0.23      2568\n",
      "weighted avg       0.48      0.49      0.42      2568\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the parameter grid for XGBoost\n",
    "param_grid = {\n",
    "    'max_depth': [3, 6, 10],  # Maximum depth of a tree\n",
    "    'learning_rate': [0.01, 0.1, 0.3],  # Step size shrinkage used to prevent overfitting\n",
    "    'n_estimators': [100, 200, 300],  # Number of trees you want to build\n",
    "    'objective': ['multi:softmax'],  # Multiclass classification using the softmax objective\n",
    "    'eval_metric': ['mlogloss'],  # Evaluation metrics for validation data\n",
    "    'num_class': [len(set(y))]  # Number of classes in the objective function\n",
    "}\n",
    "\n",
    "# Initialize the XGBClassifier\n",
    "xgb_model = xgb.XGBClassifier(use_label_encoder=False)\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=xgb_model, param_grid=param_grid, cv=3, scoring='accuracy', verbose=2)\n",
    "\n",
    "# Fit GridSearchCV\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters and the best score\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Score:\", grid_search.best_score_)\n",
    "\n",
    "# Predict on the test set with the best parameters\n",
    "y_pred = grid_search.predict(X_test)\n",
    "\n",
    "# Evaluate the classifier with the best parameters\n",
    "print(\"Accuracy on Test Set:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aea2ec7",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "7c70dfef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4057632398753894\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.06      0.03      0.04        70\n",
      "           1       0.17      0.20      0.19       269\n",
      "           2       0.26      0.26      0.26       297\n",
      "           3       0.27      0.24      0.26       476\n",
      "           4       0.16      0.08      0.11       173\n",
      "           5       0.13      0.03      0.04        78\n",
      "           6       0.55      0.65      0.60      1205\n",
      "\n",
      "    accuracy                           0.41      2568\n",
      "   macro avg       0.23      0.21      0.21      2568\n",
      "weighted avg       0.38      0.41      0.39      2568\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize the KNN classifier\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# Train the classifier\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "# Evaluate the classifier\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "02d1ac2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "[CV] END ...metric=euclidean, n_neighbors=3, weights=uniform; total time=   0.1s\n",
      "[CV] END ...metric=euclidean, n_neighbors=3, weights=uniform; total time=   0.1s\n",
      "[CV] END ...metric=euclidean, n_neighbors=3, weights=uniform; total time=   0.1s\n",
      "[CV] END ...metric=euclidean, n_neighbors=3, weights=uniform; total time=   0.1s\n",
      "[CV] END ...metric=euclidean, n_neighbors=3, weights=uniform; total time=   0.1s\n",
      "[CV] END ..metric=euclidean, n_neighbors=3, weights=distance; total time=   0.0s\n",
      "[CV] END ..metric=euclidean, n_neighbors=3, weights=distance; total time=   0.0s\n",
      "[CV] END ..metric=euclidean, n_neighbors=3, weights=distance; total time=   0.0s\n",
      "[CV] END ..metric=euclidean, n_neighbors=3, weights=distance; total time=   0.0s\n",
      "[CV] END ..metric=euclidean, n_neighbors=3, weights=distance; total time=   0.0s\n",
      "[CV] END ...metric=euclidean, n_neighbors=5, weights=uniform; total time=   0.1s\n",
      "[CV] END ...metric=euclidean, n_neighbors=5, weights=uniform; total time=   0.1s\n",
      "[CV] END ...metric=euclidean, n_neighbors=5, weights=uniform; total time=   0.1s\n",
      "[CV] END ...metric=euclidean, n_neighbors=5, weights=uniform; total time=   0.0s\n",
      "[CV] END ...metric=euclidean, n_neighbors=5, weights=uniform; total time=   0.1s\n",
      "[CV] END ..metric=euclidean, n_neighbors=5, weights=distance; total time=   0.0s\n",
      "[CV] END ..metric=euclidean, n_neighbors=5, weights=distance; total time=   0.0s\n",
      "[CV] END ..metric=euclidean, n_neighbors=5, weights=distance; total time=   0.0s\n",
      "[CV] END ..metric=euclidean, n_neighbors=5, weights=distance; total time=   0.0s\n",
      "[CV] END ..metric=euclidean, n_neighbors=5, weights=distance; total time=   0.0s\n",
      "[CV] END ...metric=euclidean, n_neighbors=7, weights=uniform; total time=   0.1s\n",
      "[CV] END ...metric=euclidean, n_neighbors=7, weights=uniform; total time=   0.1s\n",
      "[CV] END ...metric=euclidean, n_neighbors=7, weights=uniform; total time=   0.1s\n",
      "[CV] END ...metric=euclidean, n_neighbors=7, weights=uniform; total time=   0.1s\n",
      "[CV] END ...metric=euclidean, n_neighbors=7, weights=uniform; total time=   0.1s\n",
      "[CV] END ..metric=euclidean, n_neighbors=7, weights=distance; total time=   0.0s\n",
      "[CV] END ..metric=euclidean, n_neighbors=7, weights=distance; total time=   0.0s\n",
      "[CV] END ..metric=euclidean, n_neighbors=7, weights=distance; total time=   0.0s\n",
      "[CV] END ..metric=euclidean, n_neighbors=7, weights=distance; total time=   0.0s\n",
      "[CV] END ..metric=euclidean, n_neighbors=7, weights=distance; total time=   0.0s\n",
      "[CV] END ...metric=euclidean, n_neighbors=9, weights=uniform; total time=   0.1s\n",
      "[CV] END ...metric=euclidean, n_neighbors=9, weights=uniform; total time=   0.1s\n",
      "[CV] END ...metric=euclidean, n_neighbors=9, weights=uniform; total time=   0.1s\n",
      "[CV] END ...metric=euclidean, n_neighbors=9, weights=uniform; total time=   0.1s\n",
      "[CV] END ...metric=euclidean, n_neighbors=9, weights=uniform; total time=   0.1s\n",
      "[CV] END ..metric=euclidean, n_neighbors=9, weights=distance; total time=   0.0s\n",
      "[CV] END ..metric=euclidean, n_neighbors=9, weights=distance; total time=   0.0s\n",
      "[CV] END ..metric=euclidean, n_neighbors=9, weights=distance; total time=   0.0s\n",
      "[CV] END ..metric=euclidean, n_neighbors=9, weights=distance; total time=   0.0s\n",
      "[CV] END ..metric=euclidean, n_neighbors=9, weights=distance; total time=   0.0s\n",
      "[CV] END ...metric=manhattan, n_neighbors=3, weights=uniform; total time=   0.8s\n",
      "[CV] END ...metric=manhattan, n_neighbors=3, weights=uniform; total time=   0.8s\n",
      "[CV] END ...metric=manhattan, n_neighbors=3, weights=uniform; total time=   0.8s\n",
      "[CV] END ...metric=manhattan, n_neighbors=3, weights=uniform; total time=   0.8s\n",
      "[CV] END ...metric=manhattan, n_neighbors=3, weights=uniform; total time=   0.8s\n",
      "[CV] END ..metric=manhattan, n_neighbors=3, weights=distance; total time=   0.5s\n",
      "[CV] END ..metric=manhattan, n_neighbors=3, weights=distance; total time=   0.5s\n",
      "[CV] END ..metric=manhattan, n_neighbors=3, weights=distance; total time=   0.5s\n",
      "[CV] END ..metric=manhattan, n_neighbors=3, weights=distance; total time=   0.5s\n",
      "[CV] END ..metric=manhattan, n_neighbors=3, weights=distance; total time=   0.5s\n",
      "[CV] END ...metric=manhattan, n_neighbors=5, weights=uniform; total time=   0.8s\n",
      "[CV] END ...metric=manhattan, n_neighbors=5, weights=uniform; total time=   0.8s\n",
      "[CV] END ...metric=manhattan, n_neighbors=5, weights=uniform; total time=   0.8s\n",
      "[CV] END ...metric=manhattan, n_neighbors=5, weights=uniform; total time=   0.8s\n",
      "[CV] END ...metric=manhattan, n_neighbors=5, weights=uniform; total time=   0.8s\n",
      "[CV] END ..metric=manhattan, n_neighbors=5, weights=distance; total time=   0.5s\n",
      "[CV] END ..metric=manhattan, n_neighbors=5, weights=distance; total time=   0.5s\n",
      "[CV] END ..metric=manhattan, n_neighbors=5, weights=distance; total time=   0.5s\n",
      "[CV] END ..metric=manhattan, n_neighbors=5, weights=distance; total time=   0.5s\n",
      "[CV] END ..metric=manhattan, n_neighbors=5, weights=distance; total time=   0.5s\n",
      "[CV] END ...metric=manhattan, n_neighbors=7, weights=uniform; total time=   0.8s\n",
      "[CV] END ...metric=manhattan, n_neighbors=7, weights=uniform; total time=   0.8s\n",
      "[CV] END ...metric=manhattan, n_neighbors=7, weights=uniform; total time=   0.8s\n",
      "[CV] END ...metric=manhattan, n_neighbors=7, weights=uniform; total time=   0.8s\n",
      "[CV] END ...metric=manhattan, n_neighbors=7, weights=uniform; total time=   0.8s\n",
      "[CV] END ..metric=manhattan, n_neighbors=7, weights=distance; total time=   0.5s\n",
      "[CV] END ..metric=manhattan, n_neighbors=7, weights=distance; total time=   0.5s\n",
      "[CV] END ..metric=manhattan, n_neighbors=7, weights=distance; total time=   0.5s\n",
      "[CV] END ..metric=manhattan, n_neighbors=7, weights=distance; total time=   0.5s\n",
      "[CV] END ..metric=manhattan, n_neighbors=7, weights=distance; total time=   0.5s\n",
      "[CV] END ...metric=manhattan, n_neighbors=9, weights=uniform; total time=   0.8s\n",
      "[CV] END ...metric=manhattan, n_neighbors=9, weights=uniform; total time=   0.8s\n",
      "[CV] END ...metric=manhattan, n_neighbors=9, weights=uniform; total time=   0.8s\n",
      "[CV] END ...metric=manhattan, n_neighbors=9, weights=uniform; total time=   0.8s\n",
      "[CV] END ...metric=manhattan, n_neighbors=9, weights=uniform; total time=   0.8s\n",
      "[CV] END ..metric=manhattan, n_neighbors=9, weights=distance; total time=   0.5s\n",
      "[CV] END ..metric=manhattan, n_neighbors=9, weights=distance; total time=   0.5s\n",
      "[CV] END ..metric=manhattan, n_neighbors=9, weights=distance; total time=   0.5s\n",
      "[CV] END ..metric=manhattan, n_neighbors=9, weights=distance; total time=   0.5s\n",
      "[CV] END ..metric=manhattan, n_neighbors=9, weights=distance; total time=   0.5s\n",
      "[CV] END ...metric=minkowski, n_neighbors=3, weights=uniform; total time=   0.0s\n",
      "[CV] END ...metric=minkowski, n_neighbors=3, weights=uniform; total time=   0.0s\n",
      "[CV] END ...metric=minkowski, n_neighbors=3, weights=uniform; total time=   0.0s\n",
      "[CV] END ...metric=minkowski, n_neighbors=3, weights=uniform; total time=   0.0s\n",
      "[CV] END ...metric=minkowski, n_neighbors=3, weights=uniform; total time=   0.0s\n",
      "[CV] END ..metric=minkowski, n_neighbors=3, weights=distance; total time=   0.0s\n",
      "[CV] END ..metric=minkowski, n_neighbors=3, weights=distance; total time=   0.0s\n",
      "[CV] END ..metric=minkowski, n_neighbors=3, weights=distance; total time=   0.0s\n",
      "[CV] END ..metric=minkowski, n_neighbors=3, weights=distance; total time=   0.0s\n",
      "[CV] END ..metric=minkowski, n_neighbors=3, weights=distance; total time=   0.0s\n",
      "[CV] END ...metric=minkowski, n_neighbors=5, weights=uniform; total time=   0.0s\n",
      "[CV] END ...metric=minkowski, n_neighbors=5, weights=uniform; total time=   0.0s\n",
      "[CV] END ...metric=minkowski, n_neighbors=5, weights=uniform; total time=   0.0s\n",
      "[CV] END ...metric=minkowski, n_neighbors=5, weights=uniform; total time=   0.0s\n",
      "[CV] END ...metric=minkowski, n_neighbors=5, weights=uniform; total time=   0.0s\n",
      "[CV] END ..metric=minkowski, n_neighbors=5, weights=distance; total time=   0.0s\n",
      "[CV] END ..metric=minkowski, n_neighbors=5, weights=distance; total time=   0.0s\n",
      "[CV] END ..metric=minkowski, n_neighbors=5, weights=distance; total time=   0.0s\n",
      "[CV] END ..metric=minkowski, n_neighbors=5, weights=distance; total time=   0.0s\n",
      "[CV] END ..metric=minkowski, n_neighbors=5, weights=distance; total time=   0.0s\n",
      "[CV] END ...metric=minkowski, n_neighbors=7, weights=uniform; total time=   0.0s\n",
      "[CV] END ...metric=minkowski, n_neighbors=7, weights=uniform; total time=   0.0s\n",
      "[CV] END ...metric=minkowski, n_neighbors=7, weights=uniform; total time=   0.0s\n",
      "[CV] END ...metric=minkowski, n_neighbors=7, weights=uniform; total time=   0.0s\n",
      "[CV] END ...metric=minkowski, n_neighbors=7, weights=uniform; total time=   0.0s\n",
      "[CV] END ..metric=minkowski, n_neighbors=7, weights=distance; total time=   0.0s\n",
      "[CV] END ..metric=minkowski, n_neighbors=7, weights=distance; total time=   0.0s\n",
      "[CV] END ..metric=minkowski, n_neighbors=7, weights=distance; total time=   0.0s\n",
      "[CV] END ..metric=minkowski, n_neighbors=7, weights=distance; total time=   0.0s\n",
      "[CV] END ..metric=minkowski, n_neighbors=7, weights=distance; total time=   0.0s\n",
      "[CV] END ...metric=minkowski, n_neighbors=9, weights=uniform; total time=   0.0s\n",
      "[CV] END ...metric=minkowski, n_neighbors=9, weights=uniform; total time=   0.0s\n",
      "[CV] END ...metric=minkowski, n_neighbors=9, weights=uniform; total time=   0.0s\n",
      "[CV] END ...metric=minkowski, n_neighbors=9, weights=uniform; total time=   0.0s\n",
      "[CV] END ...metric=minkowski, n_neighbors=9, weights=uniform; total time=   0.0s\n",
      "[CV] END ..metric=minkowski, n_neighbors=9, weights=distance; total time=   0.0s\n",
      "[CV] END ..metric=minkowski, n_neighbors=9, weights=distance; total time=   0.0s\n",
      "[CV] END ..metric=minkowski, n_neighbors=9, weights=distance; total time=   0.0s\n",
      "[CV] END ..metric=minkowski, n_neighbors=9, weights=distance; total time=   0.0s\n",
      "[CV] END ..metric=minkowski, n_neighbors=9, weights=distance; total time=   0.0s\n",
      "Best Parameters:  {'metric': 'manhattan', 'n_neighbors': 9, 'weights': 'distance'}\n",
      "Best Score:  0.44042156186848047\n",
      "Accuracy on Test Set:  0.4591121495327103\n",
      "Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.04      0.07        70\n",
      "           1       0.21      0.13      0.16       269\n",
      "           2       0.28      0.22      0.25       297\n",
      "           3       0.28      0.17      0.21       476\n",
      "           4       0.25      0.08      0.12       173\n",
      "           5       0.40      0.03      0.05        78\n",
      "           6       0.54      0.81      0.65      1205\n",
      "\n",
      "    accuracy                           0.46      2568\n",
      "   macro avg       0.32      0.21      0.22      2568\n",
      "weighted avg       0.40      0.46      0.40      2568\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the parameter grid for KNN\n",
    "param_grid = {\n",
    "    'n_neighbors': [3, 5, 7, 9],  # Number of neighbors to use\n",
    "    'weights': ['uniform', 'distance'],  # Weight function used in prediction\n",
    "    'metric': ['euclidean', 'manhattan', 'minkowski'],  # Metric used for the distance computation\n",
    "}\n",
    "\n",
    "# Initialize the KNN classifier\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "# Initialize GridSearchCV object with KNN classifier and the parameter grid\n",
    "grid_search = GridSearchCV(estimator=knn, param_grid=param_grid, cv=5, scoring='accuracy', verbose=2)\n",
    "\n",
    "# Fit the model with the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters and the best score\n",
    "print(\"Best Parameters: \", grid_search.best_params_)\n",
    "print(\"Best Score: \", grid_search.best_score_)\n",
    "\n",
    "# Predict on the test set with the best parameters\n",
    "y_pred = grid_search.predict(X_test)\n",
    "\n",
    "# Evaluate the classifier with the best parameters\n",
    "print(\"Accuracy on Test Set: \", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report: \")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "272ef6c7",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "64fc99f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.46845794392523366\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        70\n",
      "           1       0.00      0.00      0.00       269\n",
      "           2       0.00      0.00      0.00       297\n",
      "           3       0.20      0.00      0.00       476\n",
      "           4       0.00      0.00      0.00       173\n",
      "           5       0.00      0.00      0.00        78\n",
      "           6       0.47      1.00      0.64      1205\n",
      "\n",
      "    accuracy                           0.47      2568\n",
      "   macro avg       0.10      0.14      0.09      2568\n",
      "weighted avg       0.26      0.47      0.30      2568\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Initialize the Logistic Regression classifier\n",
    "# Set to multi-class since we have a lot of classes (300 in total)\n",
    "logreg = LogisticRegression(max_iter=1000, multi_class='multinomial', solver='lbfgs')\n",
    "\n",
    "# Fitting Logistic Regression to the Training set\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "# Making the Confusion Matrix\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "d53ffcd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
      "[CV] END ...................C=0.01, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...................C=0.01, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...................C=0.01, penalty=l2, solver=lbfgs; total time=   0.1s\n",
      "[CV] END ...................C=0.01, penalty=l2, solver=lbfgs; total time=   0.1s\n",
      "[CV] END ...................C=0.01, penalty=l2, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ....................C=0.01, penalty=l2, solver=saga; total time=   1.4s\n",
      "[CV] END ....................C=0.01, penalty=l2, solver=saga; total time=   1.3s\n",
      "[CV] END ....................C=0.01, penalty=l2, solver=saga; total time=   1.3s\n",
      "[CV] END ....................C=0.01, penalty=l2, solver=saga; total time=   1.3s\n",
      "[CV] END ....................C=0.01, penalty=l2, solver=saga; total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:204: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...............C=0.01, penalty=l2, solver=newton-cg; total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:204: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...............C=0.01, penalty=l2, solver=newton-cg; total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:204: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...............C=0.01, penalty=l2, solver=newton-cg; total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:204: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...............C=0.01, penalty=l2, solver=newton-cg; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:204: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...............C=0.01, penalty=l2, solver=newton-cg; total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .................C=0.01, penalty=None, solver=lbfgs; total time=   3.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .................C=0.01, penalty=None, solver=lbfgs; total time=   3.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .................C=0.01, penalty=None, solver=lbfgs; total time=   3.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .................C=0.01, penalty=None, solver=lbfgs; total time=   3.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .................C=0.01, penalty=None, solver=lbfgs; total time=   3.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..................C=0.01, penalty=None, solver=saga; total time= 1.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..................C=0.01, penalty=None, solver=saga; total time= 1.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..................C=0.01, penalty=None, solver=saga; total time= 1.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..................C=0.01, penalty=None, solver=saga; total time= 1.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..................C=0.01, penalty=None, solver=saga; total time= 1.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:204: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .............C=0.01, penalty=None, solver=newton-cg; total time= 1.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:204: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .............C=0.01, penalty=None, solver=newton-cg; total time=  21.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:204: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .............C=0.01, penalty=None, solver=newton-cg; total time=  41.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:204: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .............C=0.01, penalty=None, solver=newton-cg; total time=  40.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:204: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .............C=0.01, penalty=None, solver=newton-cg; total time=  50.6s\n",
      "[CV] END ....................C=0.1, penalty=l2, solver=lbfgs; total time=   0.2s\n",
      "[CV] END ....................C=0.1, penalty=l2, solver=lbfgs; total time=   0.2s\n",
      "[CV] END ....................C=0.1, penalty=l2, solver=lbfgs; total time=   0.2s\n",
      "[CV] END ....................C=0.1, penalty=l2, solver=lbfgs; total time=   0.2s\n",
      "[CV] END ....................C=0.1, penalty=l2, solver=lbfgs; total time=   0.2s\n",
      "[CV] END .....................C=0.1, penalty=l2, solver=saga; total time=   1.1s\n",
      "[CV] END .....................C=0.1, penalty=l2, solver=saga; total time=   1.2s\n",
      "[CV] END .....................C=0.1, penalty=l2, solver=saga; total time=   1.2s\n",
      "[CV] END .....................C=0.1, penalty=l2, solver=saga; total time=   1.1s\n",
      "[CV] END .....................C=0.1, penalty=l2, solver=saga; total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:204: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................C=0.1, penalty=l2, solver=newton-cg; total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:204: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................C=0.1, penalty=l2, solver=newton-cg; total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:204: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................C=0.1, penalty=l2, solver=newton-cg; total time=   1.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:204: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................C=0.1, penalty=l2, solver=newton-cg; total time=   1.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:204: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................C=0.1, penalty=l2, solver=newton-cg; total time=   1.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..................C=0.1, penalty=None, solver=lbfgs; total time=   3.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..................C=0.1, penalty=None, solver=lbfgs; total time=   3.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..................C=0.1, penalty=None, solver=lbfgs; total time=   3.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..................C=0.1, penalty=None, solver=lbfgs; total time=   3.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..................C=0.1, penalty=None, solver=lbfgs; total time=   3.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...................C=0.1, penalty=None, solver=saga; total time= 1.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...................C=0.1, penalty=None, solver=saga; total time= 1.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...................C=0.1, penalty=None, solver=saga; total time= 1.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...................C=0.1, penalty=None, solver=saga; total time= 1.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...................C=0.1, penalty=None, solver=saga; total time= 1.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:204: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............C=0.1, penalty=None, solver=newton-cg; total time= 1.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:204: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............C=0.1, penalty=None, solver=newton-cg; total time=  20.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:204: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............C=0.1, penalty=None, solver=newton-cg; total time=  40.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:204: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............C=0.1, penalty=None, solver=newton-cg; total time=  39.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:204: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............C=0.1, penalty=None, solver=newton-cg; total time=  50.0s\n",
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   0.7s\n",
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   0.7s\n",
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   0.7s\n",
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   0.7s\n",
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   0.7s\n",
      "[CV] END .......................C=1, penalty=l2, solver=saga; total time=   2.8s\n",
      "[CV] END .......................C=1, penalty=l2, solver=saga; total time=   2.7s\n",
      "[CV] END .......................C=1, penalty=l2, solver=saga; total time=   2.7s\n",
      "[CV] END .......................C=1, penalty=l2, solver=saga; total time=   2.8s\n",
      "[CV] END .......................C=1, penalty=l2, solver=saga; total time=   2.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:204: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..................C=1, penalty=l2, solver=newton-cg; total time=   2.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:204: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..................C=1, penalty=l2, solver=newton-cg; total time=   2.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:204: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..................C=1, penalty=l2, solver=newton-cg; total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:204: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..................C=1, penalty=l2, solver=newton-cg; total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:204: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..................C=1, penalty=l2, solver=newton-cg; total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ....................C=1, penalty=None, solver=lbfgs; total time=   3.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ....................C=1, penalty=None, solver=lbfgs; total time=   3.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ....................C=1, penalty=None, solver=lbfgs; total time=   3.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ....................C=1, penalty=None, solver=lbfgs; total time=   3.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ....................C=1, penalty=None, solver=lbfgs; total time=   3.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .....................C=1, penalty=None, solver=saga; total time= 1.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .....................C=1, penalty=None, solver=saga; total time= 1.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .....................C=1, penalty=None, solver=saga; total time= 1.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .....................C=1, penalty=None, solver=saga; total time= 1.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .....................C=1, penalty=None, solver=saga; total time= 1.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:204: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................C=1, penalty=None, solver=newton-cg; total time= 1.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:204: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................C=1, penalty=None, solver=newton-cg; total time=  20.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:204: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................C=1, penalty=None, solver=newton-cg; total time=  42.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:204: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................C=1, penalty=None, solver=newton-cg; total time=  40.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:204: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................C=1, penalty=None, solver=newton-cg; total time=  50.8s\n",
      "[CV] END .....................C=10, penalty=l2, solver=lbfgs; total time=   1.9s\n",
      "[CV] END .....................C=10, penalty=l2, solver=lbfgs; total time=   1.9s\n",
      "[CV] END .....................C=10, penalty=l2, solver=lbfgs; total time=   2.0s\n",
      "[CV] END .....................C=10, penalty=l2, solver=lbfgs; total time=   2.0s\n",
      "[CV] END .....................C=10, penalty=l2, solver=lbfgs; total time=   1.9s\n",
      "[CV] END ......................C=10, penalty=l2, solver=saga; total time=  16.3s\n",
      "[CV] END ......................C=10, penalty=l2, solver=saga; total time=  19.2s\n",
      "[CV] END ......................C=10, penalty=l2, solver=saga; total time=  15.4s\n",
      "[CV] END ......................C=10, penalty=l2, solver=saga; total time=  15.0s\n",
      "[CV] END ......................C=10, penalty=l2, solver=saga; total time=  20.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:204: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .................C=10, penalty=l2, solver=newton-cg; total time=   2.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:204: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .................C=10, penalty=l2, solver=newton-cg; total time=   3.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:204: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .................C=10, penalty=l2, solver=newton-cg; total time=   2.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:204: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .................C=10, penalty=l2, solver=newton-cg; total time=   3.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:204: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .................C=10, penalty=l2, solver=newton-cg; total time=   2.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...................C=10, penalty=None, solver=lbfgs; total time=   3.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...................C=10, penalty=None, solver=lbfgs; total time=   3.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...................C=10, penalty=None, solver=lbfgs; total time=   3.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...................C=10, penalty=None, solver=lbfgs; total time=   3.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...................C=10, penalty=None, solver=lbfgs; total time=   3.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ....................C=10, penalty=None, solver=saga; total time= 1.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ....................C=10, penalty=None, solver=saga; total time= 1.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ....................C=10, penalty=None, solver=saga; total time= 1.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ....................C=10, penalty=None, solver=saga; total time= 1.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ....................C=10, penalty=None, solver=saga; total time= 1.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:204: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...............C=10, penalty=None, solver=newton-cg; total time= 1.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:204: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...............C=10, penalty=None, solver=newton-cg; total time=  20.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:204: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...............C=10, penalty=None, solver=newton-cg; total time=  40.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:204: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...............C=10, penalty=None, solver=newton-cg; total time=  40.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:204: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...............C=10, penalty=None, solver=newton-cg; total time=  51.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ....................C=100, penalty=l2, solver=lbfgs; total time=   3.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ....................C=100, penalty=l2, solver=lbfgs; total time=   3.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ....................C=100, penalty=l2, solver=lbfgs; total time=   3.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ....................C=100, penalty=l2, solver=lbfgs; total time=   3.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ....................C=100, penalty=l2, solver=lbfgs; total time=   3.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .....................C=100, penalty=l2, solver=saga; total time= 1.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .....................C=100, penalty=l2, solver=saga; total time= 1.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .....................C=100, penalty=l2, solver=saga; total time= 1.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .....................C=100, penalty=l2, solver=saga; total time= 1.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .....................C=100, penalty=l2, solver=saga; total time= 1.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:204: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................C=100, penalty=l2, solver=newton-cg; total time=   5.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:204: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................C=100, penalty=l2, solver=newton-cg; total time=   6.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:204: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................C=100, penalty=l2, solver=newton-cg; total time=  10.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:204: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................C=100, penalty=l2, solver=newton-cg; total time=   6.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:204: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................C=100, penalty=l2, solver=newton-cg; total time=   9.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..................C=100, penalty=None, solver=lbfgs; total time=   3.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..................C=100, penalty=None, solver=lbfgs; total time=   3.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..................C=100, penalty=None, solver=lbfgs; total time=   3.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..................C=100, penalty=None, solver=lbfgs; total time=   3.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..................C=100, penalty=None, solver=lbfgs; total time=   3.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...................C=100, penalty=None, solver=saga; total time= 1.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...................C=100, penalty=None, solver=saga; total time= 1.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...................C=100, penalty=None, solver=saga; total time= 1.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...................C=100, penalty=None, solver=saga; total time= 1.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...................C=100, penalty=None, solver=saga; total time= 1.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:204: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............C=100, penalty=None, solver=newton-cg; total time= 1.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:204: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............C=100, penalty=None, solver=newton-cg; total time=  20.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:204: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............C=100, penalty=None, solver=newton-cg; total time=  41.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:204: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............C=100, penalty=None, solver=newton-cg; total time=  39.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:204: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............C=100, penalty=None, solver=newton-cg; total time=  49.8s\n",
      "Best Parameters:  {'C': 0.1, 'penalty': None, 'solver': 'saga'}\n",
      "Best Score:  0.486468607926614\n",
      "Accuracy on Test Set:  0.4929906542056075\n",
      "Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        70\n",
      "           1       0.33      0.22      0.26       269\n",
      "           2       0.32      0.19      0.24       297\n",
      "           3       0.31      0.11      0.16       476\n",
      "           4       1.00      0.01      0.02       173\n",
      "           5       0.00      0.00      0.00        78\n",
      "           6       0.54      0.91      0.68      1205\n",
      "\n",
      "    accuracy                           0.49      2568\n",
      "   macro avg       0.36      0.21      0.19      2568\n",
      "weighted avg       0.45      0.49      0.40      2568\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Define the parameter grid for Logistic Regression\n",
    "param_grid = {\n",
    "    'penalty': ['l2', None],  # Norm used in the penalization\n",
    "    'C': [0.01, 0.1, 1, 10, 100],  # Inverse of regularization strength\n",
    "    'solver': ['lbfgs', 'saga', 'newton-cg']  # Algorithm to use in the optimization problem\n",
    "}\n",
    "\n",
    "# Note: 'saga' solver supports both l1 and l2 penalty, while 'lbfgs' and 'newton-cg' support only l2.\n",
    "# Make sure the combinations of solver and penalty are compatible.\n",
    "\n",
    "# Initialize the Logistic Regression classifier\n",
    "logreg = LogisticRegression(max_iter=1000, multi_class='multinomial')\n",
    "\n",
    "# Initialize GridSearchCV object with Logistic Regression classifier and the parameter grid\n",
    "grid_search = GridSearchCV(estimator=logreg, param_grid=param_grid, cv=5, scoring='accuracy', verbose=2)\n",
    "\n",
    "# Fit the model with the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters and the best score\n",
    "print(\"Best Parameters: \", grid_search.best_params_)\n",
    "print(\"Best Score: \", grid_search.best_score_)\n",
    "\n",
    "# Predict on the test set with the best parameters\n",
    "y_pred = grid_search.predict(X_test)\n",
    "\n",
    "# Evaluate the classifier with the best parameters\n",
    "print(\"Accuracy on Test Set: \", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report: \")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa65ce4",
   "metadata": {},
   "source": [
    "### Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "db092b23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.33372274143302183\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.06      0.06      0.06        70\n",
      "           1       0.15      0.20      0.17       269\n",
      "           2       0.20      0.21      0.20       297\n",
      "           3       0.19      0.19      0.19       476\n",
      "           4       0.11      0.10      0.11       173\n",
      "           5       0.08      0.08      0.08        78\n",
      "           6       0.55      0.52      0.53      1205\n",
      "\n",
      "    accuracy                           0.33      2568\n",
      "   macro avg       0.19      0.19      0.19      2568\n",
      "weighted avg       0.34      0.33      0.34      2568\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize the Decision Tree classifier\n",
    "decision_tree = DecisionTreeClassifier(max_depth=None, criterion='gini', random_state=42)\n",
    "\n",
    "# Fitting the Decision Tree to the Training set\n",
    "decision_tree.fit(X_train, y_train)\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = decision_tree.predict(X_test)\n",
    "\n",
    "# Evaluating the model\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "b4537493",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 90 candidates, totalling 450 fits\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=2; total time=   6.5s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=2; total time=   6.2s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=2; total time=   5.6s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=2; total time=   6.8s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=2; total time=   6.1s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=5; total time=   6.4s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=5; total time=   6.2s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=5; total time=   5.5s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=5; total time=   6.5s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=5; total time=   6.1s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=10; total time=   6.3s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=10; total time=   6.2s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=10; total time=   5.4s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=10; total time=   6.6s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=10; total time=   6.1s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=2, min_samples_split=2; total time=   6.1s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=2, min_samples_split=2; total time=   5.8s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=2, min_samples_split=2; total time=   5.3s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=2, min_samples_split=2; total time=   6.3s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=2, min_samples_split=2; total time=   5.8s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=2, min_samples_split=5; total time=   6.1s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=2, min_samples_split=5; total time=   5.8s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=2, min_samples_split=5; total time=   5.3s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=2, min_samples_split=5; total time=   6.3s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=2, min_samples_split=5; total time=   5.7s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=2, min_samples_split=10; total time=   6.0s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=2, min_samples_split=10; total time=   5.7s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=2, min_samples_split=10; total time=   5.2s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=2, min_samples_split=10; total time=   6.2s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=2, min_samples_split=10; total time=   5.7s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=4, min_samples_split=2; total time=   5.6s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=4, min_samples_split=2; total time=   5.1s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=4, min_samples_split=2; total time=   4.8s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=4, min_samples_split=2; total time=   5.8s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=4, min_samples_split=2; total time=   5.1s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=4, min_samples_split=5; total time=   5.6s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=4, min_samples_split=5; total time=   5.1s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=4, min_samples_split=5; total time=   4.9s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=4, min_samples_split=5; total time=   5.8s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=4, min_samples_split=5; total time=   5.1s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=4, min_samples_split=10; total time=   5.7s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=4, min_samples_split=10; total time=   5.1s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=4, min_samples_split=10; total time=   4.8s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=4, min_samples_split=10; total time=   5.9s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=4, min_samples_split=10; total time=   5.0s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=2; total time=   3.0s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=2; total time=   3.0s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=2; total time=   2.9s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=2; total time=   3.0s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=2; total time=   3.0s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=5; total time=   3.0s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=5; total time=   2.9s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=5; total time=   3.0s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=5; total time=   3.0s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=5; total time=   2.9s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=10; total time=   2.9s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=10; total time=   3.0s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=10; total time=   2.9s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=10; total time=   2.9s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=10; total time=   2.9s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=2, min_samples_split=2; total time=   3.0s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=2, min_samples_split=2; total time=   2.9s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=2, min_samples_split=2; total time=   3.0s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=2, min_samples_split=2; total time=   3.0s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=2, min_samples_split=2; total time=   3.0s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=2, min_samples_split=5; total time=   3.0s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=2, min_samples_split=5; total time=   2.9s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=2, min_samples_split=5; total time=   2.9s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=2, min_samples_split=5; total time=   3.0s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=2, min_samples_split=5; total time=   2.9s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=2, min_samples_split=10; total time=   3.0s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=2, min_samples_split=10; total time=   2.9s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=2, min_samples_split=10; total time=   2.9s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=2, min_samples_split=10; total time=   3.0s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=2, min_samples_split=10; total time=   2.9s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=4, min_samples_split=2; total time=   2.9s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=4, min_samples_split=2; total time=   2.9s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=4, min_samples_split=2; total time=   2.9s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=4, min_samples_split=2; total time=   3.0s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=4, min_samples_split=2; total time=   2.9s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=4, min_samples_split=5; total time=   3.0s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=4, min_samples_split=5; total time=   2.9s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=4, min_samples_split=5; total time=   2.9s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=4, min_samples_split=5; total time=   2.9s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=4, min_samples_split=5; total time=   2.9s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=4, min_samples_split=10; total time=   2.9s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=4, min_samples_split=10; total time=   2.9s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=4, min_samples_split=10; total time=   2.9s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=4, min_samples_split=10; total time=   2.9s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=4, min_samples_split=10; total time=   2.9s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=1, min_samples_split=2; total time=   4.9s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=1, min_samples_split=2; total time=   4.8s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=1, min_samples_split=2; total time=   4.7s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=1, min_samples_split=2; total time=   4.9s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=1, min_samples_split=2; total time=   4.8s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=1, min_samples_split=5; total time=   5.0s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=1, min_samples_split=5; total time=   4.8s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=1, min_samples_split=5; total time=   4.7s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=1, min_samples_split=5; total time=   4.8s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=1, min_samples_split=5; total time=   4.8s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=1, min_samples_split=10; total time=   4.8s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=1, min_samples_split=10; total time=   4.7s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=1, min_samples_split=10; total time=   4.7s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=1, min_samples_split=10; total time=   4.8s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=1, min_samples_split=10; total time=   4.7s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=2, min_samples_split=2; total time=   4.9s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=2, min_samples_split=2; total time=   4.7s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=2, min_samples_split=2; total time=   4.7s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=2, min_samples_split=2; total time=   4.8s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=2, min_samples_split=2; total time=   4.7s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=2, min_samples_split=5; total time=   4.8s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=2, min_samples_split=5; total time=   4.7s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=2, min_samples_split=5; total time=   4.6s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=2, min_samples_split=5; total time=   4.8s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=2, min_samples_split=5; total time=   4.7s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=2, min_samples_split=10; total time=   4.8s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=2, min_samples_split=10; total time=   4.6s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=2, min_samples_split=10; total time=   4.6s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=2, min_samples_split=10; total time=   4.7s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=2, min_samples_split=10; total time=   4.7s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=4, min_samples_split=2; total time=   4.7s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=4, min_samples_split=2; total time=   4.5s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=4, min_samples_split=2; total time=   4.5s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=4, min_samples_split=2; total time=   4.6s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=4, min_samples_split=2; total time=   4.5s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=4, min_samples_split=5; total time=   4.6s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=4, min_samples_split=5; total time=   4.5s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=4, min_samples_split=5; total time=   4.4s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=4, min_samples_split=5; total time=   4.6s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=4, min_samples_split=5; total time=   4.5s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=4, min_samples_split=10; total time=   4.6s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=4, min_samples_split=10; total time=   4.5s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=4, min_samples_split=10; total time=   4.4s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=4, min_samples_split=10; total time=   4.6s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=4, min_samples_split=10; total time=   4.4s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=1, min_samples_split=2; total time=   5.9s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=1, min_samples_split=2; total time=   5.6s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=1, min_samples_split=2; total time=   5.4s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=1, min_samples_split=2; total time=   5.7s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=1, min_samples_split=2; total time=   5.6s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=1, min_samples_split=5; total time=   5.8s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=1, min_samples_split=5; total time=   5.6s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=1, min_samples_split=5; total time=   5.4s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=1, min_samples_split=5; total time=   5.7s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=1, min_samples_split=5; total time=   5.6s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=1, min_samples_split=10; total time=   5.8s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=1, min_samples_split=10; total time=   5.5s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=1, min_samples_split=10; total time=   5.2s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=1, min_samples_split=10; total time=   5.7s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=1, min_samples_split=10; total time=   5.5s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=2, min_samples_split=2; total time=   5.7s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=2, min_samples_split=2; total time=   5.5s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=2, min_samples_split=2; total time=   5.2s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=2, min_samples_split=2; total time=   5.6s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=2, min_samples_split=2; total time=   5.4s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=2, min_samples_split=5; total time=   5.6s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=2, min_samples_split=5; total time=   5.4s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=2, min_samples_split=5; total time=   5.2s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=2, min_samples_split=5; total time=   5.5s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=2, min_samples_split=5; total time=   5.4s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=2, min_samples_split=10; total time=   5.6s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=2, min_samples_split=10; total time=   5.3s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=2, min_samples_split=10; total time=   5.2s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=2, min_samples_split=10; total time=   5.6s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=2, min_samples_split=10; total time=   5.4s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=4, min_samples_split=2; total time=   5.3s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=4, min_samples_split=2; total time=   5.1s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=4, min_samples_split=2; total time=   4.9s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=4, min_samples_split=2; total time=   5.4s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=4, min_samples_split=2; total time=   5.0s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=4, min_samples_split=5; total time=   5.3s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=4, min_samples_split=5; total time=   5.0s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=4, min_samples_split=5; total time=   4.8s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=4, min_samples_split=5; total time=   5.3s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=4, min_samples_split=5; total time=   5.0s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=4, min_samples_split=10; total time=   5.3s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=4, min_samples_split=10; total time=   5.0s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=4, min_samples_split=10; total time=   4.8s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=4, min_samples_split=10; total time=   5.5s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=4, min_samples_split=10; total time=   5.0s\n",
      "[CV] END criterion=gini, max_depth=40, min_samples_leaf=1, min_samples_split=2; total time=   6.3s\n",
      "[CV] END criterion=gini, max_depth=40, min_samples_leaf=1, min_samples_split=2; total time=   5.9s\n",
      "[CV] END criterion=gini, max_depth=40, min_samples_leaf=1, min_samples_split=2; total time=   5.5s\n",
      "[CV] END criterion=gini, max_depth=40, min_samples_leaf=1, min_samples_split=2; total time=   6.3s\n",
      "[CV] END criterion=gini, max_depth=40, min_samples_leaf=1, min_samples_split=2; total time=   6.0s\n",
      "[CV] END criterion=gini, max_depth=40, min_samples_leaf=1, min_samples_split=5; total time=   6.2s\n",
      "[CV] END criterion=gini, max_depth=40, min_samples_leaf=1, min_samples_split=5; total time=   5.9s\n",
      "[CV] END criterion=gini, max_depth=40, min_samples_leaf=1, min_samples_split=5; total time=   5.5s\n",
      "[CV] END criterion=gini, max_depth=40, min_samples_leaf=1, min_samples_split=5; total time=   6.2s\n",
      "[CV] END criterion=gini, max_depth=40, min_samples_leaf=1, min_samples_split=5; total time=   6.0s\n",
      "[CV] END criterion=gini, max_depth=40, min_samples_leaf=1, min_samples_split=10; total time=   6.1s\n",
      "[CV] END criterion=gini, max_depth=40, min_samples_leaf=1, min_samples_split=10; total time=   5.8s\n",
      "[CV] END criterion=gini, max_depth=40, min_samples_leaf=1, min_samples_split=10; total time=   5.4s\n",
      "[CV] END criterion=gini, max_depth=40, min_samples_leaf=1, min_samples_split=10; total time=   6.2s\n",
      "[CV] END criterion=gini, max_depth=40, min_samples_leaf=1, min_samples_split=10; total time=   5.8s\n",
      "[CV] END criterion=gini, max_depth=40, min_samples_leaf=2, min_samples_split=2; total time=   6.0s\n",
      "[CV] END criterion=gini, max_depth=40, min_samples_leaf=2, min_samples_split=2; total time=   5.7s\n",
      "[CV] END criterion=gini, max_depth=40, min_samples_leaf=2, min_samples_split=2; total time=   5.3s\n",
      "[CV] END criterion=gini, max_depth=40, min_samples_leaf=2, min_samples_split=2; total time=   6.0s\n",
      "[CV] END criterion=gini, max_depth=40, min_samples_leaf=2, min_samples_split=2; total time=   5.7s\n",
      "[CV] END criterion=gini, max_depth=40, min_samples_leaf=2, min_samples_split=5; total time=   6.0s\n",
      "[CV] END criterion=gini, max_depth=40, min_samples_leaf=2, min_samples_split=5; total time=   5.7s\n",
      "[CV] END criterion=gini, max_depth=40, min_samples_leaf=2, min_samples_split=5; total time=   5.3s\n",
      "[CV] END criterion=gini, max_depth=40, min_samples_leaf=2, min_samples_split=5; total time=   6.0s\n",
      "[CV] END criterion=gini, max_depth=40, min_samples_leaf=2, min_samples_split=5; total time=   5.7s\n",
      "[CV] END criterion=gini, max_depth=40, min_samples_leaf=2, min_samples_split=10; total time=   5.9s\n",
      "[CV] END criterion=gini, max_depth=40, min_samples_leaf=2, min_samples_split=10; total time=   5.6s\n",
      "[CV] END criterion=gini, max_depth=40, min_samples_leaf=2, min_samples_split=10; total time=   5.3s\n",
      "[CV] END criterion=gini, max_depth=40, min_samples_leaf=2, min_samples_split=10; total time=   6.0s\n",
      "[CV] END criterion=gini, max_depth=40, min_samples_leaf=2, min_samples_split=10; total time=   5.7s\n",
      "[CV] END criterion=gini, max_depth=40, min_samples_leaf=4, min_samples_split=2; total time=   5.6s\n",
      "[CV] END criterion=gini, max_depth=40, min_samples_leaf=4, min_samples_split=2; total time=   5.1s\n",
      "[CV] END criterion=gini, max_depth=40, min_samples_leaf=4, min_samples_split=2; total time=   4.9s\n",
      "[CV] END criterion=gini, max_depth=40, min_samples_leaf=4, min_samples_split=2; total time=   5.6s\n",
      "[CV] END criterion=gini, max_depth=40, min_samples_leaf=4, min_samples_split=2; total time=   5.0s\n",
      "[CV] END criterion=gini, max_depth=40, min_samples_leaf=4, min_samples_split=5; total time=   5.6s\n",
      "[CV] END criterion=gini, max_depth=40, min_samples_leaf=4, min_samples_split=5; total time=   5.1s\n",
      "[CV] END criterion=gini, max_depth=40, min_samples_leaf=4, min_samples_split=5; total time=   4.8s\n",
      "[CV] END criterion=gini, max_depth=40, min_samples_leaf=4, min_samples_split=5; total time=   5.7s\n",
      "[CV] END criterion=gini, max_depth=40, min_samples_leaf=4, min_samples_split=5; total time=   5.0s\n",
      "[CV] END criterion=gini, max_depth=40, min_samples_leaf=4, min_samples_split=10; total time=   5.5s\n",
      "[CV] END criterion=gini, max_depth=40, min_samples_leaf=4, min_samples_split=10; total time=   5.2s\n",
      "[CV] END criterion=gini, max_depth=40, min_samples_leaf=4, min_samples_split=10; total time=   5.0s\n",
      "[CV] END criterion=gini, max_depth=40, min_samples_leaf=4, min_samples_split=10; total time=   5.8s\n",
      "[CV] END criterion=gini, max_depth=40, min_samples_leaf=4, min_samples_split=10; total time=   5.1s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=2; total time=   9.8s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=2; total time=   8.4s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=2; total time=   7.7s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=2; total time=   8.7s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=2; total time=   8.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=5; total time=   9.5s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=5; total time=   8.1s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=5; total time=   7.5s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=5; total time=   8.6s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=5; total time=   8.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=10; total time=   9.4s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=10; total time=   7.9s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=10; total time=   7.3s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=10; total time=   8.5s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=10; total time=   7.8s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=2, min_samples_split=2; total time=   9.4s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=2, min_samples_split=2; total time=   8.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=2, min_samples_split=2; total time=   7.3s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=2, min_samples_split=2; total time=   8.5s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=2, min_samples_split=2; total time=   7.9s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=2, min_samples_split=5; total time=   9.4s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=2, min_samples_split=5; total time=   8.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=2, min_samples_split=5; total time=   7.3s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=2, min_samples_split=5; total time=   8.5s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=2, min_samples_split=5; total time=   7.9s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=2, min_samples_split=10; total time=   9.3s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=2, min_samples_split=10; total time=   7.9s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=2, min_samples_split=10; total time=   7.2s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=2, min_samples_split=10; total time=   8.4s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=2, min_samples_split=10; total time=   7.8s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=4, min_samples_split=2; total time=   9.1s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=4, min_samples_split=2; total time=   7.6s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=4, min_samples_split=2; total time=   7.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=4, min_samples_split=2; total time=   8.2s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=4, min_samples_split=2; total time=   7.6s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=4, min_samples_split=5; total time=   9.1s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=4, min_samples_split=5; total time=   7.6s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=4, min_samples_split=5; total time=   7.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=4, min_samples_split=5; total time=   8.2s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=4, min_samples_split=5; total time=   7.6s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=4, min_samples_split=10; total time=   9.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=4, min_samples_split=10; total time=   7.6s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=4, min_samples_split=10; total time=   7.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=4, min_samples_split=10; total time=   8.2s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=4, min_samples_split=10; total time=   7.5s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=2; total time=   5.7s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=2; total time=   5.7s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=2; total time=   5.6s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=2; total time=   5.7s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=2; total time=   5.7s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=5; total time=   5.7s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=5; total time=   5.7s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=5; total time=   5.6s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=5; total time=   5.7s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=5; total time=   5.7s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=10; total time=   5.6s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=10; total time=   5.6s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=10; total time=   5.6s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=10; total time=   5.7s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=10; total time=   5.6s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=2; total time=   5.6s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=2; total time=   5.6s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=2; total time=   5.6s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=2; total time=   5.7s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=2; total time=   5.6s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=5; total time=   5.6s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=5; total time=   5.6s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=5; total time=   5.6s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=5; total time=   5.7s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=5; total time=   5.6s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=10; total time=   5.6s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=10; total time=   5.6s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=10; total time=   5.6s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=10; total time=   5.6s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=10; total time=   5.6s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=4, min_samples_split=2; total time=   5.6s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=4, min_samples_split=2; total time=   5.5s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=4, min_samples_split=2; total time=   5.5s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=4, min_samples_split=2; total time=   5.6s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=4, min_samples_split=2; total time=   5.6s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=4, min_samples_split=5; total time=   5.6s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=4, min_samples_split=5; total time=   5.6s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=4, min_samples_split=5; total time=   5.5s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=4, min_samples_split=5; total time=   5.6s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=4, min_samples_split=5; total time=   5.6s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=4, min_samples_split=10; total time=   5.6s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=4, min_samples_split=10; total time=   5.5s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=4, min_samples_split=10; total time=   5.5s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=4, min_samples_split=10; total time=   5.6s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=4, min_samples_split=10; total time=   5.6s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=1, min_samples_split=2; total time=   8.5s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=1, min_samples_split=2; total time=   7.9s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=1, min_samples_split=2; total time=   7.4s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=1, min_samples_split=2; total time=   8.3s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=1, min_samples_split=2; total time=   7.9s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=1, min_samples_split=5; total time=   8.5s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=1, min_samples_split=5; total time=   7.9s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=1, min_samples_split=5; total time=   7.4s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=1, min_samples_split=5; total time=   8.3s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=1, min_samples_split=5; total time=   7.9s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=1, min_samples_split=10; total time=   8.4s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=1, min_samples_split=10; total time=   7.7s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=1, min_samples_split=10; total time=   7.3s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=1, min_samples_split=10; total time=   8.2s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=1, min_samples_split=10; total time=   7.7s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=2, min_samples_split=2; total time=   8.4s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=2, min_samples_split=2; total time=   7.8s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=2, min_samples_split=2; total time=   7.3s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=2, min_samples_split=2; total time=   8.2s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=2, min_samples_split=2; total time=   7.8s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=2, min_samples_split=5; total time=   8.4s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=2, min_samples_split=5; total time=   7.8s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=2, min_samples_split=5; total time=   7.3s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=2, min_samples_split=5; total time=   8.2s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=2, min_samples_split=5; total time=   7.7s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=2, min_samples_split=10; total time=   8.3s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=2, min_samples_split=10; total time=   7.7s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=2, min_samples_split=10; total time=   7.2s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=2, min_samples_split=10; total time=   8.1s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=2, min_samples_split=10; total time=   7.7s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=4, min_samples_split=2; total time=   8.2s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=4, min_samples_split=2; total time=   7.5s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=4, min_samples_split=2; total time=   7.0s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=4, min_samples_split=2; total time=   7.9s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=4, min_samples_split=2; total time=   7.5s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=4, min_samples_split=5; total time=   8.2s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=4, min_samples_split=5; total time=   7.5s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=4, min_samples_split=5; total time=   7.0s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=4, min_samples_split=5; total time=   7.9s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=4, min_samples_split=5; total time=   7.5s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=4, min_samples_split=10; total time=   8.2s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=4, min_samples_split=10; total time=   7.5s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=4, min_samples_split=10; total time=   7.0s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=4, min_samples_split=10; total time=   7.9s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=4, min_samples_split=10; total time=   7.4s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=1, min_samples_split=2; total time=   9.4s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=1, min_samples_split=2; total time=   8.1s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=1, min_samples_split=2; total time=   7.5s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=1, min_samples_split=2; total time=   8.7s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=1, min_samples_split=2; total time=   8.0s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=1, min_samples_split=5; total time=   9.4s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=1, min_samples_split=5; total time=   8.1s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=1, min_samples_split=5; total time=   7.4s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=1, min_samples_split=5; total time=   8.6s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=1, min_samples_split=5; total time=   8.0s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=1, min_samples_split=10; total time=   9.2s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=1, min_samples_split=10; total time=   7.9s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=1, min_samples_split=10; total time=   7.3s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=1, min_samples_split=10; total time=   8.5s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=1, min_samples_split=10; total time=   7.9s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=2, min_samples_split=2; total time=   9.3s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=2, min_samples_split=2; total time=   7.9s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=2, min_samples_split=2; total time=   7.4s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=2, min_samples_split=2; total time=   8.5s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=2, min_samples_split=2; total time=   7.9s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=2, min_samples_split=5; total time=   9.3s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=2, min_samples_split=5; total time=   8.0s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=2, min_samples_split=5; total time=   7.3s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=2, min_samples_split=5; total time=   8.5s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=2, min_samples_split=5; total time=   7.9s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=2, min_samples_split=10; total time=   9.2s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=2, min_samples_split=10; total time=   7.8s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=2, min_samples_split=10; total time=   7.6s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=2, min_samples_split=10; total time=   8.5s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=2, min_samples_split=10; total time=   7.8s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=4, min_samples_split=2; total time=   9.0s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=4, min_samples_split=2; total time=   7.6s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=4, min_samples_split=2; total time=   7.0s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=4, min_samples_split=2; total time=   8.2s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=4, min_samples_split=2; total time=   7.6s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=4, min_samples_split=5; total time=   9.0s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=4, min_samples_split=5; total time=   7.6s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=4, min_samples_split=5; total time=   7.0s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=4, min_samples_split=5; total time=   8.2s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=4, min_samples_split=5; total time=   7.6s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=4, min_samples_split=10; total time=   9.0s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=4, min_samples_split=10; total time=   7.6s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=4, min_samples_split=10; total time=   7.0s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=4, min_samples_split=10; total time=   8.2s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=4, min_samples_split=10; total time=   7.5s\n",
      "[CV] END criterion=entropy, max_depth=40, min_samples_leaf=1, min_samples_split=2; total time=   9.5s\n",
      "[CV] END criterion=entropy, max_depth=40, min_samples_leaf=1, min_samples_split=2; total time=   8.1s\n",
      "[CV] END criterion=entropy, max_depth=40, min_samples_leaf=1, min_samples_split=2; total time=   7.5s\n",
      "[CV] END criterion=entropy, max_depth=40, min_samples_leaf=1, min_samples_split=2; total time=   8.6s\n",
      "[CV] END criterion=entropy, max_depth=40, min_samples_leaf=1, min_samples_split=2; total time=   8.0s\n",
      "[CV] END criterion=entropy, max_depth=40, min_samples_leaf=1, min_samples_split=5; total time=   9.5s\n",
      "[CV] END criterion=entropy, max_depth=40, min_samples_leaf=1, min_samples_split=5; total time=   8.1s\n",
      "[CV] END criterion=entropy, max_depth=40, min_samples_leaf=1, min_samples_split=5; total time=   7.4s\n",
      "[CV] END criterion=entropy, max_depth=40, min_samples_leaf=1, min_samples_split=5; total time=   8.6s\n",
      "[CV] END criterion=entropy, max_depth=40, min_samples_leaf=1, min_samples_split=5; total time=   8.0s\n",
      "[CV] END criterion=entropy, max_depth=40, min_samples_leaf=1, min_samples_split=10; total time=   9.3s\n",
      "[CV] END criterion=entropy, max_depth=40, min_samples_leaf=1, min_samples_split=10; total time=   7.9s\n",
      "[CV] END criterion=entropy, max_depth=40, min_samples_leaf=1, min_samples_split=10; total time=   7.3s\n",
      "[CV] END criterion=entropy, max_depth=40, min_samples_leaf=1, min_samples_split=10; total time=   8.5s\n",
      "[CV] END criterion=entropy, max_depth=40, min_samples_leaf=1, min_samples_split=10; total time=   7.9s\n",
      "[CV] END criterion=entropy, max_depth=40, min_samples_leaf=2, min_samples_split=2; total time=   9.4s\n",
      "[CV] END criterion=entropy, max_depth=40, min_samples_leaf=2, min_samples_split=2; total time=   8.0s\n",
      "[CV] END criterion=entropy, max_depth=40, min_samples_leaf=2, min_samples_split=2; total time=   7.3s\n",
      "[CV] END criterion=entropy, max_depth=40, min_samples_leaf=2, min_samples_split=2; total time=   8.5s\n",
      "[CV] END criterion=entropy, max_depth=40, min_samples_leaf=2, min_samples_split=2; total time=   7.9s\n",
      "[CV] END criterion=entropy, max_depth=40, min_samples_leaf=2, min_samples_split=5; total time=   9.4s\n",
      "[CV] END criterion=entropy, max_depth=40, min_samples_leaf=2, min_samples_split=5; total time=   7.9s\n",
      "[CV] END criterion=entropy, max_depth=40, min_samples_leaf=2, min_samples_split=5; total time=   7.3s\n",
      "[CV] END criterion=entropy, max_depth=40, min_samples_leaf=2, min_samples_split=5; total time=   8.5s\n",
      "[CV] END criterion=entropy, max_depth=40, min_samples_leaf=2, min_samples_split=5; total time=   7.9s\n",
      "[CV] END criterion=entropy, max_depth=40, min_samples_leaf=2, min_samples_split=10; total time=   9.3s\n",
      "[CV] END criterion=entropy, max_depth=40, min_samples_leaf=2, min_samples_split=10; total time=   7.8s\n",
      "[CV] END criterion=entropy, max_depth=40, min_samples_leaf=2, min_samples_split=10; total time=   7.2s\n",
      "[CV] END criterion=entropy, max_depth=40, min_samples_leaf=2, min_samples_split=10; total time=   8.4s\n",
      "[CV] END criterion=entropy, max_depth=40, min_samples_leaf=2, min_samples_split=10; total time=   7.7s\n",
      "[CV] END criterion=entropy, max_depth=40, min_samples_leaf=4, min_samples_split=2; total time=   9.1s\n",
      "[CV] END criterion=entropy, max_depth=40, min_samples_leaf=4, min_samples_split=2; total time=   7.6s\n",
      "[CV] END criterion=entropy, max_depth=40, min_samples_leaf=4, min_samples_split=2; total time=   7.0s\n",
      "[CV] END criterion=entropy, max_depth=40, min_samples_leaf=4, min_samples_split=2; total time=   8.2s\n",
      "[CV] END criterion=entropy, max_depth=40, min_samples_leaf=4, min_samples_split=2; total time=   7.6s\n",
      "[CV] END criterion=entropy, max_depth=40, min_samples_leaf=4, min_samples_split=5; total time=   9.1s\n",
      "[CV] END criterion=entropy, max_depth=40, min_samples_leaf=4, min_samples_split=5; total time=   7.6s\n",
      "[CV] END criterion=entropy, max_depth=40, min_samples_leaf=4, min_samples_split=5; total time=   7.0s\n",
      "[CV] END criterion=entropy, max_depth=40, min_samples_leaf=4, min_samples_split=5; total time=   8.2s\n",
      "[CV] END criterion=entropy, max_depth=40, min_samples_leaf=4, min_samples_split=5; total time=   7.5s\n",
      "[CV] END criterion=entropy, max_depth=40, min_samples_leaf=4, min_samples_split=10; total time=   9.0s\n",
      "[CV] END criterion=entropy, max_depth=40, min_samples_leaf=4, min_samples_split=10; total time=   7.6s\n",
      "[CV] END criterion=entropy, max_depth=40, min_samples_leaf=4, min_samples_split=10; total time=   7.0s\n",
      "[CV] END criterion=entropy, max_depth=40, min_samples_leaf=4, min_samples_split=10; total time=   8.2s\n",
      "[CV] END criterion=entropy, max_depth=40, min_samples_leaf=4, min_samples_split=10; total time=   7.5s\n",
      "Best Parameters:  {'criterion': 'entropy', 'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score:  0.4257202965195204\n",
      "Accuracy on Test Set:  0.4310747663551402\n",
      "Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.09      0.01      0.02        70\n",
      "           1       0.17      0.11      0.13       269\n",
      "           2       0.25      0.16      0.19       297\n",
      "           3       0.25      0.16      0.20       476\n",
      "           4       0.14      0.04      0.06       173\n",
      "           5       0.00      0.00      0.00        78\n",
      "           6       0.52      0.79      0.62      1205\n",
      "\n",
      "    accuracy                           0.43      2568\n",
      "   macro avg       0.20      0.18      0.18      2568\n",
      "weighted avg       0.35      0.43      0.37      2568\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the parameter grid for Decision Tree\n",
    "param_grid = {\n",
    "    'max_depth': [None, 10, 20, 30, 40],  # Maximum depth of the tree\n",
    "    'min_samples_split': [2, 5, 10],  # Minimum number of samples required to split an internal node\n",
    "    'min_samples_leaf': [1, 2, 4],  # Minimum number of samples required to be at a leaf node\n",
    "    'criterion': ['gini', 'entropy']  # Function to measure the quality of a split\n",
    "}\n",
    "\n",
    "# Initialize the Decision Tree classifier\n",
    "decision_tree = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Initialize GridSearchCV object with Decision Tree classifier and the parameter grid\n",
    "grid_search = GridSearchCV(estimator=decision_tree, param_grid=param_grid, cv=5, scoring='accuracy', verbose=2)\n",
    "\n",
    "# Fit the model with the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters and the best score\n",
    "print(\"Best Parameters: \", grid_search.best_params_)\n",
    "print(\"Best Score: \", grid_search.best_score_)\n",
    "\n",
    "# Predict on the test set with the best parameters\n",
    "y_pred = grid_search.predict(X_test)\n",
    "\n",
    "# Evaluate the classifier with the best parameters\n",
    "print(\"Accuracy on Test Set: \", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report: \")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c535a925",
   "metadata": {},
   "source": [
    "### Fully Connected Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f12e65",
   "metadata": {},
   "source": [
    "Get an emotion classifier class. Specs of the model can be changed through here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149ce9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmotionClassifier(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(EmotionClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc3 = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)  # Output without activation; softmax will be applied externally if needed\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47745e8e",
   "metadata": {},
   "source": [
    "Train test split. Convert data to tensors. Get datasets and loaders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0767b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "# Wraps tensors into a dataset. Used to combine the input features and labels into a single dataset object for both training and testing data.\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "# Provides an iterable over the given dataset, supporting automatic batching, sampling, shuffling, and multiprocess data loading.\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c6415c",
   "metadata": {},
   "source": [
    "Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36bb07ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EmotionClassifier(input_size=X_train.shape[1], hidden_size=256, num_classes=len(set(y)))\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f3d4a38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/250], Loss: 1.4900, Accuracy: 46.92367601246106%\n",
      "Epoch [10/250], Loss: 1.5260, Accuracy: 47.27414330218068%\n",
      "Epoch [20/250], Loss: 1.7633, Accuracy: 47.27414330218068%\n",
      "Epoch [30/250], Loss: 1.4860, Accuracy: 48.442367601246104%\n",
      "Epoch [40/250], Loss: 1.6929, Accuracy: 48.5202492211838%\n",
      "Epoch [50/250], Loss: 1.9062, Accuracy: 48.28660436137071%\n",
      "Epoch [60/250], Loss: 1.3402, Accuracy: 48.13084112149533%\n",
      "Epoch [70/250], Loss: 1.5801, Accuracy: 47.624610591900314%\n",
      "Epoch [80/250], Loss: 1.7049, Accuracy: 48.481308411214954%\n",
      "Epoch [90/250], Loss: 1.5788, Accuracy: 48.71495327102804%\n",
      "Epoch [100/250], Loss: 1.5613, Accuracy: 48.90965732087228%\n",
      "Epoch [110/250], Loss: 1.5385, Accuracy: 48.71495327102804%\n",
      "Epoch [120/250], Loss: 1.3571, Accuracy: 49.76635514018692%\n",
      "Epoch [130/250], Loss: 1.1905, Accuracy: 49.299065420560744%\n",
      "Epoch [140/250], Loss: 1.7540, Accuracy: 49.22118380062305%\n",
      "Epoch [150/250], Loss: 1.4226, Accuracy: 49.41588785046729%\n",
      "Epoch [160/250], Loss: 1.2352, Accuracy: 49.22118380062305%\n",
      "Epoch [170/250], Loss: 1.3040, Accuracy: 49.493769470404985%\n",
      "Epoch [180/250], Loss: 1.3211, Accuracy: 48.90965732087228%\n",
      "Epoch [190/250], Loss: 1.2887, Accuracy: 49.06542056074766%\n",
      "Epoch [200/250], Loss: 1.3074, Accuracy: 49.96105919003115%\n",
      "Epoch [210/250], Loss: 1.2919, Accuracy: 49.02647975077882%\n",
      "Epoch [220/250], Loss: 1.4004, Accuracy: 48.481308411214954%\n",
      "Epoch [230/250], Loss: 1.6795, Accuracy: 48.598130841121495%\n",
      "Epoch [240/250], Loss: 1.3829, Accuracy: 48.559190031152646%\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 250\n",
    "accuracy_list = []\n",
    "loss_list = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for inputs, labels in train_loader:\n",
    "        optimizer.zero_grad()  # Reset gradients\n",
    "        outputs = model(inputs)  # Forward pass\n",
    "        loss = criterion(outputs, labels)  # Compute loss\n",
    "        loss.backward()  # Backward pass\n",
    "        optimizer.step()  # Update weights\n",
    "\n",
    "    # After updating weights in each epoch, add code to evaluate on the test set or a validation set\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        # Initialize variables to track accuracy, for example\n",
    "        correct, total = 0, 0\n",
    "        for inputs, labels in test_loader:\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    accuracy = 100 * correct / total\n",
    "\n",
    "    accuracy_list.append(accuracy)\n",
    "    loss_list.append(loss.item())\n",
    "    \n",
    "    model.train()  # Set the model back to training mode\n",
    "    if epoch % 10 == 0:\n",
    "        print(f'Epoch [{epoch}/{num_epochs}], Loss: {loss.item():.4f}, Accuracy: {accuracy}%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dccdd0a",
   "metadata": {},
   "source": [
    "Accuracy Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7688fe73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = range(len(accuracy_list))\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(x, accuracy_list, marker='o', linestyle='', color='b')\n",
    "plt.title('Accuracy per Epoch')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae28536",
   "metadata": {},
   "source": [
    "Loss Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bda4eea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = range(len(loss_list))\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(x, loss_list, marker='o', linestyle='', color='r')\n",
    "plt.title('Loss per Epoch')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b612e200",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow.keras import datasets, layers, models \n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc80c96f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10272, 300)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08682f09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10272,)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "047d31af",
   "metadata": {},
   "source": [
    "Just testing out another Fully Connected Layers code from a website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81668176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "321/321 [==============================] - 1s 2ms/step - loss: 1.5906 - accuracy: 0.4617 - val_loss: 1.5409 - val_accuracy: 0.4692\n",
      "Epoch 2/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.5515 - accuracy: 0.4629 - val_loss: 1.5363 - val_accuracy: 0.4692\n",
      "Epoch 3/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.5376 - accuracy: 0.4629 - val_loss: 1.5270 - val_accuracy: 0.4692\n",
      "Epoch 4/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.5261 - accuracy: 0.4618 - val_loss: 1.5077 - val_accuracy: 0.4657\n",
      "Epoch 5/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.5133 - accuracy: 0.4618 - val_loss: 1.4965 - val_accuracy: 0.4677\n",
      "Epoch 6/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.5093 - accuracy: 0.4613 - val_loss: 1.5203 - val_accuracy: 0.4688\n",
      "Epoch 7/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.5058 - accuracy: 0.4646 - val_loss: 1.4881 - val_accuracy: 0.4743\n",
      "Epoch 8/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.4976 - accuracy: 0.4622 - val_loss: 1.5352 - val_accuracy: 0.4607\n",
      "Epoch 9/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.4940 - accuracy: 0.4613 - val_loss: 1.4907 - val_accuracy: 0.4681\n",
      "Epoch 10/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.4921 - accuracy: 0.4647 - val_loss: 1.4694 - val_accuracy: 0.4759\n",
      "Epoch 11/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.4849 - accuracy: 0.4648 - val_loss: 1.4764 - val_accuracy: 0.4712\n",
      "Epoch 12/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.4884 - accuracy: 0.4672 - val_loss: 1.5043 - val_accuracy: 0.4700\n",
      "Epoch 13/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.4850 - accuracy: 0.4683 - val_loss: 1.4721 - val_accuracy: 0.4794\n",
      "Epoch 14/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.4794 - accuracy: 0.4640 - val_loss: 1.4786 - val_accuracy: 0.4704\n",
      "Epoch 15/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.4787 - accuracy: 0.4688 - val_loss: 1.4654 - val_accuracy: 0.4801\n",
      "Epoch 16/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.4775 - accuracy: 0.4657 - val_loss: 1.4691 - val_accuracy: 0.4759\n",
      "Epoch 17/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.4736 - accuracy: 0.4687 - val_loss: 1.4612 - val_accuracy: 0.4821\n",
      "Epoch 18/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.4743 - accuracy: 0.4686 - val_loss: 1.4650 - val_accuracy: 0.4762\n",
      "Epoch 19/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.4735 - accuracy: 0.4685 - val_loss: 1.4742 - val_accuracy: 0.4735\n",
      "Epoch 20/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.4722 - accuracy: 0.4694 - val_loss: 1.4615 - val_accuracy: 0.4782\n",
      "Epoch 21/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.4708 - accuracy: 0.4732 - val_loss: 1.4597 - val_accuracy: 0.4778\n",
      "Epoch 22/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.4710 - accuracy: 0.4696 - val_loss: 1.4555 - val_accuracy: 0.4805\n",
      "Epoch 23/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.4680 - accuracy: 0.4695 - val_loss: 1.4598 - val_accuracy: 0.4794\n",
      "Epoch 24/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.4686 - accuracy: 0.4706 - val_loss: 1.4654 - val_accuracy: 0.4805\n",
      "Epoch 25/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.4647 - accuracy: 0.4717 - val_loss: 1.4534 - val_accuracy: 0.4864\n",
      "Epoch 26/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.4652 - accuracy: 0.4719 - val_loss: 1.4535 - val_accuracy: 0.4821\n",
      "Epoch 27/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.4648 - accuracy: 0.4698 - val_loss: 1.4538 - val_accuracy: 0.4798\n",
      "Epoch 28/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.4607 - accuracy: 0.4718 - val_loss: 1.4583 - val_accuracy: 0.4762\n",
      "Epoch 29/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.4610 - accuracy: 0.4740 - val_loss: 1.4542 - val_accuracy: 0.4790\n",
      "Epoch 30/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.4634 - accuracy: 0.4696 - val_loss: 1.4711 - val_accuracy: 0.4786\n",
      "Epoch 31/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.4593 - accuracy: 0.4755 - val_loss: 1.4524 - val_accuracy: 0.4871\n",
      "Epoch 32/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.4633 - accuracy: 0.4738 - val_loss: 1.4540 - val_accuracy: 0.4871\n",
      "Epoch 33/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.4567 - accuracy: 0.4739 - val_loss: 1.4515 - val_accuracy: 0.4883\n",
      "Epoch 34/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.4577 - accuracy: 0.4735 - val_loss: 1.4556 - val_accuracy: 0.4778\n",
      "Epoch 35/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.4579 - accuracy: 0.4741 - val_loss: 1.4543 - val_accuracy: 0.4801\n",
      "Epoch 36/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.4565 - accuracy: 0.4754 - val_loss: 1.4478 - val_accuracy: 0.4848\n",
      "Epoch 37/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.4544 - accuracy: 0.4744 - val_loss: 1.4482 - val_accuracy: 0.4840\n",
      "Epoch 38/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.4545 - accuracy: 0.4767 - val_loss: 1.4518 - val_accuracy: 0.4825\n",
      "Epoch 39/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.4559 - accuracy: 0.4758 - val_loss: 1.4598 - val_accuracy: 0.4848\n",
      "Epoch 40/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.4529 - accuracy: 0.4720 - val_loss: 1.4508 - val_accuracy: 0.4836\n",
      "Epoch 41/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.4522 - accuracy: 0.4748 - val_loss: 1.4443 - val_accuracy: 0.4856\n",
      "Epoch 42/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.4493 - accuracy: 0.4753 - val_loss: 1.4623 - val_accuracy: 0.4840\n",
      "Epoch 43/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.4508 - accuracy: 0.4732 - val_loss: 1.4506 - val_accuracy: 0.4786\n",
      "Epoch 44/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.4513 - accuracy: 0.4749 - val_loss: 1.4792 - val_accuracy: 0.4821\n",
      "Epoch 45/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.4503 - accuracy: 0.4769 - val_loss: 1.4635 - val_accuracy: 0.4848\n",
      "Epoch 46/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.4490 - accuracy: 0.4787 - val_loss: 1.4514 - val_accuracy: 0.4883\n",
      "Epoch 47/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.4489 - accuracy: 0.4757 - val_loss: 1.4570 - val_accuracy: 0.4805\n",
      "Epoch 48/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.4484 - accuracy: 0.4761 - val_loss: 1.4439 - val_accuracy: 0.4891\n",
      "Epoch 49/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.4462 - accuracy: 0.4751 - val_loss: 1.4562 - val_accuracy: 0.4856\n",
      "Epoch 50/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.4464 - accuracy: 0.4778 - val_loss: 1.4528 - val_accuracy: 0.4813\n",
      "Epoch 51/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.4485 - accuracy: 0.4784 - val_loss: 1.4676 - val_accuracy: 0.4930\n",
      "Epoch 52/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.4491 - accuracy: 0.4760 - val_loss: 1.4435 - val_accuracy: 0.4883\n",
      "Epoch 53/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.4449 - accuracy: 0.4761 - val_loss: 1.4485 - val_accuracy: 0.4910\n",
      "Epoch 54/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.4417 - accuracy: 0.4794 - val_loss: 1.4468 - val_accuracy: 0.4922\n",
      "Epoch 55/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.4444 - accuracy: 0.4789 - val_loss: 1.4553 - val_accuracy: 0.4934\n",
      "Epoch 56/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.4433 - accuracy: 0.4785 - val_loss: 1.4533 - val_accuracy: 0.4864\n",
      "Epoch 57/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.4435 - accuracy: 0.4794 - val_loss: 1.4517 - val_accuracy: 0.4871\n",
      "Epoch 58/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.4412 - accuracy: 0.4806 - val_loss: 1.4507 - val_accuracy: 0.4856\n",
      "Epoch 59/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.4425 - accuracy: 0.4808 - val_loss: 1.4525 - val_accuracy: 0.4868\n",
      "Epoch 60/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.4425 - accuracy: 0.4779 - val_loss: 1.4549 - val_accuracy: 0.4794\n",
      "Epoch 61/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.4418 - accuracy: 0.4807 - val_loss: 1.4523 - val_accuracy: 0.4945\n",
      "Epoch 62/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.4389 - accuracy: 0.4769 - val_loss: 1.4481 - val_accuracy: 0.4864\n",
      "Epoch 63/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.4429 - accuracy: 0.4795 - val_loss: 1.4552 - val_accuracy: 0.4875\n",
      "Epoch 64/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.4376 - accuracy: 0.4807 - val_loss: 1.4644 - val_accuracy: 0.4879\n",
      "Epoch 65/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.4384 - accuracy: 0.4813 - val_loss: 1.4515 - val_accuracy: 0.4895\n",
      "Epoch 66/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.4362 - accuracy: 0.4805 - val_loss: 1.4718 - val_accuracy: 0.4836\n",
      "Epoch 67/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.4388 - accuracy: 0.4776 - val_loss: 1.4595 - val_accuracy: 0.4817\n",
      "Epoch 68/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.4362 - accuracy: 0.4803 - val_loss: 1.4576 - val_accuracy: 0.4836\n",
      "Epoch 69/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.4375 - accuracy: 0.4805 - val_loss: 1.4520 - val_accuracy: 0.4926\n",
      "Epoch 70/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.4387 - accuracy: 0.4801 - val_loss: 1.4492 - val_accuracy: 0.4848\n",
      "Epoch 71/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.4338 - accuracy: 0.4801 - val_loss: 1.4560 - val_accuracy: 0.4848\n",
      "Epoch 72/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.4325 - accuracy: 0.4829 - val_loss: 1.4514 - val_accuracy: 0.4825\n",
      "Epoch 73/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.4332 - accuracy: 0.4820 - val_loss: 1.4572 - val_accuracy: 0.4840\n",
      "Epoch 74/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.4323 - accuracy: 0.4844 - val_loss: 1.4679 - val_accuracy: 0.4871\n",
      "Epoch 75/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.4324 - accuracy: 0.4810 - val_loss: 1.4612 - val_accuracy: 0.4899\n",
      "Epoch 76/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.4309 - accuracy: 0.4849 - val_loss: 1.4490 - val_accuracy: 0.4934\n",
      "Epoch 77/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.4278 - accuracy: 0.4836 - val_loss: 1.4670 - val_accuracy: 0.4825\n",
      "Epoch 78/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.4325 - accuracy: 0.4848 - val_loss: 1.4538 - val_accuracy: 0.4922\n",
      "Epoch 79/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.4302 - accuracy: 0.4836 - val_loss: 1.4467 - val_accuracy: 0.4926\n",
      "Epoch 80/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.4279 - accuracy: 0.4839 - val_loss: 1.4490 - val_accuracy: 0.4883\n",
      "Epoch 81/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.4264 - accuracy: 0.4838 - val_loss: 1.4475 - val_accuracy: 0.4860\n",
      "Epoch 82/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.4260 - accuracy: 0.4855 - val_loss: 1.4433 - val_accuracy: 0.4942\n",
      "Epoch 83/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.4263 - accuracy: 0.4880 - val_loss: 1.4621 - val_accuracy: 0.4871\n",
      "Epoch 84/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.4311 - accuracy: 0.4832 - val_loss: 1.4712 - val_accuracy: 0.4907\n",
      "Epoch 85/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.4255 - accuracy: 0.4844 - val_loss: 1.4501 - val_accuracy: 0.4910\n",
      "Epoch 86/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.4223 - accuracy: 0.4868 - val_loss: 1.4598 - val_accuracy: 0.4903\n",
      "Epoch 87/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.4255 - accuracy: 0.4873 - val_loss: 1.4469 - val_accuracy: 0.4942\n",
      "Epoch 88/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.4215 - accuracy: 0.4871 - val_loss: 1.4493 - val_accuracy: 0.4922\n",
      "Epoch 89/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.4216 - accuracy: 0.4863 - val_loss: 1.4631 - val_accuracy: 0.4926\n",
      "Epoch 90/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.4197 - accuracy: 0.4851 - val_loss: 1.4507 - val_accuracy: 0.4891\n",
      "Epoch 91/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.4198 - accuracy: 0.4854 - val_loss: 1.4523 - val_accuracy: 0.4907\n",
      "Epoch 92/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.4199 - accuracy: 0.4871 - val_loss: 1.4511 - val_accuracy: 0.4910\n",
      "Epoch 93/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.4200 - accuracy: 0.4888 - val_loss: 1.4616 - val_accuracy: 0.4864\n",
      "Epoch 94/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.4156 - accuracy: 0.4867 - val_loss: 1.4591 - val_accuracy: 0.4942\n",
      "Epoch 95/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.4221 - accuracy: 0.4844 - val_loss: 1.4728 - val_accuracy: 0.4868\n",
      "Epoch 96/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.4159 - accuracy: 0.4892 - val_loss: 1.4620 - val_accuracy: 0.4961\n",
      "Epoch 97/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.4149 - accuracy: 0.4875 - val_loss: 1.4581 - val_accuracy: 0.4914\n",
      "Epoch 98/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.4163 - accuracy: 0.4884 - val_loss: 1.4527 - val_accuracy: 0.4891\n",
      "Epoch 99/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.4146 - accuracy: 0.4845 - val_loss: 1.4573 - val_accuracy: 0.4895\n",
      "Epoch 100/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.4150 - accuracy: 0.4862 - val_loss: 1.4556 - val_accuracy: 0.4899\n",
      "Epoch 101/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.4082 - accuracy: 0.4915 - val_loss: 1.4514 - val_accuracy: 0.4965\n",
      "Epoch 102/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.4129 - accuracy: 0.4878 - val_loss: 1.4603 - val_accuracy: 0.4864\n",
      "Epoch 103/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.4104 - accuracy: 0.4900 - val_loss: 1.4553 - val_accuracy: 0.4922\n",
      "Epoch 104/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.4083 - accuracy: 0.4893 - val_loss: 1.4636 - val_accuracy: 0.4910\n",
      "Epoch 105/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.4091 - accuracy: 0.4908 - val_loss: 1.4639 - val_accuracy: 0.4856\n",
      "Epoch 106/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.4064 - accuracy: 0.4932 - val_loss: 1.4624 - val_accuracy: 0.4860\n",
      "Epoch 107/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.4087 - accuracy: 0.4893 - val_loss: 1.4699 - val_accuracy: 0.4887\n",
      "Epoch 108/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.4066 - accuracy: 0.4876 - val_loss: 1.4599 - val_accuracy: 0.4922\n",
      "Epoch 109/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.4035 - accuracy: 0.4904 - val_loss: 1.4583 - val_accuracy: 0.4891\n",
      "Epoch 110/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.4061 - accuracy: 0.4888 - val_loss: 1.4673 - val_accuracy: 0.4887\n",
      "Epoch 111/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.4043 - accuracy: 0.4894 - val_loss: 1.4600 - val_accuracy: 0.4918\n",
      "Epoch 112/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.4027 - accuracy: 0.4915 - val_loss: 1.4663 - val_accuracy: 0.4879\n",
      "Epoch 113/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.4027 - accuracy: 0.4918 - val_loss: 1.4751 - val_accuracy: 0.4922\n",
      "Epoch 114/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.4022 - accuracy: 0.4923 - val_loss: 1.4681 - val_accuracy: 0.4957\n",
      "Epoch 115/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.4021 - accuracy: 0.4901 - val_loss: 1.4552 - val_accuracy: 0.4922\n",
      "Epoch 116/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.4004 - accuracy: 0.4910 - val_loss: 1.4619 - val_accuracy: 0.4969\n",
      "Epoch 117/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.3980 - accuracy: 0.4908 - val_loss: 1.4542 - val_accuracy: 0.4930\n",
      "Epoch 118/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.4006 - accuracy: 0.4928 - val_loss: 1.4817 - val_accuracy: 0.4860\n",
      "Epoch 119/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.3985 - accuracy: 0.4928 - val_loss: 1.4628 - val_accuracy: 0.4918\n",
      "Epoch 120/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.3971 - accuracy: 0.4914 - val_loss: 1.4626 - val_accuracy: 0.4899\n",
      "Epoch 121/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.3974 - accuracy: 0.4933 - val_loss: 1.4796 - val_accuracy: 0.4829\n",
      "Epoch 122/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.3949 - accuracy: 0.4918 - val_loss: 1.4821 - val_accuracy: 0.4852\n",
      "Epoch 123/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.3960 - accuracy: 0.4946 - val_loss: 1.4715 - val_accuracy: 0.4852\n",
      "Epoch 124/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.3946 - accuracy: 0.4937 - val_loss: 1.4621 - val_accuracy: 0.4852\n",
      "Epoch 125/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.3944 - accuracy: 0.4962 - val_loss: 1.4645 - val_accuracy: 0.4934\n",
      "Epoch 126/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.3934 - accuracy: 0.4930 - val_loss: 1.4576 - val_accuracy: 0.4934\n",
      "Epoch 127/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.3913 - accuracy: 0.4966 - val_loss: 1.4765 - val_accuracy: 0.4875\n",
      "Epoch 128/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.3888 - accuracy: 0.4933 - val_loss: 1.4710 - val_accuracy: 0.4875\n",
      "Epoch 129/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.3894 - accuracy: 0.4980 - val_loss: 1.4813 - val_accuracy: 0.4879\n",
      "Epoch 130/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.3885 - accuracy: 0.4967 - val_loss: 1.4695 - val_accuracy: 0.4864\n",
      "Epoch 131/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.3875 - accuracy: 0.4960 - val_loss: 1.4613 - val_accuracy: 0.4868\n",
      "Epoch 132/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.3878 - accuracy: 0.4966 - val_loss: 1.4737 - val_accuracy: 0.4801\n",
      "Epoch 133/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.3852 - accuracy: 0.4948 - val_loss: 1.4716 - val_accuracy: 0.4914\n",
      "Epoch 134/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.3866 - accuracy: 0.4975 - val_loss: 1.4742 - val_accuracy: 0.4879\n",
      "Epoch 135/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.3827 - accuracy: 0.5008 - val_loss: 1.4768 - val_accuracy: 0.4930\n",
      "Epoch 136/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.3858 - accuracy: 0.4928 - val_loss: 1.4653 - val_accuracy: 0.4879\n",
      "Epoch 137/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.3813 - accuracy: 0.4981 - val_loss: 1.4663 - val_accuracy: 0.4918\n",
      "Epoch 138/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.3800 - accuracy: 0.4980 - val_loss: 1.4705 - val_accuracy: 0.4875\n",
      "Epoch 139/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.3825 - accuracy: 0.4975 - val_loss: 1.4685 - val_accuracy: 0.4856\n",
      "Epoch 140/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.3779 - accuracy: 0.4965 - val_loss: 1.4769 - val_accuracy: 0.4930\n",
      "Epoch 141/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.3784 - accuracy: 0.4975 - val_loss: 1.4692 - val_accuracy: 0.4934\n",
      "Epoch 142/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.3785 - accuracy: 0.4979 - val_loss: 1.4669 - val_accuracy: 0.4895\n",
      "Epoch 143/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.3733 - accuracy: 0.4989 - val_loss: 1.4713 - val_accuracy: 0.4864\n",
      "Epoch 144/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.3766 - accuracy: 0.4954 - val_loss: 1.4710 - val_accuracy: 0.4821\n",
      "Epoch 145/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.3765 - accuracy: 0.4967 - val_loss: 1.4942 - val_accuracy: 0.4821\n",
      "Epoch 146/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.3732 - accuracy: 0.5018 - val_loss: 1.4780 - val_accuracy: 0.4868\n",
      "Epoch 147/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.3740 - accuracy: 0.4987 - val_loss: 1.4775 - val_accuracy: 0.4813\n",
      "Epoch 148/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.3713 - accuracy: 0.5014 - val_loss: 1.4729 - val_accuracy: 0.4864\n",
      "Epoch 149/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.3714 - accuracy: 0.5019 - val_loss: 1.4847 - val_accuracy: 0.4825\n",
      "Epoch 150/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.3680 - accuracy: 0.5023 - val_loss: 1.4873 - val_accuracy: 0.4836\n",
      "Epoch 151/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.3707 - accuracy: 0.4988 - val_loss: 1.4978 - val_accuracy: 0.4759\n",
      "Epoch 152/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.3693 - accuracy: 0.5029 - val_loss: 1.4789 - val_accuracy: 0.4895\n",
      "Epoch 153/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.3700 - accuracy: 0.5022 - val_loss: 1.4748 - val_accuracy: 0.4875\n",
      "Epoch 154/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.3669 - accuracy: 0.5042 - val_loss: 1.4760 - val_accuracy: 0.4813\n",
      "Epoch 155/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.3624 - accuracy: 0.5057 - val_loss: 1.4792 - val_accuracy: 0.4883\n",
      "Epoch 156/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.3634 - accuracy: 0.5052 - val_loss: 1.4815 - val_accuracy: 0.4794\n",
      "Epoch 157/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.3612 - accuracy: 0.5065 - val_loss: 1.4742 - val_accuracy: 0.4899\n",
      "Epoch 158/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.3646 - accuracy: 0.5011 - val_loss: 1.4787 - val_accuracy: 0.4821\n",
      "Epoch 159/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.3642 - accuracy: 0.4998 - val_loss: 1.4846 - val_accuracy: 0.4817\n",
      "Epoch 160/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.3597 - accuracy: 0.5034 - val_loss: 1.4824 - val_accuracy: 0.4821\n",
      "Epoch 161/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.3620 - accuracy: 0.5033 - val_loss: 1.4909 - val_accuracy: 0.4774\n",
      "Epoch 162/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.3597 - accuracy: 0.5022 - val_loss: 1.4798 - val_accuracy: 0.4840\n",
      "Epoch 163/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.3588 - accuracy: 0.5047 - val_loss: 1.4822 - val_accuracy: 0.4907\n",
      "Epoch 164/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.3549 - accuracy: 0.5044 - val_loss: 1.4842 - val_accuracy: 0.4821\n",
      "Epoch 165/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.3514 - accuracy: 0.5069 - val_loss: 1.4833 - val_accuracy: 0.4840\n",
      "Epoch 166/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.3533 - accuracy: 0.5088 - val_loss: 1.4964 - val_accuracy: 0.4821\n",
      "Epoch 167/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.3514 - accuracy: 0.5066 - val_loss: 1.5062 - val_accuracy: 0.4805\n",
      "Epoch 168/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.3495 - accuracy: 0.5040 - val_loss: 1.4843 - val_accuracy: 0.4836\n",
      "Epoch 169/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.3520 - accuracy: 0.5073 - val_loss: 1.4995 - val_accuracy: 0.4821\n",
      "Epoch 170/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.3504 - accuracy: 0.5039 - val_loss: 1.4767 - val_accuracy: 0.4840\n",
      "Epoch 171/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.3512 - accuracy: 0.5063 - val_loss: 1.4839 - val_accuracy: 0.4852\n",
      "Epoch 172/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.3455 - accuracy: 0.5064 - val_loss: 1.4851 - val_accuracy: 0.4833\n",
      "Epoch 173/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.3419 - accuracy: 0.5088 - val_loss: 1.5008 - val_accuracy: 0.4848\n",
      "Epoch 174/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.3447 - accuracy: 0.5079 - val_loss: 1.4955 - val_accuracy: 0.4879\n",
      "Epoch 175/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.3439 - accuracy: 0.5047 - val_loss: 1.5025 - val_accuracy: 0.4856\n",
      "Epoch 176/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.3443 - accuracy: 0.5109 - val_loss: 1.4923 - val_accuracy: 0.4821\n",
      "Epoch 177/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.3466 - accuracy: 0.5065 - val_loss: 1.5070 - val_accuracy: 0.4724\n",
      "Epoch 178/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.3442 - accuracy: 0.5082 - val_loss: 1.4950 - val_accuracy: 0.4829\n",
      "Epoch 179/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.3417 - accuracy: 0.5078 - val_loss: 1.5188 - val_accuracy: 0.4798\n",
      "Epoch 180/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.3448 - accuracy: 0.5076 - val_loss: 1.4978 - val_accuracy: 0.4871\n",
      "Epoch 181/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.3366 - accuracy: 0.5092 - val_loss: 1.5018 - val_accuracy: 0.4829\n",
      "Epoch 182/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.3382 - accuracy: 0.5083 - val_loss: 1.5131 - val_accuracy: 0.4821\n",
      "Epoch 183/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.3363 - accuracy: 0.5121 - val_loss: 1.5129 - val_accuracy: 0.4833\n",
      "Epoch 184/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.3337 - accuracy: 0.5113 - val_loss: 1.5005 - val_accuracy: 0.4871\n",
      "Epoch 185/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.3307 - accuracy: 0.5109 - val_loss: 1.5064 - val_accuracy: 0.4821\n",
      "Epoch 186/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.3321 - accuracy: 0.5115 - val_loss: 1.5181 - val_accuracy: 0.4856\n",
      "Epoch 187/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.3296 - accuracy: 0.5129 - val_loss: 1.5058 - val_accuracy: 0.4833\n",
      "Epoch 188/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.3316 - accuracy: 0.5119 - val_loss: 1.5091 - val_accuracy: 0.4755\n",
      "Epoch 189/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.3279 - accuracy: 0.5143 - val_loss: 1.5048 - val_accuracy: 0.4786\n",
      "Epoch 190/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.3327 - accuracy: 0.5114 - val_loss: 1.5106 - val_accuracy: 0.4778\n",
      "Epoch 191/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.3280 - accuracy: 0.5124 - val_loss: 1.5252 - val_accuracy: 0.4755\n",
      "Epoch 192/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.3230 - accuracy: 0.5134 - val_loss: 1.5183 - val_accuracy: 0.4829\n",
      "Epoch 193/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.3228 - accuracy: 0.5132 - val_loss: 1.5142 - val_accuracy: 0.4825\n",
      "Epoch 194/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.3239 - accuracy: 0.5129 - val_loss: 1.5279 - val_accuracy: 0.4692\n",
      "Epoch 195/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.3190 - accuracy: 0.5185 - val_loss: 1.5304 - val_accuracy: 0.4809\n",
      "Epoch 196/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.3213 - accuracy: 0.5135 - val_loss: 1.5352 - val_accuracy: 0.4786\n",
      "Epoch 197/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.3206 - accuracy: 0.5177 - val_loss: 1.5122 - val_accuracy: 0.4856\n",
      "Epoch 198/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.3180 - accuracy: 0.5158 - val_loss: 1.5191 - val_accuracy: 0.4817\n",
      "Epoch 199/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.3215 - accuracy: 0.5183 - val_loss: 1.5084 - val_accuracy: 0.4805\n",
      "Epoch 200/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.3179 - accuracy: 0.5159 - val_loss: 1.5092 - val_accuracy: 0.4809\n",
      "Epoch 201/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.3154 - accuracy: 0.5157 - val_loss: 1.5194 - val_accuracy: 0.4809\n",
      "Epoch 202/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.3142 - accuracy: 0.5199 - val_loss: 1.5214 - val_accuracy: 0.4829\n",
      "Epoch 203/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.3124 - accuracy: 0.5149 - val_loss: 1.5143 - val_accuracy: 0.4829\n",
      "Epoch 204/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.3135 - accuracy: 0.5173 - val_loss: 1.5264 - val_accuracy: 0.4805\n",
      "Epoch 205/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.3111 - accuracy: 0.5203 - val_loss: 1.5153 - val_accuracy: 0.4762\n",
      "Epoch 206/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.3138 - accuracy: 0.5161 - val_loss: 1.5239 - val_accuracy: 0.4836\n",
      "Epoch 207/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.3098 - accuracy: 0.5243 - val_loss: 1.5272 - val_accuracy: 0.4821\n",
      "Epoch 208/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.3084 - accuracy: 0.5186 - val_loss: 1.5111 - val_accuracy: 0.4759\n",
      "Epoch 209/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.3067 - accuracy: 0.5215 - val_loss: 1.5338 - val_accuracy: 0.4798\n",
      "Epoch 210/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.3038 - accuracy: 0.5238 - val_loss: 1.5303 - val_accuracy: 0.4798\n",
      "Epoch 211/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.3057 - accuracy: 0.5197 - val_loss: 1.5334 - val_accuracy: 0.4871\n",
      "Epoch 212/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.3021 - accuracy: 0.5227 - val_loss: 1.5298 - val_accuracy: 0.4836\n",
      "Epoch 213/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.3057 - accuracy: 0.5198 - val_loss: 1.5335 - val_accuracy: 0.4801\n",
      "Epoch 214/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.2992 - accuracy: 0.5206 - val_loss: 1.5365 - val_accuracy: 0.4743\n",
      "Epoch 215/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.3003 - accuracy: 0.5231 - val_loss: 1.5281 - val_accuracy: 0.4856\n",
      "Epoch 216/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.2995 - accuracy: 0.5250 - val_loss: 1.5305 - val_accuracy: 0.4891\n",
      "Epoch 217/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.2985 - accuracy: 0.5230 - val_loss: 1.5308 - val_accuracy: 0.4778\n",
      "Epoch 218/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.3005 - accuracy: 0.5225 - val_loss: 1.5290 - val_accuracy: 0.4821\n",
      "Epoch 219/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.2937 - accuracy: 0.5235 - val_loss: 1.5439 - val_accuracy: 0.4801\n",
      "Epoch 220/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.2955 - accuracy: 0.5244 - val_loss: 1.5359 - val_accuracy: 0.4778\n",
      "Epoch 221/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.2951 - accuracy: 0.5232 - val_loss: 1.5481 - val_accuracy: 0.4692\n",
      "Epoch 222/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.2937 - accuracy: 0.5248 - val_loss: 1.5297 - val_accuracy: 0.4786\n",
      "Epoch 223/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.2903 - accuracy: 0.5262 - val_loss: 1.5343 - val_accuracy: 0.4809\n",
      "Epoch 224/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.2934 - accuracy: 0.5241 - val_loss: 1.5282 - val_accuracy: 0.4809\n",
      "Epoch 225/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.2870 - accuracy: 0.5265 - val_loss: 1.5615 - val_accuracy: 0.4743\n",
      "Epoch 226/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.2914 - accuracy: 0.5226 - val_loss: 1.5534 - val_accuracy: 0.4794\n",
      "Epoch 227/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.2867 - accuracy: 0.5290 - val_loss: 1.5495 - val_accuracy: 0.4735\n",
      "Epoch 228/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.2853 - accuracy: 0.5295 - val_loss: 1.5451 - val_accuracy: 0.4786\n",
      "Epoch 229/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.2851 - accuracy: 0.5263 - val_loss: 1.5602 - val_accuracy: 0.4688\n",
      "Epoch 230/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.2912 - accuracy: 0.5254 - val_loss: 1.5704 - val_accuracy: 0.4704\n",
      "Epoch 231/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.2804 - accuracy: 0.5263 - val_loss: 1.5397 - val_accuracy: 0.4782\n",
      "Epoch 232/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.2790 - accuracy: 0.5289 - val_loss: 1.5727 - val_accuracy: 0.4743\n",
      "Epoch 233/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.2845 - accuracy: 0.5321 - val_loss: 1.5546 - val_accuracy: 0.4681\n",
      "Epoch 234/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.2768 - accuracy: 0.5281 - val_loss: 1.5556 - val_accuracy: 0.4762\n",
      "Epoch 235/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.2763 - accuracy: 0.5277 - val_loss: 1.5922 - val_accuracy: 0.4716\n",
      "Epoch 236/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.2832 - accuracy: 0.5337 - val_loss: 1.5481 - val_accuracy: 0.4739\n",
      "Epoch 237/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.2820 - accuracy: 0.5298 - val_loss: 1.5497 - val_accuracy: 0.4790\n",
      "Epoch 238/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.2739 - accuracy: 0.5260 - val_loss: 1.5720 - val_accuracy: 0.4759\n",
      "Epoch 239/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.2757 - accuracy: 0.5261 - val_loss: 1.5704 - val_accuracy: 0.4786\n",
      "Epoch 240/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.2781 - accuracy: 0.5315 - val_loss: 1.5403 - val_accuracy: 0.4692\n",
      "Epoch 241/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.2773 - accuracy: 0.5267 - val_loss: 1.5613 - val_accuracy: 0.4712\n",
      "Epoch 242/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.2734 - accuracy: 0.5290 - val_loss: 1.5704 - val_accuracy: 0.4704\n",
      "Epoch 243/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.2740 - accuracy: 0.5296 - val_loss: 1.5623 - val_accuracy: 0.4727\n",
      "Epoch 244/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.2648 - accuracy: 0.5358 - val_loss: 1.5757 - val_accuracy: 0.4786\n",
      "Epoch 245/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.2687 - accuracy: 0.5329 - val_loss: 1.5538 - val_accuracy: 0.4817\n",
      "Epoch 246/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.2671 - accuracy: 0.5334 - val_loss: 1.5570 - val_accuracy: 0.4755\n",
      "Epoch 247/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.2633 - accuracy: 0.5352 - val_loss: 1.5811 - val_accuracy: 0.4708\n",
      "Epoch 248/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.2647 - accuracy: 0.5358 - val_loss: 1.5685 - val_accuracy: 0.4700\n",
      "Epoch 249/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.2613 - accuracy: 0.5344 - val_loss: 1.5721 - val_accuracy: 0.4778\n",
      "Epoch 250/250\n",
      "321/321 [==============================] - 0s 1ms/step - loss: 1.2664 - accuracy: 0.5323 - val_loss: 1.5738 - val_accuracy: 0.4704\n"
     ]
    }
   ],
   "source": [
    "# Initialize a sequential model\n",
    "model = models.Sequential()\n",
    "\n",
    "# Add the input layer\n",
    "model.add(layers.Input(shape=(300,)))  # Adjust the input shape to match your feature vector size\n",
    "\n",
    "# Add fully connected (Dense) layers\n",
    "model.add(layers.Dense(256, activation='relu'))  # First hidden layer with 256 units\n",
    "model.add(layers.Dense(128, activation='relu'))  # Second hidden layer with 128 units\n",
    "model.add(layers.Dense(64, activation='relu'))   # Third hidden layer with 64 units\n",
    "\n",
    "# Add the output layer\n",
    "model.add(layers.Dense(10, activation='softmax'))  # Assuming a multi-class classification problem with 10 classes\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(),  # Suitable for integer-labeled data\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Assuming X_train, y_train, X_test, y_test are already defined and properly preprocessed\n",
    "history = model.fit(X_train, y_train, epochs=250, validation_data=(X_test, y_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3436fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81/81 - 0s - loss: 1.5738 - accuracy: 0.4704 - 63ms/epoch - 782us/step\n"
     ]
    }
   ],
   "source": [
    "# Plotting accuracy\n",
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0, 1])  # Adjust the y-axis range to better fit your accuracy range\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test, verbose=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

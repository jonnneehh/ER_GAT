{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c88b60e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB # Gaussian Naive Bayes\n",
    "from sklearn.svm import SVC  # Support Vector Classifier\n",
    "from sklearn.ensemble import RandomForestClassifier # Random Forest Classifier\n",
    "import xgboost as xgb # Gradient Boosting Machines\n",
    "from sklearn.neighbors import KNeighborsClassifier # KNN\n",
    "from sklearn.linear_model import LogisticRegression # Logistic Regression\n",
    "from sklearn.tree import DecisionTreeClassifier # Decision Trees\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# For the fully connected layers\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70fb6ce7",
   "metadata": {},
   "source": [
    "### Getting training and testing data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec484e1",
   "metadata": {},
   "source": [
    "This code was taken from context_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f53a9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.load('data/train_test_data/x_train_contextencoder.pt')\n",
    "y_train = pd.read_csv('data/train_test_data/y_train_contextencoder.csv')\n",
    "\n",
    "X_test = torch.load('data/train_test_data/x_test_contextencoder.pt')\n",
    "y_test = pd.read_csv('data/train_test_data/y_test_contextencoder.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cdb2edeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.02106448,  0.03402166,  0.41411582, ..., -0.02596821,\n",
       "         0.02658154, -0.04077357],\n",
       "       [ 0.03329327,  0.03269034,  0.16543297, ..., -0.02377809,\n",
       "         0.02932434, -0.03381041],\n",
       "       [ 0.0602355 ,  0.04271767,  0.09228501, ..., -0.02530025,\n",
       "         0.02808624, -0.03916406],\n",
       "       ...,\n",
       "       [ 0.07361973,  0.05439407,  0.03723658, ...,  0.03439288,\n",
       "        -0.07036522, -0.06370108],\n",
       "       [ 0.07075164,  0.05669767,  0.03161025, ...,  0.04010216,\n",
       "        -0.193852  , -0.11699423],\n",
       "       [ 0.07090013,  0.06418796,  0.0271789 , ...,  0.08496671,\n",
       "        -0.24383666, -0.20624714]], dtype=float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X_train.detach().numpy()\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "347c2738",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    1\n",
       "Name: Emotion, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = y_train['Emotion']\n",
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb43f97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be242083",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    6\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "Name: Emotion, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test = y_test['Emotion']\n",
    "y_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "72220464",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of X_train: (12840, 300)\n",
      "Length of y_train: (12840,)\n",
      "Length of X_test: (3400, 300)\n",
      "Length of y_test: (3400,)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Length of X_train: {X_train.shape}\")\n",
    "print(f\"Length of y_train: {y_train.shape}\")\n",
    "print(f\"Length of X_test: {X_test.shape}\")\n",
    "print(f\"Length of y_test: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e02ee902",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Encoder Mapping (Emotion -> Encoded Label):\n",
      "neutral: 0\n",
      "surprise: 1\n",
      "fear: 2\n",
      "sadness: 3\n",
      "joy: 4\n",
      "disgust: 5\n",
      "anger: 6\n"
     ]
    }
   ],
   "source": [
    "file1 = open('data/dump/label_encoder.pkl', 'rb')\n",
    "file2 = open('data/dump/label_decoder.pkl', 'rb')\n",
    "label_encoder = pickle.load(file1)\n",
    "label_decoder = pickle.load(file2)\n",
    "file1.close()\n",
    "file2.close()\n",
    "\n",
    "# Print the label_encoder dictionary to see the mapping\n",
    "print(\"Label Encoder Mapping (Emotion -> Encoded Label):\")\n",
    "for label, encoded_label in label_encoder.items():\n",
    "    print(f\"{label}: {encoded_label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf1ecef",
   "metadata": {},
   "source": [
    "### Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "38ade457",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:  {'var_smoothing': 1.0}\n",
      "Best Score:  0.23021806853582555\n",
      "Accuracy on Test Set:  0.15176470588235294\n",
      "Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      1615\n",
      "           1       0.00      0.00      0.00       352\n",
      "           2       0.00      0.00      0.00        60\n",
      "           3       0.00      0.00      0.00       263\n",
      "           4       0.00      0.00      0.00       495\n",
      "           5       0.00      0.00      0.00        99\n",
      "           6       0.15      1.00      0.26       516\n",
      "\n",
      "    accuracy                           0.15      3400\n",
      "   macro avg       0.02      0.14      0.04      3400\n",
      "weighted avg       0.02      0.15      0.04      3400\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Initialize the Gaussian Naive Bayes classifier\n",
    "gnb = GaussianNB()\n",
    "\n",
    "# Define the parameter grid for 'var_smoothing'\n",
    "param_grid = {'var_smoothing': np.logspace(0,-9, num=100)}\n",
    "\n",
    "# Initialize the GridSearchCV object with GaussianNB classifier and the parameter grid\n",
    "grid_search = GridSearchCV(estimator=gnb, param_grid=param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "# Fit the model with the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters and the best score\n",
    "print(\"Best Parameters: \", grid_search.best_params_)\n",
    "print(\"Best Score: \", grid_search.best_score_)\n",
    "\n",
    "# Predict on the test set with the best parameters\n",
    "y_pred = grid_search.predict(X_test)\n",
    "\n",
    "# Evaluate the classifier with the best parameters\n",
    "print(\"Accuracy on Test Set: \", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report: \")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef09713a",
   "metadata": {},
   "source": [
    "### Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b73108e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 96 candidates, totalling 480 fits\n",
      "[CV] END ...........C=0.1, degree=2, gamma=scale, kernel=rbf; total time=  14.4s\n",
      "[CV] END ...........C=0.1, degree=2, gamma=scale, kernel=rbf; total time=  14.5s\n",
      "[CV] END ...........C=0.1, degree=2, gamma=scale, kernel=rbf; total time=  13.9s\n",
      "[CV] END ...........C=0.1, degree=2, gamma=scale, kernel=rbf; total time=  13.8s\n",
      "[CV] END ...........C=0.1, degree=2, gamma=scale, kernel=rbf; total time=  14.5s\n",
      "[CV] END ........C=0.1, degree=2, gamma=scale, kernel=linear; total time=  11.6s\n",
      "[CV] END ........C=0.1, degree=2, gamma=scale, kernel=linear; total time=  11.2s\n",
      "[CV] END ........C=0.1, degree=2, gamma=scale, kernel=linear; total time=  11.3s\n",
      "[CV] END ........C=0.1, degree=2, gamma=scale, kernel=linear; total time=  11.3s\n",
      "[CV] END ........C=0.1, degree=2, gamma=scale, kernel=linear; total time=  11.6s\n",
      "[CV] END ..........C=0.1, degree=2, gamma=scale, kernel=poly; total time=  11.2s\n",
      "[CV] END ..........C=0.1, degree=2, gamma=scale, kernel=poly; total time=  10.9s\n",
      "[CV] END ..........C=0.1, degree=2, gamma=scale, kernel=poly; total time=  11.3s\n",
      "[CV] END ..........C=0.1, degree=2, gamma=scale, kernel=poly; total time=  11.4s\n",
      "[CV] END ..........C=0.1, degree=2, gamma=scale, kernel=poly; total time=  11.3s\n",
      "[CV] END .......C=0.1, degree=2, gamma=scale, kernel=sigmoid; total time=  11.3s\n",
      "[CV] END .......C=0.1, degree=2, gamma=scale, kernel=sigmoid; total time=  11.1s\n",
      "[CV] END .......C=0.1, degree=2, gamma=scale, kernel=sigmoid; total time=  11.3s\n",
      "[CV] END .......C=0.1, degree=2, gamma=scale, kernel=sigmoid; total time=  11.2s\n",
      "[CV] END .......C=0.1, degree=2, gamma=scale, kernel=sigmoid; total time=  11.2s\n",
      "[CV] END ............C=0.1, degree=2, gamma=auto, kernel=rbf; total time=  12.8s\n",
      "[CV] END ............C=0.1, degree=2, gamma=auto, kernel=rbf; total time=  12.4s\n",
      "[CV] END ............C=0.1, degree=2, gamma=auto, kernel=rbf; total time=  12.6s\n",
      "[CV] END ............C=0.1, degree=2, gamma=auto, kernel=rbf; total time=  12.4s\n",
      "[CV] END ............C=0.1, degree=2, gamma=auto, kernel=rbf; total time=  12.4s\n",
      "[CV] END .........C=0.1, degree=2, gamma=auto, kernel=linear; total time=  13.4s\n",
      "[CV] END .........C=0.1, degree=2, gamma=auto, kernel=linear; total time=  11.3s\n",
      "[CV] END .........C=0.1, degree=2, gamma=auto, kernel=linear; total time=  11.4s\n",
      "[CV] END .........C=0.1, degree=2, gamma=auto, kernel=linear; total time=  11.2s\n",
      "[CV] END .........C=0.1, degree=2, gamma=auto, kernel=linear; total time=  11.6s\n",
      "[CV] END ...........C=0.1, degree=2, gamma=auto, kernel=poly; total time=  10.0s\n",
      "[CV] END ...........C=0.1, degree=2, gamma=auto, kernel=poly; total time=   9.9s\n",
      "[CV] END ...........C=0.1, degree=2, gamma=auto, kernel=poly; total time=   9.9s\n",
      "[CV] END ...........C=0.1, degree=2, gamma=auto, kernel=poly; total time=   9.8s\n",
      "[CV] END ...........C=0.1, degree=2, gamma=auto, kernel=poly; total time=  10.1s\n",
      "[CV] END ........C=0.1, degree=2, gamma=auto, kernel=sigmoid; total time=  10.6s\n",
      "[CV] END ........C=0.1, degree=2, gamma=auto, kernel=sigmoid; total time=  10.6s\n",
      "[CV] END ........C=0.1, degree=2, gamma=auto, kernel=sigmoid; total time=  10.3s\n",
      "[CV] END ........C=0.1, degree=2, gamma=auto, kernel=sigmoid; total time=  10.4s\n",
      "[CV] END ........C=0.1, degree=2, gamma=auto, kernel=sigmoid; total time=  10.9s\n",
      "[CV] END ...........C=0.1, degree=3, gamma=scale, kernel=rbf; total time=  13.4s\n",
      "[CV] END ...........C=0.1, degree=3, gamma=scale, kernel=rbf; total time=  13.5s\n",
      "[CV] END ...........C=0.1, degree=3, gamma=scale, kernel=rbf; total time=  13.5s\n",
      "[CV] END ...........C=0.1, degree=3, gamma=scale, kernel=rbf; total time=  13.3s\n",
      "[CV] END ...........C=0.1, degree=3, gamma=scale, kernel=rbf; total time=  13.2s\n",
      "[CV] END ........C=0.1, degree=3, gamma=scale, kernel=linear; total time=  11.7s\n",
      "[CV] END ........C=0.1, degree=3, gamma=scale, kernel=linear; total time=  12.8s\n",
      "[CV] END ........C=0.1, degree=3, gamma=scale, kernel=linear; total time=  11.4s\n",
      "[CV] END ........C=0.1, degree=3, gamma=scale, kernel=linear; total time=  11.4s\n",
      "[CV] END ........C=0.1, degree=3, gamma=scale, kernel=linear; total time=  11.4s\n",
      "[CV] END ..........C=0.1, degree=3, gamma=scale, kernel=poly; total time=  11.6s\n",
      "[CV] END ..........C=0.1, degree=3, gamma=scale, kernel=poly; total time=  11.6s\n",
      "[CV] END ..........C=0.1, degree=3, gamma=scale, kernel=poly; total time=  11.3s\n",
      "[CV] END ..........C=0.1, degree=3, gamma=scale, kernel=poly; total time=  11.4s\n",
      "[CV] END ..........C=0.1, degree=3, gamma=scale, kernel=poly; total time=  11.8s\n",
      "[CV] END .......C=0.1, degree=3, gamma=scale, kernel=sigmoid; total time=  11.0s\n",
      "[CV] END .......C=0.1, degree=3, gamma=scale, kernel=sigmoid; total time=  11.1s\n",
      "[CV] END .......C=0.1, degree=3, gamma=scale, kernel=sigmoid; total time=  11.1s\n",
      "[CV] END .......C=0.1, degree=3, gamma=scale, kernel=sigmoid; total time=  11.0s\n",
      "[CV] END .......C=0.1, degree=3, gamma=scale, kernel=sigmoid; total time=  11.3s\n",
      "[CV] END ............C=0.1, degree=3, gamma=auto, kernel=rbf; total time=  12.5s\n",
      "[CV] END ............C=0.1, degree=3, gamma=auto, kernel=rbf; total time=  12.3s\n",
      "[CV] END ............C=0.1, degree=3, gamma=auto, kernel=rbf; total time=  12.3s\n",
      "[CV] END ............C=0.1, degree=3, gamma=auto, kernel=rbf; total time=  12.2s\n",
      "[CV] END ............C=0.1, degree=3, gamma=auto, kernel=rbf; total time=  12.6s\n",
      "[CV] END .........C=0.1, degree=3, gamma=auto, kernel=linear; total time=  11.5s\n",
      "[CV] END .........C=0.1, degree=3, gamma=auto, kernel=linear; total time=  11.4s\n",
      "[CV] END .........C=0.1, degree=3, gamma=auto, kernel=linear; total time=  11.3s\n",
      "[CV] END .........C=0.1, degree=3, gamma=auto, kernel=linear; total time=  11.1s\n",
      "[CV] END .........C=0.1, degree=3, gamma=auto, kernel=linear; total time=  11.4s\n",
      "[CV] END ...........C=0.1, degree=3, gamma=auto, kernel=poly; total time=  10.1s\n",
      "[CV] END ...........C=0.1, degree=3, gamma=auto, kernel=poly; total time=  10.0s\n",
      "[CV] END ...........C=0.1, degree=3, gamma=auto, kernel=poly; total time=   9.9s\n",
      "[CV] END ...........C=0.1, degree=3, gamma=auto, kernel=poly; total time=   9.9s\n",
      "[CV] END ...........C=0.1, degree=3, gamma=auto, kernel=poly; total time=  10.0s\n",
      "[CV] END ........C=0.1, degree=3, gamma=auto, kernel=sigmoid; total time=  10.6s\n",
      "[CV] END ........C=0.1, degree=3, gamma=auto, kernel=sigmoid; total time=  10.7s\n",
      "[CV] END ........C=0.1, degree=3, gamma=auto, kernel=sigmoid; total time=  10.6s\n",
      "[CV] END ........C=0.1, degree=3, gamma=auto, kernel=sigmoid; total time=  10.5s\n",
      "[CV] END ........C=0.1, degree=3, gamma=auto, kernel=sigmoid; total time=  10.5s\n",
      "[CV] END ...........C=0.1, degree=4, gamma=scale, kernel=rbf; total time=  13.6s\n",
      "[CV] END ...........C=0.1, degree=4, gamma=scale, kernel=rbf; total time=  13.4s\n",
      "[CV] END ...........C=0.1, degree=4, gamma=scale, kernel=rbf; total time=  13.6s\n",
      "[CV] END ...........C=0.1, degree=4, gamma=scale, kernel=rbf; total time=  13.4s\n",
      "[CV] END ...........C=0.1, degree=4, gamma=scale, kernel=rbf; total time=  13.3s\n",
      "[CV] END ........C=0.1, degree=4, gamma=scale, kernel=linear; total time=  11.4s\n",
      "[CV] END ........C=0.1, degree=4, gamma=scale, kernel=linear; total time=  11.2s\n",
      "[CV] END ........C=0.1, degree=4, gamma=scale, kernel=linear; total time=  11.1s\n",
      "[CV] END ........C=0.1, degree=4, gamma=scale, kernel=linear; total time=  11.1s\n",
      "[CV] END ........C=0.1, degree=4, gamma=scale, kernel=linear; total time=  11.4s\n",
      "[CV] END ..........C=0.1, degree=4, gamma=scale, kernel=poly; total time=  12.1s\n",
      "[CV] END ..........C=0.1, degree=4, gamma=scale, kernel=poly; total time=  12.0s\n",
      "[CV] END ..........C=0.1, degree=4, gamma=scale, kernel=poly; total time=  12.1s\n",
      "[CV] END ..........C=0.1, degree=4, gamma=scale, kernel=poly; total time=  12.1s\n",
      "[CV] END ..........C=0.1, degree=4, gamma=scale, kernel=poly; total time=  12.2s\n",
      "[CV] END .......C=0.1, degree=4, gamma=scale, kernel=sigmoid; total time=  11.1s\n",
      "[CV] END .......C=0.1, degree=4, gamma=scale, kernel=sigmoid; total time=  11.0s\n",
      "[CV] END .......C=0.1, degree=4, gamma=scale, kernel=sigmoid; total time=  11.2s\n",
      "[CV] END .......C=0.1, degree=4, gamma=scale, kernel=sigmoid; total time=  11.1s\n",
      "[CV] END .......C=0.1, degree=4, gamma=scale, kernel=sigmoid; total time=  11.3s\n",
      "[CV] END ............C=0.1, degree=4, gamma=auto, kernel=rbf; total time=  12.4s\n",
      "[CV] END ............C=0.1, degree=4, gamma=auto, kernel=rbf; total time=  12.2s\n",
      "[CV] END ............C=0.1, degree=4, gamma=auto, kernel=rbf; total time=  12.4s\n",
      "[CV] END ............C=0.1, degree=4, gamma=auto, kernel=rbf; total time=  12.5s\n",
      "[CV] END ............C=0.1, degree=4, gamma=auto, kernel=rbf; total time=  12.5s\n",
      "[CV] END .........C=0.1, degree=4, gamma=auto, kernel=linear; total time=  11.4s\n",
      "[CV] END .........C=0.1, degree=4, gamma=auto, kernel=linear; total time=  11.2s\n",
      "[CV] END .........C=0.1, degree=4, gamma=auto, kernel=linear; total time=  11.2s\n",
      "[CV] END .........C=0.1, degree=4, gamma=auto, kernel=linear; total time=  11.1s\n",
      "[CV] END .........C=0.1, degree=4, gamma=auto, kernel=linear; total time=  11.1s\n",
      "[CV] END ...........C=0.1, degree=4, gamma=auto, kernel=poly; total time=  10.2s\n",
      "[CV] END ...........C=0.1, degree=4, gamma=auto, kernel=poly; total time=  10.0s\n",
      "[CV] END ...........C=0.1, degree=4, gamma=auto, kernel=poly; total time=  10.0s\n",
      "[CV] END ...........C=0.1, degree=4, gamma=auto, kernel=poly; total time=  10.2s\n",
      "[CV] END ...........C=0.1, degree=4, gamma=auto, kernel=poly; total time=  10.1s\n",
      "[CV] END ........C=0.1, degree=4, gamma=auto, kernel=sigmoid; total time=  10.3s\n",
      "[CV] END ........C=0.1, degree=4, gamma=auto, kernel=sigmoid; total time=  10.7s\n",
      "[CV] END ........C=0.1, degree=4, gamma=auto, kernel=sigmoid; total time=  10.5s\n",
      "[CV] END ........C=0.1, degree=4, gamma=auto, kernel=sigmoid; total time=  10.4s\n",
      "[CV] END ........C=0.1, degree=4, gamma=auto, kernel=sigmoid; total time=  10.7s\n",
      "[CV] END .............C=1, degree=2, gamma=scale, kernel=rbf; total time=  15.8s\n",
      "[CV] END .............C=1, degree=2, gamma=scale, kernel=rbf; total time=  15.8s\n",
      "[CV] END .............C=1, degree=2, gamma=scale, kernel=rbf; total time=  15.4s\n",
      "[CV] END .............C=1, degree=2, gamma=scale, kernel=rbf; total time=  15.7s\n",
      "[CV] END .............C=1, degree=2, gamma=scale, kernel=rbf; total time=  15.5s\n",
      "[CV] END ..........C=1, degree=2, gamma=scale, kernel=linear; total time=  13.3s\n",
      "[CV] END ..........C=1, degree=2, gamma=scale, kernel=linear; total time=  13.3s\n",
      "[CV] END ..........C=1, degree=2, gamma=scale, kernel=linear; total time=  13.7s\n",
      "[CV] END ..........C=1, degree=2, gamma=scale, kernel=linear; total time=  13.2s\n",
      "[CV] END ..........C=1, degree=2, gamma=scale, kernel=linear; total time=  13.4s\n",
      "[CV] END ............C=1, degree=2, gamma=scale, kernel=poly; total time=  13.2s\n",
      "[CV] END ............C=1, degree=2, gamma=scale, kernel=poly; total time=  13.0s\n",
      "[CV] END ............C=1, degree=2, gamma=scale, kernel=poly; total time=  13.0s\n",
      "[CV] END ............C=1, degree=2, gamma=scale, kernel=poly; total time=  13.0s\n",
      "[CV] END ............C=1, degree=2, gamma=scale, kernel=poly; total time=  13.2s\n",
      "[CV] END .........C=1, degree=2, gamma=scale, kernel=sigmoid; total time=  10.3s\n",
      "[CV] END .........C=1, degree=2, gamma=scale, kernel=sigmoid; total time=  10.5s\n",
      "[CV] END .........C=1, degree=2, gamma=scale, kernel=sigmoid; total time=  10.1s\n",
      "[CV] END .........C=1, degree=2, gamma=scale, kernel=sigmoid; total time=  10.1s\n",
      "[CV] END .........C=1, degree=2, gamma=scale, kernel=sigmoid; total time=  10.9s\n",
      "[CV] END ..............C=1, degree=2, gamma=auto, kernel=rbf; total time=  12.6s\n",
      "[CV] END ..............C=1, degree=2, gamma=auto, kernel=rbf; total time=  12.7s\n",
      "[CV] END ..............C=1, degree=2, gamma=auto, kernel=rbf; total time=  12.9s\n",
      "[CV] END ..............C=1, degree=2, gamma=auto, kernel=rbf; total time=  12.4s\n",
      "[CV] END ..............C=1, degree=2, gamma=auto, kernel=rbf; total time=  12.5s\n",
      "[CV] END ...........C=1, degree=2, gamma=auto, kernel=linear; total time=  13.4s\n",
      "[CV] END ...........C=1, degree=2, gamma=auto, kernel=linear; total time=  14.0s\n",
      "[CV] END ...........C=1, degree=2, gamma=auto, kernel=linear; total time=  13.5s\n",
      "[CV] END ...........C=1, degree=2, gamma=auto, kernel=linear; total time=  13.3s\n",
      "[CV] END ...........C=1, degree=2, gamma=auto, kernel=linear; total time=  13.4s\n",
      "[CV] END .............C=1, degree=2, gamma=auto, kernel=poly; total time=   9.8s\n",
      "[CV] END .............C=1, degree=2, gamma=auto, kernel=poly; total time=  10.0s\n",
      "[CV] END .............C=1, degree=2, gamma=auto, kernel=poly; total time=   9.7s\n",
      "[CV] END .............C=1, degree=2, gamma=auto, kernel=poly; total time=   9.8s\n",
      "[CV] END .............C=1, degree=2, gamma=auto, kernel=poly; total time=   9.8s\n",
      "[CV] END ..........C=1, degree=2, gamma=auto, kernel=sigmoid; total time=  10.8s\n",
      "[CV] END ..........C=1, degree=2, gamma=auto, kernel=sigmoid; total time=  10.7s\n",
      "[CV] END ..........C=1, degree=2, gamma=auto, kernel=sigmoid; total time=  10.5s\n",
      "[CV] END ..........C=1, degree=2, gamma=auto, kernel=sigmoid; total time=  10.5s\n",
      "[CV] END ..........C=1, degree=2, gamma=auto, kernel=sigmoid; total time=  10.5s\n",
      "[CV] END .............C=1, degree=3, gamma=scale, kernel=rbf; total time=  15.9s\n",
      "[CV] END .............C=1, degree=3, gamma=scale, kernel=rbf; total time=  15.7s\n",
      "[CV] END .............C=1, degree=3, gamma=scale, kernel=rbf; total time=  15.3s\n",
      "[CV] END .............C=1, degree=3, gamma=scale, kernel=rbf; total time=  15.3s\n",
      "[CV] END .............C=1, degree=3, gamma=scale, kernel=rbf; total time=  15.4s\n",
      "[CV] END ..........C=1, degree=3, gamma=scale, kernel=linear; total time=  13.5s\n",
      "[CV] END ..........C=1, degree=3, gamma=scale, kernel=linear; total time=  13.3s\n",
      "[CV] END ..........C=1, degree=3, gamma=scale, kernel=linear; total time=  13.3s\n",
      "[CV] END ..........C=1, degree=3, gamma=scale, kernel=linear; total time=  13.3s\n",
      "[CV] END ..........C=1, degree=3, gamma=scale, kernel=linear; total time=  13.6s\n",
      "[CV] END ............C=1, degree=3, gamma=scale, kernel=poly; total time=  13.8s\n",
      "[CV] END ............C=1, degree=3, gamma=scale, kernel=poly; total time=  13.2s\n",
      "[CV] END ............C=1, degree=3, gamma=scale, kernel=poly; total time=  13.5s\n",
      "[CV] END ............C=1, degree=3, gamma=scale, kernel=poly; total time=  13.3s\n",
      "[CV] END ............C=1, degree=3, gamma=scale, kernel=poly; total time=  13.4s\n",
      "[CV] END .........C=1, degree=3, gamma=scale, kernel=sigmoid; total time=  10.2s\n",
      "[CV] END .........C=1, degree=3, gamma=scale, kernel=sigmoid; total time=  10.0s\n",
      "[CV] END .........C=1, degree=3, gamma=scale, kernel=sigmoid; total time=  10.2s\n",
      "[CV] END .........C=1, degree=3, gamma=scale, kernel=sigmoid; total time=  10.1s\n",
      "[CV] END .........C=1, degree=3, gamma=scale, kernel=sigmoid; total time=  10.4s\n",
      "[CV] END ..............C=1, degree=3, gamma=auto, kernel=rbf; total time=  12.5s\n",
      "[CV] END ..............C=1, degree=3, gamma=auto, kernel=rbf; total time=  12.5s\n",
      "[CV] END ..............C=1, degree=3, gamma=auto, kernel=rbf; total time=  12.7s\n",
      "[CV] END ..............C=1, degree=3, gamma=auto, kernel=rbf; total time=  12.6s\n",
      "[CV] END ..............C=1, degree=3, gamma=auto, kernel=rbf; total time=  12.3s\n",
      "[CV] END ...........C=1, degree=3, gamma=auto, kernel=linear; total time=  13.6s\n",
      "[CV] END ...........C=1, degree=3, gamma=auto, kernel=linear; total time=  13.2s\n",
      "[CV] END ...........C=1, degree=3, gamma=auto, kernel=linear; total time=  13.5s\n",
      "[CV] END ...........C=1, degree=3, gamma=auto, kernel=linear; total time=  13.3s\n",
      "[CV] END ...........C=1, degree=3, gamma=auto, kernel=linear; total time=  13.5s\n",
      "[CV] END .............C=1, degree=3, gamma=auto, kernel=poly; total time=  10.1s\n",
      "[CV] END .............C=1, degree=3, gamma=auto, kernel=poly; total time=   9.9s\n",
      "[CV] END .............C=1, degree=3, gamma=auto, kernel=poly; total time=   9.8s\n",
      "[CV] END .............C=1, degree=3, gamma=auto, kernel=poly; total time=   9.8s\n",
      "[CV] END .............C=1, degree=3, gamma=auto, kernel=poly; total time=  10.0s\n",
      "[CV] END ..........C=1, degree=3, gamma=auto, kernel=sigmoid; total time=  10.7s\n",
      "[CV] END ..........C=1, degree=3, gamma=auto, kernel=sigmoid; total time=  10.6s\n",
      "[CV] END ..........C=1, degree=3, gamma=auto, kernel=sigmoid; total time=  10.8s\n",
      "[CV] END ..........C=1, degree=3, gamma=auto, kernel=sigmoid; total time=  10.5s\n",
      "[CV] END ..........C=1, degree=3, gamma=auto, kernel=sigmoid; total time=  10.6s\n",
      "[CV] END .............C=1, degree=4, gamma=scale, kernel=rbf; total time=  15.7s\n",
      "[CV] END .............C=1, degree=4, gamma=scale, kernel=rbf; total time=  15.7s\n",
      "[CV] END .............C=1, degree=4, gamma=scale, kernel=rbf; total time=  15.4s\n",
      "[CV] END .............C=1, degree=4, gamma=scale, kernel=rbf; total time=  15.5s\n",
      "[CV] END .............C=1, degree=4, gamma=scale, kernel=rbf; total time=  15.3s\n",
      "[CV] END ..........C=1, degree=4, gamma=scale, kernel=linear; total time=  13.7s\n",
      "[CV] END ..........C=1, degree=4, gamma=scale, kernel=linear; total time=  13.4s\n",
      "[CV] END ..........C=1, degree=4, gamma=scale, kernel=linear; total time=  13.4s\n",
      "[CV] END ..........C=1, degree=4, gamma=scale, kernel=linear; total time=  13.3s\n",
      "[CV] END ..........C=1, degree=4, gamma=scale, kernel=linear; total time=  13.4s\n",
      "[CV] END ............C=1, degree=4, gamma=scale, kernel=poly; total time=  13.8s\n",
      "[CV] END ............C=1, degree=4, gamma=scale, kernel=poly; total time=  13.7s\n",
      "[CV] END ............C=1, degree=4, gamma=scale, kernel=poly; total time=  13.8s\n",
      "[CV] END ............C=1, degree=4, gamma=scale, kernel=poly; total time=  14.2s\n",
      "[CV] END ............C=1, degree=4, gamma=scale, kernel=poly; total time=  13.6s\n",
      "[CV] END .........C=1, degree=4, gamma=scale, kernel=sigmoid; total time=  10.4s\n",
      "[CV] END .........C=1, degree=4, gamma=scale, kernel=sigmoid; total time=  10.3s\n",
      "[CV] END .........C=1, degree=4, gamma=scale, kernel=sigmoid; total time=  10.0s\n",
      "[CV] END .........C=1, degree=4, gamma=scale, kernel=sigmoid; total time=  10.2s\n",
      "[CV] END .........C=1, degree=4, gamma=scale, kernel=sigmoid; total time=  10.4s\n",
      "[CV] END ..............C=1, degree=4, gamma=auto, kernel=rbf; total time=  12.7s\n",
      "[CV] END ..............C=1, degree=4, gamma=auto, kernel=rbf; total time=  12.4s\n",
      "[CV] END ..............C=1, degree=4, gamma=auto, kernel=rbf; total time=  12.4s\n",
      "[CV] END ..............C=1, degree=4, gamma=auto, kernel=rbf; total time=  12.8s\n",
      "[CV] END ..............C=1, degree=4, gamma=auto, kernel=rbf; total time=  12.4s\n",
      "[CV] END ...........C=1, degree=4, gamma=auto, kernel=linear; total time=  13.3s\n",
      "[CV] END ...........C=1, degree=4, gamma=auto, kernel=linear; total time=  13.6s\n",
      "[CV] END ...........C=1, degree=4, gamma=auto, kernel=linear; total time=  13.6s\n",
      "[CV] END ...........C=1, degree=4, gamma=auto, kernel=linear; total time=  13.6s\n",
      "[CV] END ...........C=1, degree=4, gamma=auto, kernel=linear; total time=  13.6s\n",
      "[CV] END .............C=1, degree=4, gamma=auto, kernel=poly; total time=  10.2s\n",
      "[CV] END .............C=1, degree=4, gamma=auto, kernel=poly; total time=  10.0s\n",
      "[CV] END .............C=1, degree=4, gamma=auto, kernel=poly; total time=  10.3s\n",
      "[CV] END .............C=1, degree=4, gamma=auto, kernel=poly; total time=  10.2s\n",
      "[CV] END .............C=1, degree=4, gamma=auto, kernel=poly; total time=  10.1s\n",
      "[CV] END ..........C=1, degree=4, gamma=auto, kernel=sigmoid; total time=  10.8s\n",
      "[CV] END ..........C=1, degree=4, gamma=auto, kernel=sigmoid; total time=  10.7s\n",
      "[CV] END ..........C=1, degree=4, gamma=auto, kernel=sigmoid; total time=  10.8s\n",
      "[CV] END ..........C=1, degree=4, gamma=auto, kernel=sigmoid; total time=  10.7s\n",
      "[CV] END ..........C=1, degree=4, gamma=auto, kernel=sigmoid; total time=  10.7s\n",
      "[CV] END ............C=10, degree=2, gamma=scale, kernel=rbf; total time=  17.7s\n",
      "[CV] END ............C=10, degree=2, gamma=scale, kernel=rbf; total time=  17.4s\n",
      "[CV] END ............C=10, degree=2, gamma=scale, kernel=rbf; total time=  17.6s\n",
      "[CV] END ............C=10, degree=2, gamma=scale, kernel=rbf; total time=  17.8s\n",
      "[CV] END ............C=10, degree=2, gamma=scale, kernel=rbf; total time=  17.7s\n",
      "[CV] END .........C=10, degree=2, gamma=scale, kernel=linear; total time=  18.0s\n",
      "[CV] END .........C=10, degree=2, gamma=scale, kernel=linear; total time=  17.9s\n",
      "[CV] END .........C=10, degree=2, gamma=scale, kernel=linear; total time=  17.8s\n",
      "[CV] END .........C=10, degree=2, gamma=scale, kernel=linear; total time=  17.8s\n",
      "[CV] END .........C=10, degree=2, gamma=scale, kernel=linear; total time=  18.3s\n",
      "[CV] END ...........C=10, degree=2, gamma=scale, kernel=poly; total time=  15.9s\n",
      "[CV] END ...........C=10, degree=2, gamma=scale, kernel=poly; total time=  15.1s\n",
      "[CV] END ...........C=10, degree=2, gamma=scale, kernel=poly; total time=  15.4s\n",
      "[CV] END ...........C=10, degree=2, gamma=scale, kernel=poly; total time=  15.4s\n",
      "[CV] END ...........C=10, degree=2, gamma=scale, kernel=poly; total time=  15.7s\n",
      "[CV] END ........C=10, degree=2, gamma=scale, kernel=sigmoid; total time=   9.3s\n",
      "[CV] END ........C=10, degree=2, gamma=scale, kernel=sigmoid; total time=   9.6s\n",
      "[CV] END ........C=10, degree=2, gamma=scale, kernel=sigmoid; total time=   9.5s\n",
      "[CV] END ........C=10, degree=2, gamma=scale, kernel=sigmoid; total time=  11.0s\n",
      "[CV] END ........C=10, degree=2, gamma=scale, kernel=sigmoid; total time=   9.6s\n",
      "[CV] END .............C=10, degree=2, gamma=auto, kernel=rbf; total time=  14.0s\n",
      "[CV] END .............C=10, degree=2, gamma=auto, kernel=rbf; total time=  14.8s\n",
      "[CV] END .............C=10, degree=2, gamma=auto, kernel=rbf; total time=  13.8s\n",
      "[CV] END .............C=10, degree=2, gamma=auto, kernel=rbf; total time=  14.1s\n",
      "[CV] END .............C=10, degree=2, gamma=auto, kernel=rbf; total time=  13.9s\n",
      "[CV] END ..........C=10, degree=2, gamma=auto, kernel=linear; total time=  18.0s\n",
      "[CV] END ..........C=10, degree=2, gamma=auto, kernel=linear; total time=  17.8s\n",
      "[CV] END ..........C=10, degree=2, gamma=auto, kernel=linear; total time=  17.6s\n",
      "[CV] END ..........C=10, degree=2, gamma=auto, kernel=linear; total time=  17.7s\n",
      "[CV] END ..........C=10, degree=2, gamma=auto, kernel=linear; total time=  18.1s\n",
      "[CV] END ............C=10, degree=2, gamma=auto, kernel=poly; total time=   9.9s\n",
      "[CV] END ............C=10, degree=2, gamma=auto, kernel=poly; total time=   9.7s\n",
      "[CV] END ............C=10, degree=2, gamma=auto, kernel=poly; total time=   9.8s\n",
      "[CV] END ............C=10, degree=2, gamma=auto, kernel=poly; total time=   9.9s\n",
      "[CV] END ............C=10, degree=2, gamma=auto, kernel=poly; total time=  10.1s\n",
      "[CV] END .........C=10, degree=2, gamma=auto, kernel=sigmoid; total time=  11.4s\n",
      "[CV] END .........C=10, degree=2, gamma=auto, kernel=sigmoid; total time=  11.3s\n",
      "[CV] END .........C=10, degree=2, gamma=auto, kernel=sigmoid; total time=  11.4s\n",
      "[CV] END .........C=10, degree=2, gamma=auto, kernel=sigmoid; total time=  11.5s\n",
      "[CV] END .........C=10, degree=2, gamma=auto, kernel=sigmoid; total time=  11.5s\n",
      "[CV] END ............C=10, degree=3, gamma=scale, kernel=rbf; total time=  17.4s\n",
      "[CV] END ............C=10, degree=3, gamma=scale, kernel=rbf; total time=  17.9s\n",
      "[CV] END ............C=10, degree=3, gamma=scale, kernel=rbf; total time=  17.1s\n",
      "[CV] END ............C=10, degree=3, gamma=scale, kernel=rbf; total time=  17.5s\n",
      "[CV] END ............C=10, degree=3, gamma=scale, kernel=rbf; total time=  17.8s\n",
      "[CV] END .........C=10, degree=3, gamma=scale, kernel=linear; total time=  18.2s\n",
      "[CV] END .........C=10, degree=3, gamma=scale, kernel=linear; total time=  18.1s\n",
      "[CV] END .........C=10, degree=3, gamma=scale, kernel=linear; total time=  17.9s\n",
      "[CV] END .........C=10, degree=3, gamma=scale, kernel=linear; total time=  17.5s\n",
      "[CV] END .........C=10, degree=3, gamma=scale, kernel=linear; total time=  18.3s\n",
      "[CV] END ...........C=10, degree=3, gamma=scale, kernel=poly; total time=  15.4s\n",
      "[CV] END ...........C=10, degree=3, gamma=scale, kernel=poly; total time=  15.3s\n",
      "[CV] END ...........C=10, degree=3, gamma=scale, kernel=poly; total time=  15.2s\n",
      "[CV] END ...........C=10, degree=3, gamma=scale, kernel=poly; total time=  15.3s\n",
      "[CV] END ...........C=10, degree=3, gamma=scale, kernel=poly; total time=  15.2s\n",
      "[CV] END ........C=10, degree=3, gamma=scale, kernel=sigmoid; total time=   9.3s\n",
      "[CV] END ........C=10, degree=3, gamma=scale, kernel=sigmoid; total time=   9.4s\n",
      "[CV] END ........C=10, degree=3, gamma=scale, kernel=sigmoid; total time=   9.3s\n",
      "[CV] END ........C=10, degree=3, gamma=scale, kernel=sigmoid; total time=   9.3s\n",
      "[CV] END ........C=10, degree=3, gamma=scale, kernel=sigmoid; total time=   9.8s\n",
      "[CV] END .............C=10, degree=3, gamma=auto, kernel=rbf; total time=  13.8s\n",
      "[CV] END .............C=10, degree=3, gamma=auto, kernel=rbf; total time=  13.8s\n",
      "[CV] END .............C=10, degree=3, gamma=auto, kernel=rbf; total time=  13.9s\n",
      "[CV] END .............C=10, degree=3, gamma=auto, kernel=rbf; total time=  13.7s\n",
      "[CV] END .............C=10, degree=3, gamma=auto, kernel=rbf; total time=  13.8s\n",
      "[CV] END ..........C=10, degree=3, gamma=auto, kernel=linear; total time=  18.0s\n",
      "[CV] END ..........C=10, degree=3, gamma=auto, kernel=linear; total time=  18.0s\n",
      "[CV] END ..........C=10, degree=3, gamma=auto, kernel=linear; total time=  17.8s\n",
      "[CV] END ..........C=10, degree=3, gamma=auto, kernel=linear; total time=  17.5s\n",
      "[CV] END ..........C=10, degree=3, gamma=auto, kernel=linear; total time=  18.2s\n",
      "[CV] END ............C=10, degree=3, gamma=auto, kernel=poly; total time=   9.8s\n",
      "[CV] END ............C=10, degree=3, gamma=auto, kernel=poly; total time=   9.8s\n",
      "[CV] END ............C=10, degree=3, gamma=auto, kernel=poly; total time=  10.0s\n",
      "[CV] END ............C=10, degree=3, gamma=auto, kernel=poly; total time=   9.9s\n",
      "[CV] END ............C=10, degree=3, gamma=auto, kernel=poly; total time=   9.7s\n",
      "[CV] END .........C=10, degree=3, gamma=auto, kernel=sigmoid; total time=  11.5s\n",
      "[CV] END .........C=10, degree=3, gamma=auto, kernel=sigmoid; total time=  11.4s\n",
      "[CV] END .........C=10, degree=3, gamma=auto, kernel=sigmoid; total time=  11.6s\n",
      "[CV] END .........C=10, degree=3, gamma=auto, kernel=sigmoid; total time=  11.3s\n",
      "[CV] END .........C=10, degree=3, gamma=auto, kernel=sigmoid; total time=  11.6s\n",
      "[CV] END ............C=10, degree=4, gamma=scale, kernel=rbf; total time=  18.0s\n",
      "[CV] END ............C=10, degree=4, gamma=scale, kernel=rbf; total time=  17.8s\n",
      "[CV] END ............C=10, degree=4, gamma=scale, kernel=rbf; total time=  17.1s\n",
      "[CV] END ............C=10, degree=4, gamma=scale, kernel=rbf; total time=  17.7s\n",
      "[CV] END ............C=10, degree=4, gamma=scale, kernel=rbf; total time=  17.5s\n",
      "[CV] END .........C=10, degree=4, gamma=scale, kernel=linear; total time=  17.9s\n",
      "[CV] END .........C=10, degree=4, gamma=scale, kernel=linear; total time=  18.0s\n",
      "[CV] END .........C=10, degree=4, gamma=scale, kernel=linear; total time=  17.5s\n",
      "[CV] END .........C=10, degree=4, gamma=scale, kernel=linear; total time=  17.3s\n",
      "[CV] END .........C=10, degree=4, gamma=scale, kernel=linear; total time=  18.3s\n",
      "[CV] END ...........C=10, degree=4, gamma=scale, kernel=poly; total time=  15.8s\n",
      "[CV] END ...........C=10, degree=4, gamma=scale, kernel=poly; total time=  15.6s\n",
      "[CV] END ...........C=10, degree=4, gamma=scale, kernel=poly; total time=  15.9s\n",
      "[CV] END ...........C=10, degree=4, gamma=scale, kernel=poly; total time=  15.3s\n",
      "[CV] END ...........C=10, degree=4, gamma=scale, kernel=poly; total time=  15.8s\n",
      "[CV] END ........C=10, degree=4, gamma=scale, kernel=sigmoid; total time=   9.2s\n",
      "[CV] END ........C=10, degree=4, gamma=scale, kernel=sigmoid; total time=   9.3s\n",
      "[CV] END ........C=10, degree=4, gamma=scale, kernel=sigmoid; total time=   9.7s\n",
      "[CV] END ........C=10, degree=4, gamma=scale, kernel=sigmoid; total time=   9.6s\n",
      "[CV] END ........C=10, degree=4, gamma=scale, kernel=sigmoid; total time=   9.8s\n",
      "[CV] END .............C=10, degree=4, gamma=auto, kernel=rbf; total time=  13.9s\n",
      "[CV] END .............C=10, degree=4, gamma=auto, kernel=rbf; total time=  14.0s\n",
      "[CV] END .............C=10, degree=4, gamma=auto, kernel=rbf; total time=  13.9s\n",
      "[CV] END .............C=10, degree=4, gamma=auto, kernel=rbf; total time=  14.1s\n",
      "[CV] END .............C=10, degree=4, gamma=auto, kernel=rbf; total time=  13.8s\n",
      "[CV] END ..........C=10, degree=4, gamma=auto, kernel=linear; total time=  18.0s\n",
      "[CV] END ..........C=10, degree=4, gamma=auto, kernel=linear; total time=  18.1s\n",
      "[CV] END ..........C=10, degree=4, gamma=auto, kernel=linear; total time=  17.9s\n",
      "[CV] END ..........C=10, degree=4, gamma=auto, kernel=linear; total time=  17.1s\n",
      "[CV] END ..........C=10, degree=4, gamma=auto, kernel=linear; total time=  18.2s\n",
      "[CV] END ............C=10, degree=4, gamma=auto, kernel=poly; total time=  10.1s\n",
      "[CV] END ............C=10, degree=4, gamma=auto, kernel=poly; total time=  10.2s\n",
      "[CV] END ............C=10, degree=4, gamma=auto, kernel=poly; total time=  10.1s\n",
      "[CV] END ............C=10, degree=4, gamma=auto, kernel=poly; total time=  10.1s\n",
      "[CV] END ............C=10, degree=4, gamma=auto, kernel=poly; total time=   9.9s\n",
      "[CV] END .........C=10, degree=4, gamma=auto, kernel=sigmoid; total time=  11.6s\n",
      "[CV] END .........C=10, degree=4, gamma=auto, kernel=sigmoid; total time=  11.5s\n",
      "[CV] END .........C=10, degree=4, gamma=auto, kernel=sigmoid; total time=  11.6s\n",
      "[CV] END .........C=10, degree=4, gamma=auto, kernel=sigmoid; total time=  11.0s\n",
      "[CV] END .........C=10, degree=4, gamma=auto, kernel=sigmoid; total time=  11.3s\n",
      "[CV] END ...........C=100, degree=2, gamma=scale, kernel=rbf; total time=  18.7s\n",
      "[CV] END ...........C=100, degree=2, gamma=scale, kernel=rbf; total time=  18.5s\n",
      "[CV] END ...........C=100, degree=2, gamma=scale, kernel=rbf; total time=  18.5s\n",
      "[CV] END ...........C=100, degree=2, gamma=scale, kernel=rbf; total time=  18.6s\n",
      "[CV] END ...........C=100, degree=2, gamma=scale, kernel=rbf; total time=  18.8s\n",
      "[CV] END ........C=100, degree=2, gamma=scale, kernel=linear; total time=  33.8s\n",
      "[CV] END ........C=100, degree=2, gamma=scale, kernel=linear; total time=  36.7s\n",
      "[CV] END ........C=100, degree=2, gamma=scale, kernel=linear; total time=  34.4s\n",
      "[CV] END ........C=100, degree=2, gamma=scale, kernel=linear; total time=  38.1s\n",
      "[CV] END ........C=100, degree=2, gamma=scale, kernel=linear; total time=  39.1s\n",
      "[CV] END ..........C=100, degree=2, gamma=scale, kernel=poly; total time=  17.5s\n",
      "[CV] END ..........C=100, degree=2, gamma=scale, kernel=poly; total time=  17.7s\n",
      "[CV] END ..........C=100, degree=2, gamma=scale, kernel=poly; total time=  17.6s\n",
      "[CV] END ..........C=100, degree=2, gamma=scale, kernel=poly; total time=  17.9s\n",
      "[CV] END ..........C=100, degree=2, gamma=scale, kernel=poly; total time=  18.0s\n",
      "[CV] END .......C=100, degree=2, gamma=scale, kernel=sigmoid; total time=   9.0s\n",
      "[CV] END .......C=100, degree=2, gamma=scale, kernel=sigmoid; total time=   9.0s\n",
      "[CV] END .......C=100, degree=2, gamma=scale, kernel=sigmoid; total time=   8.9s\n",
      "[CV] END .......C=100, degree=2, gamma=scale, kernel=sigmoid; total time=   8.8s\n",
      "[CV] END .......C=100, degree=2, gamma=scale, kernel=sigmoid; total time=   9.7s\n",
      "[CV] END ............C=100, degree=2, gamma=auto, kernel=rbf; total time=  16.0s\n",
      "[CV] END ............C=100, degree=2, gamma=auto, kernel=rbf; total time=  16.0s\n",
      "[CV] END ............C=100, degree=2, gamma=auto, kernel=rbf; total time=  16.5s\n",
      "[CV] END ............C=100, degree=2, gamma=auto, kernel=rbf; total time=  15.9s\n",
      "[CV] END ............C=100, degree=2, gamma=auto, kernel=rbf; total time=  16.4s\n",
      "[CV] END .........C=100, degree=2, gamma=auto, kernel=linear; total time=  33.6s\n",
      "[CV] END .........C=100, degree=2, gamma=auto, kernel=linear; total time=  37.0s\n",
      "[CV] END .........C=100, degree=2, gamma=auto, kernel=linear; total time=  34.5s\n",
      "[CV] END .........C=100, degree=2, gamma=auto, kernel=linear; total time=  37.9s\n",
      "[CV] END .........C=100, degree=2, gamma=auto, kernel=linear; total time=  39.4s\n",
      "[CV] END ...........C=100, degree=2, gamma=auto, kernel=poly; total time=  10.1s\n",
      "[CV] END ...........C=100, degree=2, gamma=auto, kernel=poly; total time=  10.3s\n",
      "[CV] END ...........C=100, degree=2, gamma=auto, kernel=poly; total time=  10.2s\n",
      "[CV] END ...........C=100, degree=2, gamma=auto, kernel=poly; total time=  10.4s\n",
      "[CV] END ...........C=100, degree=2, gamma=auto, kernel=poly; total time=  10.4s\n",
      "[CV] END ........C=100, degree=2, gamma=auto, kernel=sigmoid; total time=  15.0s\n",
      "[CV] END ........C=100, degree=2, gamma=auto, kernel=sigmoid; total time=  13.6s\n",
      "[CV] END ........C=100, degree=2, gamma=auto, kernel=sigmoid; total time=  13.6s\n",
      "[CV] END ........C=100, degree=2, gamma=auto, kernel=sigmoid; total time=  14.9s\n",
      "[CV] END ........C=100, degree=2, gamma=auto, kernel=sigmoid; total time=  14.0s\n",
      "[CV] END ...........C=100, degree=3, gamma=scale, kernel=rbf; total time=  18.3s\n",
      "[CV] END ...........C=100, degree=3, gamma=scale, kernel=rbf; total time=  18.7s\n",
      "[CV] END ...........C=100, degree=3, gamma=scale, kernel=rbf; total time=  18.4s\n",
      "[CV] END ...........C=100, degree=3, gamma=scale, kernel=rbf; total time=  18.6s\n",
      "[CV] END ...........C=100, degree=3, gamma=scale, kernel=rbf; total time=  18.8s\n",
      "[CV] END ........C=100, degree=3, gamma=scale, kernel=linear; total time=  33.6s\n",
      "[CV] END ........C=100, degree=3, gamma=scale, kernel=linear; total time=  37.5s\n",
      "[CV] END ........C=100, degree=3, gamma=scale, kernel=linear; total time=  34.5s\n",
      "[CV] END ........C=100, degree=3, gamma=scale, kernel=linear; total time=  38.1s\n",
      "[CV] END ........C=100, degree=3, gamma=scale, kernel=linear; total time=  39.2s\n",
      "[CV] END ..........C=100, degree=3, gamma=scale, kernel=poly; total time=  17.2s\n",
      "[CV] END ..........C=100, degree=3, gamma=scale, kernel=poly; total time=  17.7s\n",
      "[CV] END ..........C=100, degree=3, gamma=scale, kernel=poly; total time=  17.3s\n",
      "[CV] END ..........C=100, degree=3, gamma=scale, kernel=poly; total time=  17.0s\n",
      "[CV] END ..........C=100, degree=3, gamma=scale, kernel=poly; total time=  17.6s\n",
      "[CV] END .......C=100, degree=3, gamma=scale, kernel=sigmoid; total time=   8.8s\n",
      "[CV] END .......C=100, degree=3, gamma=scale, kernel=sigmoid; total time=   9.1s\n",
      "[CV] END .......C=100, degree=3, gamma=scale, kernel=sigmoid; total time=   9.1s\n",
      "[CV] END .......C=100, degree=3, gamma=scale, kernel=sigmoid; total time=   9.0s\n",
      "[CV] END .......C=100, degree=3, gamma=scale, kernel=sigmoid; total time=   9.3s\n",
      "[CV] END ............C=100, degree=3, gamma=auto, kernel=rbf; total time=  16.1s\n",
      "[CV] END ............C=100, degree=3, gamma=auto, kernel=rbf; total time=  16.0s\n",
      "[CV] END ............C=100, degree=3, gamma=auto, kernel=rbf; total time=  16.3s\n",
      "[CV] END ............C=100, degree=3, gamma=auto, kernel=rbf; total time=  16.2s\n",
      "[CV] END ............C=100, degree=3, gamma=auto, kernel=rbf; total time=  16.3s\n",
      "[CV] END .........C=100, degree=3, gamma=auto, kernel=linear; total time=  33.6s\n",
      "[CV] END .........C=100, degree=3, gamma=auto, kernel=linear; total time=  36.7s\n",
      "[CV] END .........C=100, degree=3, gamma=auto, kernel=linear; total time=  34.3s\n",
      "[CV] END .........C=100, degree=3, gamma=auto, kernel=linear; total time=  37.4s\n",
      "[CV] END .........C=100, degree=3, gamma=auto, kernel=linear; total time=  39.2s\n",
      "[CV] END ...........C=100, degree=3, gamma=auto, kernel=poly; total time=  10.2s\n",
      "[CV] END ...........C=100, degree=3, gamma=auto, kernel=poly; total time=   9.9s\n",
      "[CV] END ...........C=100, degree=3, gamma=auto, kernel=poly; total time=   9.8s\n",
      "[CV] END ...........C=100, degree=3, gamma=auto, kernel=poly; total time=  10.0s\n",
      "[CV] END ...........C=100, degree=3, gamma=auto, kernel=poly; total time=  10.0s\n",
      "[CV] END ........C=100, degree=3, gamma=auto, kernel=sigmoid; total time=  14.7s\n",
      "[CV] END ........C=100, degree=3, gamma=auto, kernel=sigmoid; total time=  13.9s\n",
      "[CV] END ........C=100, degree=3, gamma=auto, kernel=sigmoid; total time=  13.8s\n",
      "[CV] END ........C=100, degree=3, gamma=auto, kernel=sigmoid; total time=  14.7s\n",
      "[CV] END ........C=100, degree=3, gamma=auto, kernel=sigmoid; total time=  13.6s\n",
      "[CV] END ...........C=100, degree=4, gamma=scale, kernel=rbf; total time=  18.6s\n",
      "[CV] END ...........C=100, degree=4, gamma=scale, kernel=rbf; total time=  18.4s\n",
      "[CV] END ...........C=100, degree=4, gamma=scale, kernel=rbf; total time=  18.0s\n",
      "[CV] END ...........C=100, degree=4, gamma=scale, kernel=rbf; total time=  18.6s\n",
      "[CV] END ...........C=100, degree=4, gamma=scale, kernel=rbf; total time=  18.5s\n",
      "[CV] END ........C=100, degree=4, gamma=scale, kernel=linear; total time=  33.6s\n",
      "[CV] END ........C=100, degree=4, gamma=scale, kernel=linear; total time=  36.9s\n",
      "[CV] END ........C=100, degree=4, gamma=scale, kernel=linear; total time=  34.4s\n",
      "[CV] END ........C=100, degree=4, gamma=scale, kernel=linear; total time=  37.7s\n",
      "[CV] END ........C=100, degree=4, gamma=scale, kernel=linear; total time=  39.5s\n",
      "[CV] END ..........C=100, degree=4, gamma=scale, kernel=poly; total time=  18.2s\n",
      "[CV] END ..........C=100, degree=4, gamma=scale, kernel=poly; total time=  18.0s\n",
      "[CV] END ..........C=100, degree=4, gamma=scale, kernel=poly; total time=  17.8s\n",
      "[CV] END ..........C=100, degree=4, gamma=scale, kernel=poly; total time=  17.5s\n",
      "[CV] END ..........C=100, degree=4, gamma=scale, kernel=poly; total time=  17.8s\n",
      "[CV] END .......C=100, degree=4, gamma=scale, kernel=sigmoid; total time=   8.8s\n",
      "[CV] END .......C=100, degree=4, gamma=scale, kernel=sigmoid; total time=   9.2s\n",
      "[CV] END .......C=100, degree=4, gamma=scale, kernel=sigmoid; total time=   9.0s\n",
      "[CV] END .......C=100, degree=4, gamma=scale, kernel=sigmoid; total time=   8.9s\n",
      "[CV] END .......C=100, degree=4, gamma=scale, kernel=sigmoid; total time=   9.3s\n",
      "[CV] END ............C=100, degree=4, gamma=auto, kernel=rbf; total time=  15.9s\n",
      "[CV] END ............C=100, degree=4, gamma=auto, kernel=rbf; total time=  16.0s\n",
      "[CV] END ............C=100, degree=4, gamma=auto, kernel=rbf; total time=  16.3s\n",
      "[CV] END ............C=100, degree=4, gamma=auto, kernel=rbf; total time=  16.0s\n",
      "[CV] END ............C=100, degree=4, gamma=auto, kernel=rbf; total time=  16.5s\n",
      "[CV] END .........C=100, degree=4, gamma=auto, kernel=linear; total time=  33.6s\n",
      "[CV] END .........C=100, degree=4, gamma=auto, kernel=linear; total time=  36.9s\n",
      "[CV] END .........C=100, degree=4, gamma=auto, kernel=linear; total time=  34.3s\n",
      "[CV] END .........C=100, degree=4, gamma=auto, kernel=linear; total time=  37.6s\n",
      "[CV] END .........C=100, degree=4, gamma=auto, kernel=linear; total time=  39.3s\n",
      "[CV] END ...........C=100, degree=4, gamma=auto, kernel=poly; total time=  10.2s\n",
      "[CV] END ...........C=100, degree=4, gamma=auto, kernel=poly; total time=   9.9s\n",
      "[CV] END ...........C=100, degree=4, gamma=auto, kernel=poly; total time=  10.1s\n",
      "[CV] END ...........C=100, degree=4, gamma=auto, kernel=poly; total time=  10.0s\n",
      "[CV] END ...........C=100, degree=4, gamma=auto, kernel=poly; total time=  10.1s\n",
      "[CV] END ........C=100, degree=4, gamma=auto, kernel=sigmoid; total time=  14.4s\n",
      "[CV] END ........C=100, degree=4, gamma=auto, kernel=sigmoid; total time=  14.0s\n",
      "[CV] END ........C=100, degree=4, gamma=auto, kernel=sigmoid; total time=  13.7s\n",
      "[CV] END ........C=100, degree=4, gamma=auto, kernel=sigmoid; total time=  14.6s\n",
      "[CV] END ........C=100, degree=4, gamma=auto, kernel=sigmoid; total time=  13.7s\n",
      "Best Parameters:  {'C': 100, 'degree': 3, 'gamma': 'scale', 'kernel': 'poly'}\n",
      "Best Score:  0.4672897196261682\n",
      "Accuracy on Test Set:  0.475\n",
      "Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      1.00      0.64      1615\n",
      "           1       0.00      0.00      0.00       352\n",
      "           2       0.00      0.00      0.00        60\n",
      "           3       0.00      0.00      0.00       263\n",
      "           4       0.00      0.00      0.00       495\n",
      "           5       0.00      0.00      0.00        99\n",
      "           6       0.00      0.00      0.00       516\n",
      "\n",
      "    accuracy                           0.48      3400\n",
      "   macro avg       0.07      0.14      0.09      3400\n",
      "weighted avg       0.23      0.47      0.31      3400\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Parameter grid for the GridSearchCV\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],  # Regularization parameter\n",
    "    'kernel': ['rbf', 'linear', 'poly', 'sigmoid'],  # Type of SVM kernel\n",
    "    'gamma': ['scale', 'auto'],  # Kernel coefficient for 'rbf', 'poly', and 'sigmoid'\n",
    "    'degree': [2, 3, 4]  # Degree of the polynomial kernel function ('poly'). Ignored by all other kernels.\n",
    "}\n",
    "\n",
    "# Initialize the SVM classifier\n",
    "svm = SVC(random_state=42)\n",
    "\n",
    "# Initialize the GridSearchCV object with SVM classifier and the parameter grid\n",
    "grid_search = GridSearchCV(estimator=svm, param_grid=param_grid, cv=5, scoring='accuracy', verbose=2)\n",
    "\n",
    "# Fit the model with the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters and the best score\n",
    "print(\"Best Parameters: \", grid_search.best_params_)\n",
    "print(\"Best Score: \", grid_search.best_score_)\n",
    "\n",
    "# Predict on the test set with the best parameters\n",
    "y_pred = grid_search.predict(X_test)\n",
    "\n",
    "# Evaluate the classifier with the best parameters\n",
    "print(\"Accuracy on Test Set: \", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report: \")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad93360a",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "83202b7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 216 candidates, totalling 1080 fits\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  33.1s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  32.8s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  32.5s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  32.8s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  33.3s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time= 1.1min\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time= 1.1min\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time= 1.1min\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time= 1.1min\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time= 1.1min\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time= 1.6min\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time= 1.6min\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time= 1.6min\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time= 1.6min\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time= 1.7min\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  32.7s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  32.1s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  32.6s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  32.2s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  32.4s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time= 1.1min\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time= 1.1min\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time= 1.1min\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time= 1.1min\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time= 1.1min\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time= 1.6min\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time= 1.6min\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time= 1.6min\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time= 1.6min\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time= 1.6min\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=  31.9s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=  31.4s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=  31.7s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=  31.9s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=  31.2s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time= 1.1min\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time= 1.0min\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time= 1.1min\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time= 1.1min\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time= 1.0min\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time= 1.6min\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time= 1.6min\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time= 1.6min\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time= 1.6min\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time= 1.6min\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  30.6s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  30.4s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  31.0s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  30.5s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  30.6s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time= 1.0min\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time= 1.0min\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time= 1.0min\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time= 1.0min\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time= 1.0min\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time= 1.5min\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time= 1.5min\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time= 1.5min\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time= 1.5min\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time= 1.5min\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  30.4s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  30.7s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  30.3s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  30.3s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  30.3s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time= 1.0min\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time= 1.0min\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time= 1.0min\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time= 1.0min\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time= 1.0min\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time= 1.5min\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time= 1.5min\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time= 1.5min\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time= 1.5min\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time= 1.5min\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=  30.3s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=  29.3s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=  29.8s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=  30.3s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=  30.1s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=  59.4s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=  58.9s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time= 1.0min\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time= 1.0min\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time= 1.0min\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time= 1.5min\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time= 1.5min\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time= 1.5min\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time= 1.5min\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time= 1.5min\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=  27.4s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=  27.3s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=  27.5s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=  27.6s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=  27.1s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=  54.8s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=  54.8s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=  55.0s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=  55.4s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=  54.6s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time= 1.4min\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time= 1.4min\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time= 1.4min\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time= 1.4min\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time= 1.4min\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=  27.5s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=  27.4s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=  27.5s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=  27.6s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=  27.1s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=  55.0s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=  54.8s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=  55.1s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=  55.3s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=  54.5s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time= 1.4min\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time= 1.4min\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time= 1.4min\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time= 1.4min\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time= 1.4min\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  27.4s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  28.1s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  31.1s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  28.1s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  27.2s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=  54.3s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=  54.5s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=  54.4s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=  55.3s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=  54.0s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time= 1.4min\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time= 1.4min\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time= 1.4min\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time= 1.4min\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time= 1.3min\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  16.6s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  16.6s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  16.4s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  16.3s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  16.2s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=  33.1s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=  33.0s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=  33.1s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=  32.9s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=  32.7s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=  49.5s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=  49.6s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=  49.4s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=  49.9s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=  50.0s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  16.5s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  16.4s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  16.6s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  16.4s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  16.4s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  32.9s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  32.9s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  32.9s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  32.8s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  32.8s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=  49.4s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=  49.3s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=  49.3s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=  49.2s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=  49.5s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=  16.3s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=  16.3s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=  16.3s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=  16.3s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=  16.3s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=  32.8s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=  32.7s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=  32.8s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=  32.8s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=  32.6s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=  49.1s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=  49.3s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=  49.1s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=  49.0s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=  48.9s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  16.4s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  16.3s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  16.3s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  16.3s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  16.3s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=  32.7s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=  32.7s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=  32.8s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=  32.8s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=  32.8s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=  49.1s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=  49.2s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=  49.1s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=  49.2s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=  49.0s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  16.3s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  16.3s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  16.3s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  16.3s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  16.3s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=  32.7s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=  32.8s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=  32.8s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=  32.8s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=  32.7s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=  49.1s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=  49.2s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=  49.3s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=  49.1s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=  49.1s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=  16.3s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=  16.2s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=  16.3s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=  16.3s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=  16.2s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=  32.6s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=  32.8s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=  32.6s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=  32.6s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=  32.7s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=  48.9s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=  48.9s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=  49.0s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=  48.9s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=  48.9s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=  16.2s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=  16.2s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=  16.1s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=  16.1s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=  16.0s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=  32.5s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=  32.3s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=  32.4s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=  32.3s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=  32.3s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=  48.6s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=  48.6s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=  48.6s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=  48.6s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=  48.5s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=  16.1s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=  16.1s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=  16.3s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=  16.2s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=  16.1s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=  32.3s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=  32.3s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=  32.4s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=  32.3s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=  32.3s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=  48.6s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=  48.6s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=  48.6s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=  48.5s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=  48.6s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  16.1s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  16.1s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  16.1s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  16.1s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  16.1s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=  32.3s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=  32.3s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=  32.3s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=  32.3s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=  32.3s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=  48.5s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=  48.4s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=  48.6s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=  48.4s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=  48.5s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  27.4s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  27.1s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  27.3s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  27.2s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  27.2s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=  54.9s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=  54.4s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=  54.6s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=  54.5s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=  54.6s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time= 1.4min\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time= 1.4min\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time= 1.4min\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time= 1.4min\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time= 1.4min\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  27.1s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  26.9s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  26.9s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  27.0s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  26.9s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  54.2s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  53.7s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  54.4s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  53.9s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  53.9s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time= 1.4min\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time= 1.3min\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time= 1.3min\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time= 1.3min\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time= 1.3min\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=  26.5s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=  26.4s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=  26.6s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=  26.4s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=  26.3s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=  53.0s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=  52.7s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=  53.1s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=  52.9s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=  52.7s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time= 1.3min\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time= 1.3min\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time= 1.3min\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time= 1.3min\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time= 1.3min\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  26.5s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  26.2s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  26.4s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  26.3s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  26.3s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=  52.9s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=  53.1s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=  53.3s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=  53.6s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=  53.4s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time= 1.3min\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time= 1.3min\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time= 1.4min\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time= 1.3min\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time= 1.3min\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  26.7s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  26.7s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  26.9s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  26.5s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  26.5s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=  53.1s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=  52.7s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=  53.7s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=  52.9s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=  52.7s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time= 1.3min\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time= 1.3min\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time= 1.3min\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time= 1.3min\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time= 1.3min\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=  26.1s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=  25.8s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=  25.8s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=  26.0s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=  26.1s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=  52.1s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=  51.7s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=  52.0s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=  52.2s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=  52.1s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time= 1.3min\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time= 1.3min\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time= 1.3min\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time= 1.3min\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time= 1.3min\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=  24.9s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=  25.2s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=  26.6s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=  25.9s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=  26.0s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=  51.7s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=  50.1s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=  49.7s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=  49.4s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=  49.3s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time= 1.2min\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time= 1.2min\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time= 1.2min\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time= 1.3min\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time= 1.2min\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=  24.5s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=  24.5s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=  24.8s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=  24.6s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=  24.7s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=  49.8s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=  49.7s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=  49.9s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=  49.9s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=  49.2s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time= 1.2min\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time= 1.2min\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time= 1.2min\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time= 1.2min\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time= 1.2min\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  24.8s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  24.7s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  24.8s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  24.9s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  24.4s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=  49.5s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=  48.9s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=  49.6s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=  49.4s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=  48.9s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time= 1.2min\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time= 1.2min\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time= 1.2min\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time= 1.2min\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time= 1.2min\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  31.5s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  30.9s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  31.1s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  31.0s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  31.1s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time= 1.1min\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time= 1.0min\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time= 1.1min\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time= 1.0min\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time= 1.1min\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time= 1.6min\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time= 1.6min\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time= 1.6min\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time= 1.6min\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time= 1.6min\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  31.8s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  30.5s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  31.3s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  30.7s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  30.6s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time= 1.1min\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time= 1.0min\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time= 1.0min\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time= 1.0min\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time= 1.0min\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time= 1.6min\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time= 1.6min\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time= 1.6min\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time= 1.6min\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time= 1.5min\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=  30.0s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=  30.0s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=  30.3s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=  30.0s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=  30.1s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time= 1.0min\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=  59.6s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time= 1.0min\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time= 1.0min\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=  59.9s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time= 1.5min\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time= 1.5min\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time= 1.5min\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time= 1.5min\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time= 1.5min\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  29.6s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  29.5s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  29.8s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  29.5s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  29.6s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=  59.5s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=  59.0s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=  59.4s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=  59.2s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=  58.9s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time= 1.5min\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time= 1.5min\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time= 1.5min\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time= 1.5min\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time= 1.5min\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  30.4s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  30.4s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  30.3s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  30.2s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  30.2s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time= 1.0min\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time= 1.0min\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time= 1.0min\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time= 1.0min\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time= 1.0min\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time= 1.5min\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time= 1.5min\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time= 1.5min\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time= 1.5min\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time= 1.5min\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=  30.0s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=  29.4s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=  29.8s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=  30.1s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=  29.8s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=  59.5s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=  58.9s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=  58.6s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=  58.3s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=  57.9s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time= 1.5min\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time= 1.4min\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time= 1.4min\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time= 1.5min\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time= 1.4min\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=  27.0s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=  26.9s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=  27.2s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=  27.1s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=  26.8s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=  54.4s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=  54.0s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=  54.2s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=  54.4s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=  54.2s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time= 1.4min\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time= 1.3min\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time= 1.4min\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time= 1.4min\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time= 1.4min\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=  27.8s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=  27.8s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=  28.0s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=  27.9s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=  27.6s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=  55.7s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=  55.7s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=  56.0s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=  55.9s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=  55.4s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time= 1.4min\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time= 1.4min\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time= 1.4min\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time= 1.4min\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time= 1.4min\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  27.5s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  27.5s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  27.9s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  28.1s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  27.4s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=  55.5s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=  55.1s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=  55.4s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=  55.7s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=  53.4s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time= 1.3min\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time= 1.3min\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time= 1.3min\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time= 1.4min\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time= 1.3min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  46.0s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  46.5s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  46.8s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  46.1s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  45.7s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time= 1.5min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time= 1.5min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time= 1.6min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time= 1.5min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time= 1.5min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time= 2.3min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time= 2.3min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time= 2.3min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time= 2.3min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time= 2.3min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  45.7s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  45.6s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  45.6s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  45.2s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  45.9s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time= 1.5min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time= 1.5min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time= 1.5min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time= 1.5min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time= 1.5min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time= 2.3min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time= 2.3min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time= 2.3min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time= 2.3min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time= 2.3min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=  44.8s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=  45.0s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=  45.1s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=  44.6s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=  44.1s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time= 1.5min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time= 1.5min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time= 1.5min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time= 1.5min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time= 1.5min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time= 2.2min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time= 2.2min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time= 2.2min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time= 2.2min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time= 2.2min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  44.3s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  44.0s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  44.4s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  44.3s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  43.1s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time= 1.5min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time= 1.5min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time= 1.5min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time= 1.5min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time= 1.5min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time= 2.2min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time= 2.2min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time= 2.2min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time= 2.2min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time= 2.2min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  43.6s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  43.1s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  44.4s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  44.2s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  43.2s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time= 1.5min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time= 1.4min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time= 1.5min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time= 1.5min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time= 1.4min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time= 2.2min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time= 2.2min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time= 2.2min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time= 2.2min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time= 2.2min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=  43.0s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=  43.3s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=  42.8s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=  43.0s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=  42.6s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time= 1.4min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time= 1.4min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time= 1.4min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time= 1.4min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time= 1.4min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time= 2.1min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time= 2.1min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time= 2.2min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time= 2.1min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time= 2.1min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=  40.0s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=  40.1s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=  40.4s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=  40.7s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=  39.3s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time= 1.3min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time= 1.3min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time= 1.3min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time= 1.4min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time= 1.3min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time= 2.0min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time= 2.0min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time= 2.0min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time= 2.0min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time= 2.0min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=  40.1s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=  40.1s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=  40.4s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=  40.7s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=  39.2s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time= 1.3min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time= 1.3min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time= 1.3min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time= 1.4min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time= 1.3min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time= 2.0min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time= 2.0min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time= 2.0min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time= 2.0min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time= 2.0min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  40.3s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  39.9s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  40.0s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  40.0s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  39.7s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time= 1.3min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time= 1.3min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time= 1.3min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time= 1.3min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time= 1.3min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time= 2.0min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time= 2.0min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time= 2.0min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time= 2.0min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time= 2.0min\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  22.9s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  22.9s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  22.9s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  22.9s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  22.8s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=  45.8s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=  46.0s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=  46.0s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=  46.1s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=  45.8s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time= 1.1min\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time= 1.1min\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time= 1.1min\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time= 1.1min\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time= 1.1min\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  22.9s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  22.9s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  23.0s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  22.8s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  22.8s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  45.8s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  45.8s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  46.0s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  45.8s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  45.7s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time= 1.1min\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time= 1.2min\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time= 1.1min\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time= 1.1min\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time= 1.1min\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=  22.8s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=  22.7s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=  22.8s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=  22.8s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=  22.7s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=  45.8s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=  45.8s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=  45.7s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=  45.6s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=  45.5s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time= 1.1min\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time= 1.1min\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time= 1.1min\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time= 1.1min\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time= 1.1min\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  22.8s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  22.8s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  22.8s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  22.7s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  22.7s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=  45.7s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=  45.8s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=  45.7s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=  45.7s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=  45.6s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time= 1.1min\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time= 1.1min\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time= 1.1min\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time= 1.1min\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time= 1.1min\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  22.9s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  22.8s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  22.8s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  22.7s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  22.7s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=  45.6s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=  45.6s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=  45.7s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=  45.7s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=  45.6s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time= 1.1min\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time= 1.1min\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time= 1.1min\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time= 1.1min\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time= 1.1min\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=  22.8s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=  22.7s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=  22.7s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=  22.7s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=  22.6s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=  45.6s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=  45.5s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=  45.4s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=  45.5s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=  45.4s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time= 1.1min\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time= 1.1min\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time= 1.1min\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time= 1.1min\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time= 1.1min\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=  22.7s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=  22.6s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=  22.6s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=  22.5s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=  22.6s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=  45.3s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=  45.2s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=  45.2s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=  45.2s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=  45.1s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time= 1.1min\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time= 1.1min\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time= 1.1min\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time= 1.1min\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time= 1.1min\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=  22.9s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=  22.6s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=  22.6s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=  22.5s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=  22.5s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=  45.4s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=  45.3s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=  45.3s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=  45.3s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=  45.2s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time= 1.1min\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time= 1.1min\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time= 1.1min\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time= 1.1min\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time= 1.1min\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  22.6s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  22.6s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  22.6s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  22.5s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  22.5s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=  45.2s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=  45.2s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=  45.4s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=  45.2s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=  45.1s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time= 1.1min\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time= 1.1min\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time= 1.1min\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time= 1.1min\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time= 1.1min\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  38.5s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  38.1s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  38.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  38.0s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  37.9s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time= 1.3min\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time= 1.3min\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time= 1.3min\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time= 1.3min\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time= 1.3min\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time= 1.9min\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time= 1.9min\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time= 1.9min\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time= 1.9min\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time= 1.9min\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  38.0s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  37.6s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  37.9s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  37.7s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  37.7s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time= 1.3min\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time= 1.3min\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time= 1.3min\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time= 1.3min\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time= 1.3min\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time= 1.9min\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time= 1.9min\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time= 1.9min\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time= 1.9min\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time= 1.9min\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=  37.4s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=  37.4s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=  37.1s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=  37.1s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=  37.0s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time= 1.2min\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time= 1.2min\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time= 1.2min\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time= 1.2min\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time= 1.2min\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time= 1.9min\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time= 1.9min\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time= 1.9min\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time= 1.9min\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time= 1.9min\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  37.5s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  37.1s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  37.2s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  37.2s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  37.0s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time= 1.2min\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time= 1.2min\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time= 1.2min\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time= 1.2min\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time= 1.2min\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time= 1.9min\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time= 1.9min\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time= 1.9min\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time= 1.9min\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time= 1.8min\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  37.4s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  36.8s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  37.1s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  37.1s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  36.9s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time= 1.2min\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time= 1.2min\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time= 1.2min\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time= 1.2min\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time= 1.2min\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time= 1.9min\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time= 1.8min\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time= 1.9min\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time= 1.9min\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time= 1.8min\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=  36.8s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=  36.5s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=  36.7s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=  36.6s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=  36.5s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time= 1.2min\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time= 1.2min\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time= 1.2min\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time= 1.2min\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time= 1.2min\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time= 1.8min\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time= 1.8min\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time= 1.8min\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time= 1.8min\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time= 1.8min\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=  35.8s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=  35.4s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=  35.6s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=  35.4s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=  35.2s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time= 1.2min\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time= 1.2min\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time= 1.2min\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time= 1.2min\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time= 1.2min\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time= 1.8min\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time= 1.8min\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time= 1.8min\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time= 1.8min\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time= 1.8min\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=  35.9s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=  35.5s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=  35.7s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=  35.4s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=  35.2s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time= 1.2min\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time= 1.2min\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time= 1.2min\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time= 1.2min\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time= 1.2min\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time= 1.8min\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time= 1.8min\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time= 1.8min\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time= 1.8min\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time= 1.8min\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  35.7s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  35.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  35.6s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  35.1s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  35.2s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time= 1.2min\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time= 1.2min\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time= 1.2min\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time= 1.2min\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time= 1.2min\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time= 1.8min\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time= 1.8min\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time= 1.8min\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time= 1.8min\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time= 1.8min\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  43.9s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  44.5s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  44.2s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  43.8s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  43.6s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time= 1.5min\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time= 1.5min\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time= 1.5min\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time= 1.5min\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time= 1.5min\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time= 2.2min\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time= 2.2min\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time= 2.2min\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time= 2.2min\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time= 2.2min\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  43.3s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  43.2s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  43.3s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  43.5s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  43.3s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time= 1.4min\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time= 1.4min\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time= 1.4min\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time= 1.5min\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time= 1.4min\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time= 2.2min\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time= 2.2min\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time= 2.2min\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time= 2.2min\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time= 2.1min\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=  42.6s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=  42.6s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=  42.7s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=  42.4s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=  42.0s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time= 1.4min\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time= 1.4min\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time= 1.4min\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time= 1.4min\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time= 1.4min\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time= 2.1min\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time= 2.1min\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time= 2.1min\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time= 2.1min\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time= 2.1min\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  42.7s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  41.8s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  42.3s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  42.5s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  41.8s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time= 1.4min\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time= 1.4min\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time= 1.4min\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time= 1.4min\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time= 1.4min\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time= 2.1min\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time= 2.1min\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time= 2.1min\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time= 2.1min\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time= 2.1min\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  42.0s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  41.6s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  42.3s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  41.9s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  41.7s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time= 1.4min\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time= 1.4min\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time= 1.4min\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time= 1.4min\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time= 1.4min\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time= 2.1min\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time= 2.1min\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time= 2.1min\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time= 2.1min\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time= 2.1min\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=  41.2s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=  41.4s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=  41.2s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=  41.5s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=  40.7s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time= 1.4min\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time= 1.4min\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time= 1.4min\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time= 1.4min\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time= 1.4min\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time= 2.1min\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time= 2.1min\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time= 2.1min\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time= 2.1min\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time= 2.0min\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=  39.5s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=  39.2s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=  39.6s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=  39.7s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=  38.7s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time= 1.3min\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time= 1.3min\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time= 1.3min\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time= 1.3min\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time= 1.3min\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time= 2.0min\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time= 2.0min\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time= 2.0min\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time= 2.0min\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time= 1.9min\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=  39.5s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=  39.1s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=  39.6s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=  39.6s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=  38.7s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time= 1.3min\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time= 1.3min\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time= 1.3min\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time= 1.3min\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time= 1.3min\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time= 2.0min\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time= 2.0min\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time= 2.0min\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time= 2.0min\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time= 1.9min\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  39.4s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  39.0s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  39.0s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  38.9s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  38.4s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time= 1.3min\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time= 1.3min\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time= 1.3min\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time= 1.3min\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time= 1.3min\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time= 2.0min\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time= 1.9min\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time= 1.9min\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time= 2.0min\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time= 1.9min\n",
      "Best Parameters:  {'bootstrap': True, 'max_depth': 20, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Best Score:  0.47445482866043615\n",
      "Accuracy on Test Set:  0.2685294117647059\n",
      "Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.37      0.42      1615\n",
      "           1       0.11      0.04      0.05       352\n",
      "           2       0.00      0.00      0.00        60\n",
      "           3       0.00      0.00      0.00       263\n",
      "           4       0.15      0.48      0.23       495\n",
      "           5       0.00      0.00      0.00        99\n",
      "           6       0.14      0.13      0.13       516\n",
      "\n",
      "    accuracy                           0.27      3400\n",
      "   macro avg       0.13      0.14      0.12      3400\n",
      "weighted avg       0.29      0.27      0.26      3400\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Parameter grid for GridSearchCV\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],  # Number of trees in the forest\n",
    "    'max_depth': [None, 10, 20, 30],  # Maximum depth of the tree\n",
    "    'min_samples_split': [2, 5, 10],  # Minimum number of samples required to split an internal node\n",
    "    'min_samples_leaf': [1, 2, 4],  # Minimum number of samples required to be at a leaf node\n",
    "    'bootstrap': [True, False]  # Method of selecting samples for training each tree\n",
    "}\n",
    "\n",
    "# Initialize the Random Forest classifier\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Initialize GridSearchCV object with Random Forest classifier and the parameter grid\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=5, scoring='accuracy', verbose=2)\n",
    "\n",
    "# Fit the model with the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters and the best score\n",
    "print(\"Best Parameters: \", grid_search.best_params_)\n",
    "print(\"Best Score: \", grid_search.best_score_)\n",
    "\n",
    "# Predict on the test set with the best parameters\n",
    "y_pred = grid_search.predict(X_test)\n",
    "\n",
    "# Evaluate the classifier with the best parameters\n",
    "print(\"Accuracy on Test Set: \", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report: \")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e57d712",
   "metadata": {},
   "source": [
    "### Gradient Boosting Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0c68edf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 27 candidates, totalling 81 fits\n",
      "[CV] END eval_metric=mlogloss, learning_rate=0.01, max_depth=3, n_estimators=100, num_class=7, objective=multi:softmax; total time=   2.4s\n",
      "[CV] END eval_metric=mlogloss, learning_rate=0.01, max_depth=3, n_estimators=100, num_class=7, objective=multi:softmax; total time=   2.4s\n",
      "[CV] END eval_metric=mlogloss, learning_rate=0.01, max_depth=3, n_estimators=100, num_class=7, objective=multi:softmax; total time=   2.4s\n",
      "[CV] END eval_metric=mlogloss, learning_rate=0.01, max_depth=3, n_estimators=200, num_class=7, objective=multi:softmax; total time=   4.5s\n",
      "[CV] END eval_metric=mlogloss, learning_rate=0.01, max_depth=3, n_estimators=200, num_class=7, objective=multi:softmax; total time=   4.4s\n",
      "[CV] END eval_metric=mlogloss, learning_rate=0.01, max_depth=3, n_estimators=200, num_class=7, objective=multi:softmax; total time=   4.3s\n",
      "[CV] END eval_metric=mlogloss, learning_rate=0.01, max_depth=3, n_estimators=300, num_class=7, objective=multi:softmax; total time=   6.3s\n",
      "[CV] END eval_metric=mlogloss, learning_rate=0.01, max_depth=3, n_estimators=300, num_class=7, objective=multi:softmax; total time=   6.4s\n",
      "[CV] END eval_metric=mlogloss, learning_rate=0.01, max_depth=3, n_estimators=300, num_class=7, objective=multi:softmax; total time=   6.6s\n",
      "[CV] END eval_metric=mlogloss, learning_rate=0.01, max_depth=6, n_estimators=100, num_class=7, objective=multi:softmax; total time=  10.4s\n",
      "[CV] END eval_metric=mlogloss, learning_rate=0.01, max_depth=6, n_estimators=100, num_class=7, objective=multi:softmax; total time=  11.0s\n",
      "[CV] END eval_metric=mlogloss, learning_rate=0.01, max_depth=6, n_estimators=100, num_class=7, objective=multi:softmax; total time=  10.9s\n",
      "[CV] END eval_metric=mlogloss, learning_rate=0.01, max_depth=6, n_estimators=200, num_class=7, objective=multi:softmax; total time=  21.4s\n",
      "[CV] END eval_metric=mlogloss, learning_rate=0.01, max_depth=6, n_estimators=200, num_class=7, objective=multi:softmax; total time=  21.8s\n",
      "[CV] END eval_metric=mlogloss, learning_rate=0.01, max_depth=6, n_estimators=200, num_class=7, objective=multi:softmax; total time=  22.1s\n",
      "[CV] END eval_metric=mlogloss, learning_rate=0.01, max_depth=6, n_estimators=300, num_class=7, objective=multi:softmax; total time=  31.6s\n",
      "[CV] END eval_metric=mlogloss, learning_rate=0.01, max_depth=6, n_estimators=300, num_class=7, objective=multi:softmax; total time=  32.5s\n",
      "[CV] END eval_metric=mlogloss, learning_rate=0.01, max_depth=6, n_estimators=300, num_class=7, objective=multi:softmax; total time=  32.0s\n",
      "[CV] END eval_metric=mlogloss, learning_rate=0.01, max_depth=10, n_estimators=100, num_class=7, objective=multi:softmax; total time=  42.3s\n",
      "[CV] END eval_metric=mlogloss, learning_rate=0.01, max_depth=10, n_estimators=100, num_class=7, objective=multi:softmax; total time=  41.2s\n",
      "[CV] END eval_metric=mlogloss, learning_rate=0.01, max_depth=10, n_estimators=100, num_class=7, objective=multi:softmax; total time=  44.2s\n",
      "[CV] END eval_metric=mlogloss, learning_rate=0.01, max_depth=10, n_estimators=200, num_class=7, objective=multi:softmax; total time= 1.4min\n",
      "[CV] END eval_metric=mlogloss, learning_rate=0.01, max_depth=10, n_estimators=200, num_class=7, objective=multi:softmax; total time= 1.3min\n",
      "[CV] END eval_metric=mlogloss, learning_rate=0.01, max_depth=10, n_estimators=200, num_class=7, objective=multi:softmax; total time= 1.5min\n",
      "[CV] END eval_metric=mlogloss, learning_rate=0.01, max_depth=10, n_estimators=300, num_class=7, objective=multi:softmax; total time= 1.9min\n",
      "[CV] END eval_metric=mlogloss, learning_rate=0.01, max_depth=10, n_estimators=300, num_class=7, objective=multi:softmax; total time= 1.9min\n",
      "[CV] END eval_metric=mlogloss, learning_rate=0.01, max_depth=10, n_estimators=300, num_class=7, objective=multi:softmax; total time= 2.0min\n",
      "[CV] END eval_metric=mlogloss, learning_rate=0.1, max_depth=3, n_estimators=100, num_class=7, objective=multi:softmax; total time=   2.2s\n",
      "[CV] END eval_metric=mlogloss, learning_rate=0.1, max_depth=3, n_estimators=100, num_class=7, objective=multi:softmax; total time=   2.1s\n",
      "[CV] END eval_metric=mlogloss, learning_rate=0.1, max_depth=3, n_estimators=100, num_class=7, objective=multi:softmax; total time=   2.1s\n",
      "[CV] END eval_metric=mlogloss, learning_rate=0.1, max_depth=3, n_estimators=200, num_class=7, objective=multi:softmax; total time=   4.1s\n",
      "[CV] END eval_metric=mlogloss, learning_rate=0.1, max_depth=3, n_estimators=200, num_class=7, objective=multi:softmax; total time=   4.2s\n",
      "[CV] END eval_metric=mlogloss, learning_rate=0.1, max_depth=3, n_estimators=200, num_class=7, objective=multi:softmax; total time=   4.2s\n",
      "[CV] END eval_metric=mlogloss, learning_rate=0.1, max_depth=3, n_estimators=300, num_class=7, objective=multi:softmax; total time=   6.2s\n",
      "[CV] END eval_metric=mlogloss, learning_rate=0.1, max_depth=3, n_estimators=300, num_class=7, objective=multi:softmax; total time=   6.2s\n",
      "[CV] END eval_metric=mlogloss, learning_rate=0.1, max_depth=3, n_estimators=300, num_class=7, objective=multi:softmax; total time=   6.2s\n",
      "[CV] END eval_metric=mlogloss, learning_rate=0.1, max_depth=6, n_estimators=100, num_class=7, objective=multi:softmax; total time=   9.0s\n",
      "[CV] END eval_metric=mlogloss, learning_rate=0.1, max_depth=6, n_estimators=100, num_class=7, objective=multi:softmax; total time=   9.2s\n",
      "[CV] END eval_metric=mlogloss, learning_rate=0.1, max_depth=6, n_estimators=100, num_class=7, objective=multi:softmax; total time=   8.7s\n",
      "[CV] END eval_metric=mlogloss, learning_rate=0.1, max_depth=6, n_estimators=200, num_class=7, objective=multi:softmax; total time=  16.9s\n",
      "[CV] END eval_metric=mlogloss, learning_rate=0.1, max_depth=6, n_estimators=200, num_class=7, objective=multi:softmax; total time=  17.3s\n",
      "[CV] END eval_metric=mlogloss, learning_rate=0.1, max_depth=6, n_estimators=200, num_class=7, objective=multi:softmax; total time=  16.6s\n",
      "[CV] END eval_metric=mlogloss, learning_rate=0.1, max_depth=6, n_estimators=300, num_class=7, objective=multi:softmax; total time=  24.9s\n",
      "[CV] END eval_metric=mlogloss, learning_rate=0.1, max_depth=6, n_estimators=300, num_class=7, objective=multi:softmax; total time=  25.4s\n",
      "[CV] END eval_metric=mlogloss, learning_rate=0.1, max_depth=6, n_estimators=300, num_class=7, objective=multi:softmax; total time=  24.8s\n",
      "[CV] END eval_metric=mlogloss, learning_rate=0.1, max_depth=10, n_estimators=100, num_class=7, objective=multi:softmax; total time=  27.2s\n",
      "[CV] END eval_metric=mlogloss, learning_rate=0.1, max_depth=10, n_estimators=100, num_class=7, objective=multi:softmax; total time=  27.1s\n",
      "[CV] END eval_metric=mlogloss, learning_rate=0.1, max_depth=10, n_estimators=100, num_class=7, objective=multi:softmax; total time=  27.1s\n",
      "[CV] END eval_metric=mlogloss, learning_rate=0.1, max_depth=10, n_estimators=200, num_class=7, objective=multi:softmax; total time=  45.6s\n",
      "[CV] END eval_metric=mlogloss, learning_rate=0.1, max_depth=10, n_estimators=200, num_class=7, objective=multi:softmax; total time=  45.7s\n",
      "[CV] END eval_metric=mlogloss, learning_rate=0.1, max_depth=10, n_estimators=200, num_class=7, objective=multi:softmax; total time=  45.7s\n",
      "[CV] END eval_metric=mlogloss, learning_rate=0.1, max_depth=10, n_estimators=300, num_class=7, objective=multi:softmax; total time= 1.0min\n",
      "[CV] END eval_metric=mlogloss, learning_rate=0.1, max_depth=10, n_estimators=300, num_class=7, objective=multi:softmax; total time= 1.0min\n",
      "[CV] END eval_metric=mlogloss, learning_rate=0.1, max_depth=10, n_estimators=300, num_class=7, objective=multi:softmax; total time= 1.0min\n",
      "[CV] END eval_metric=mlogloss, learning_rate=0.3, max_depth=3, n_estimators=100, num_class=7, objective=multi:softmax; total time=   2.1s\n",
      "[CV] END eval_metric=mlogloss, learning_rate=0.3, max_depth=3, n_estimators=100, num_class=7, objective=multi:softmax; total time=   2.1s\n",
      "[CV] END eval_metric=mlogloss, learning_rate=0.3, max_depth=3, n_estimators=100, num_class=7, objective=multi:softmax; total time=   2.1s\n",
      "[CV] END eval_metric=mlogloss, learning_rate=0.3, max_depth=3, n_estimators=200, num_class=7, objective=multi:softmax; total time=   4.2s\n",
      "[CV] END eval_metric=mlogloss, learning_rate=0.3, max_depth=3, n_estimators=200, num_class=7, objective=multi:softmax; total time=   4.2s\n",
      "[CV] END eval_metric=mlogloss, learning_rate=0.3, max_depth=3, n_estimators=200, num_class=7, objective=multi:softmax; total time=   4.3s\n",
      "[CV] END eval_metric=mlogloss, learning_rate=0.3, max_depth=3, n_estimators=300, num_class=7, objective=multi:softmax; total time=   6.3s\n",
      "[CV] END eval_metric=mlogloss, learning_rate=0.3, max_depth=3, n_estimators=300, num_class=7, objective=multi:softmax; total time=   6.3s\n",
      "[CV] END eval_metric=mlogloss, learning_rate=0.3, max_depth=3, n_estimators=300, num_class=7, objective=multi:softmax; total time=   6.3s\n",
      "[CV] END eval_metric=mlogloss, learning_rate=0.3, max_depth=6, n_estimators=100, num_class=7, objective=multi:softmax; total time=   8.6s\n",
      "[CV] END eval_metric=mlogloss, learning_rate=0.3, max_depth=6, n_estimators=100, num_class=7, objective=multi:softmax; total time=   8.7s\n",
      "[CV] END eval_metric=mlogloss, learning_rate=0.3, max_depth=6, n_estimators=100, num_class=7, objective=multi:softmax; total time=   8.5s\n",
      "[CV] END eval_metric=mlogloss, learning_rate=0.3, max_depth=6, n_estimators=200, num_class=7, objective=multi:softmax; total time=  16.5s\n",
      "[CV] END eval_metric=mlogloss, learning_rate=0.3, max_depth=6, n_estimators=200, num_class=7, objective=multi:softmax; total time=  16.6s\n",
      "[CV] END eval_metric=mlogloss, learning_rate=0.3, max_depth=6, n_estimators=200, num_class=7, objective=multi:softmax; total time=  16.5s\n",
      "[CV] END eval_metric=mlogloss, learning_rate=0.3, max_depth=6, n_estimators=300, num_class=7, objective=multi:softmax; total time=  23.7s\n",
      "[CV] END eval_metric=mlogloss, learning_rate=0.3, max_depth=6, n_estimators=300, num_class=7, objective=multi:softmax; total time=  23.9s\n",
      "[CV] END eval_metric=mlogloss, learning_rate=0.3, max_depth=6, n_estimators=300, num_class=7, objective=multi:softmax; total time=  23.6s\n",
      "[CV] END eval_metric=mlogloss, learning_rate=0.3, max_depth=10, n_estimators=100, num_class=7, objective=multi:softmax; total time=  21.0s\n",
      "[CV] END eval_metric=mlogloss, learning_rate=0.3, max_depth=10, n_estimators=100, num_class=7, objective=multi:softmax; total time=  21.2s\n",
      "[CV] END eval_metric=mlogloss, learning_rate=0.3, max_depth=10, n_estimators=100, num_class=7, objective=multi:softmax; total time=  21.1s\n",
      "[CV] END eval_metric=mlogloss, learning_rate=0.3, max_depth=10, n_estimators=200, num_class=7, objective=multi:softmax; total time=  32.3s\n",
      "[CV] END eval_metric=mlogloss, learning_rate=0.3, max_depth=10, n_estimators=200, num_class=7, objective=multi:softmax; total time=  32.6s\n",
      "[CV] END eval_metric=mlogloss, learning_rate=0.3, max_depth=10, n_estimators=200, num_class=7, objective=multi:softmax; total time=  32.2s\n",
      "[CV] END eval_metric=mlogloss, learning_rate=0.3, max_depth=10, n_estimators=300, num_class=7, objective=multi:softmax; total time=  40.3s\n",
      "[CV] END eval_metric=mlogloss, learning_rate=0.3, max_depth=10, n_estimators=300, num_class=7, objective=multi:softmax; total time=  40.8s\n",
      "[CV] END eval_metric=mlogloss, learning_rate=0.3, max_depth=10, n_estimators=300, num_class=7, objective=multi:softmax; total time=  40.4s\n",
      "Best Parameters: {'eval_metric': 'mlogloss', 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100, 'num_class': 7, 'objective': 'multi:softmax'}\n",
      "Best Score: 0.4717289719626168\n",
      "Accuracy on Test Set: 0.16970588235294118\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.06      0.10      1615\n",
      "           1       0.00      0.00      0.00       352\n",
      "           2       0.00      0.00      0.00        60\n",
      "           3       0.00      0.00      0.00       263\n",
      "           4       0.17      0.09      0.12       495\n",
      "           5       0.00      0.00      0.00        99\n",
      "           6       0.15      0.85      0.26       516\n",
      "\n",
      "    accuracy                           0.17      3400\n",
      "   macro avg       0.12      0.14      0.07      3400\n",
      "weighted avg       0.28      0.17      0.10      3400\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Define the parameter grid for XGBoost\n",
    "param_grid = {\n",
    "    'max_depth': [3, 6, 10],  # Maximum depth of a tree\n",
    "    'learning_rate': [0.01, 0.1, 0.3],  # Step size shrinkage used to prevent overfitting\n",
    "    'n_estimators': [100, 200, 300],  # Number of trees you want to build\n",
    "    'objective': ['multi:softmax'],  # Multiclass classification using the softmax objective\n",
    "    'eval_metric': ['mlogloss'],  # Evaluation metrics for validation data\n",
    "    'num_class': [len(set(y_train))]  # Number of classes in the objective function\n",
    "}\n",
    "\n",
    "# Initialize the XGBClassifier\n",
    "xgb_model = xgb.XGBClassifier(use_label_encoder=False)\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=xgb_model, param_grid=param_grid, cv=3, scoring='accuracy', verbose=2)\n",
    "\n",
    "# Fit GridSearchCV\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters and the best score\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Score:\", grid_search.best_score_)\n",
    "\n",
    "# Predict on the test set with the best parameters\n",
    "y_pred = grid_search.predict(X_test)\n",
    "\n",
    "# Evaluate the classifier with the best parameters\n",
    "print(\"Accuracy on Test Set:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cebe972",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2b920b24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "Best Parameters:  {'metric': 'euclidean', 'n_neighbors': 9, 'weights': 'uniform'}\n",
      "Best Score:  0.4478193146417445\n",
      "Accuracy on Test Set:  0.2011764705882353\n",
      "Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.16      0.24      1615\n",
      "           1       0.00      0.00      0.00       352\n",
      "           2       0.00      0.00      0.00        60\n",
      "           3       0.07      0.00      0.01       263\n",
      "           4       0.15      0.86      0.26       495\n",
      "           5       0.00      0.00      0.00        99\n",
      "           6       0.00      0.00      0.00       516\n",
      "\n",
      "    accuracy                           0.20      3400\n",
      "   macro avg       0.10      0.15      0.07      3400\n",
      "weighted avg       0.25      0.20      0.15      3400\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Define the parameter grid for KNN\n",
    "param_grid = {\n",
    "    'n_neighbors': [3, 5, 7, 9],  # Number of neighbors to use\n",
    "    'weights': ['uniform', 'distance'],  # Weight function used in prediction\n",
    "    'metric': ['euclidean', 'manhattan', 'minkowski'],  # Metric used for the distance computation\n",
    "}\n",
    "\n",
    "# Initialize the KNN classifier\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "# Initialize GridSearchCV object with KNN classifier and the parameter grid\n",
    "grid_search = GridSearchCV(estimator=knn, param_grid=param_grid, cv=5, scoring='accuracy', verbose=2, n_jobs=-1)\n",
    "\n",
    "# Fit the model with the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters and the best score\n",
    "print(\"Best Parameters: \", grid_search.best_params_)\n",
    "print(\"Best Score: \", grid_search.best_score_)\n",
    "\n",
    "# Predict on the test set with the best parameters\n",
    "y_pred = grid_search.predict(X_test)\n",
    "\n",
    "# Evaluate the classifier with the best parameters\n",
    "print(\"Accuracy on Test Set: \", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report: \")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "415386d8",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d8d6fc9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
      "[CV] END ...................C=0.01, penalty=l2, solver=lbfgs; total time=   0.1s\n",
      "[CV] END ...................C=0.01, penalty=l2, solver=lbfgs; total time=   0.2s\n",
      "[CV] END ...................C=0.01, penalty=l2, solver=lbfgs; total time=   0.1s\n",
      "[CV] END ...................C=0.01, penalty=l2, solver=lbfgs; total time=   0.1s\n",
      "[CV] END ...................C=0.01, penalty=l2, solver=lbfgs; total time=   0.1s\n",
      "[CV] END ....................C=0.01, penalty=l2, solver=saga; total time=   1.6s\n",
      "[CV] END ....................C=0.01, penalty=l2, solver=saga; total time=   1.8s\n",
      "[CV] END ....................C=0.01, penalty=l2, solver=saga; total time=   1.7s\n",
      "[CV] END ....................C=0.01, penalty=l2, solver=saga; total time=   1.7s\n",
      "[CV] END ....................C=0.01, penalty=l2, solver=saga; total time=   1.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:204: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...............C=0.01, penalty=l2, solver=newton-cg; total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:204: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...............C=0.01, penalty=l2, solver=newton-cg; total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:204: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...............C=0.01, penalty=l2, solver=newton-cg; total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:204: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...............C=0.01, penalty=l2, solver=newton-cg; total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:204: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...............C=0.01, penalty=l2, solver=newton-cg; total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .................C=0.01, penalty=None, solver=lbfgs; total time=   4.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .................C=0.01, penalty=None, solver=lbfgs; total time=   4.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .................C=0.01, penalty=None, solver=lbfgs; total time=   4.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .................C=0.01, penalty=None, solver=lbfgs; total time=   4.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .................C=0.01, penalty=None, solver=lbfgs; total time=   4.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..................C=0.01, penalty=None, solver=saga; total time= 1.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..................C=0.01, penalty=None, solver=saga; total time= 1.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..................C=0.01, penalty=None, solver=saga; total time= 1.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..................C=0.01, penalty=None, solver=saga; total time= 1.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..................C=0.01, penalty=None, solver=saga; total time= 1.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:204: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .............C=0.01, penalty=None, solver=newton-cg; total time=  41.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:204: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .............C=0.01, penalty=None, solver=newton-cg; total time= 1.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:204: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .............C=0.01, penalty=None, solver=newton-cg; total time=  43.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:204: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .............C=0.01, penalty=None, solver=newton-cg; total time=  35.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:204: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .............C=0.01, penalty=None, solver=newton-cg; total time= 1.0min\n",
      "[CV] END ....................C=0.1, penalty=l2, solver=lbfgs; total time=   0.4s\n",
      "[CV] END ....................C=0.1, penalty=l2, solver=lbfgs; total time=   0.4s\n",
      "[CV] END ....................C=0.1, penalty=l2, solver=lbfgs; total time=   0.4s\n",
      "[CV] END ....................C=0.1, penalty=l2, solver=lbfgs; total time=   0.4s\n",
      "[CV] END ....................C=0.1, penalty=l2, solver=lbfgs; total time=   0.4s\n",
      "[CV] END .....................C=0.1, penalty=l2, solver=saga; total time=   1.4s\n",
      "[CV] END .....................C=0.1, penalty=l2, solver=saga; total time=   1.5s\n",
      "[CV] END .....................C=0.1, penalty=l2, solver=saga; total time=   1.3s\n",
      "[CV] END .....................C=0.1, penalty=l2, solver=saga; total time=   1.3s\n",
      "[CV] END .....................C=0.1, penalty=l2, solver=saga; total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:204: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................C=0.1, penalty=l2, solver=newton-cg; total time=   2.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:204: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................C=0.1, penalty=l2, solver=newton-cg; total time=   1.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:204: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................C=0.1, penalty=l2, solver=newton-cg; total time=   1.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:204: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................C=0.1, penalty=l2, solver=newton-cg; total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:204: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................C=0.1, penalty=l2, solver=newton-cg; total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..................C=0.1, penalty=None, solver=lbfgs; total time=   4.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..................C=0.1, penalty=None, solver=lbfgs; total time=   4.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..................C=0.1, penalty=None, solver=lbfgs; total time=   4.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..................C=0.1, penalty=None, solver=lbfgs; total time=   4.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..................C=0.1, penalty=None, solver=lbfgs; total time=   4.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...................C=0.1, penalty=None, solver=saga; total time= 1.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...................C=0.1, penalty=None, solver=saga; total time= 1.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...................C=0.1, penalty=None, solver=saga; total time= 1.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...................C=0.1, penalty=None, solver=saga; total time= 1.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...................C=0.1, penalty=None, solver=saga; total time= 1.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:204: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............C=0.1, penalty=None, solver=newton-cg; total time=  41.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:204: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............C=0.1, penalty=None, solver=newton-cg; total time= 1.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:204: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............C=0.1, penalty=None, solver=newton-cg; total time=  43.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:204: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............C=0.1, penalty=None, solver=newton-cg; total time=  35.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:204: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............C=0.1, penalty=None, solver=newton-cg; total time= 1.0min\n",
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   1.1s\n",
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   1.2s\n",
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   1.2s\n",
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   1.2s\n",
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   1.2s\n",
      "[CV] END .......................C=1, penalty=l2, solver=saga; total time=   3.4s\n",
      "[CV] END .......................C=1, penalty=l2, solver=saga; total time=   3.4s\n",
      "[CV] END .......................C=1, penalty=l2, solver=saga; total time=   3.4s\n",
      "[CV] END .......................C=1, penalty=l2, solver=saga; total time=   3.4s\n",
      "[CV] END .......................C=1, penalty=l2, solver=saga; total time=   3.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:204: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..................C=1, penalty=l2, solver=newton-cg; total time=   2.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:204: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..................C=1, penalty=l2, solver=newton-cg; total time=   1.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:204: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..................C=1, penalty=l2, solver=newton-cg; total time=   3.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:204: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..................C=1, penalty=l2, solver=newton-cg; total time=   2.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:204: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..................C=1, penalty=l2, solver=newton-cg; total time=   1.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ....................C=1, penalty=None, solver=lbfgs; total time=   4.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ....................C=1, penalty=None, solver=lbfgs; total time=   4.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ....................C=1, penalty=None, solver=lbfgs; total time=   4.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ....................C=1, penalty=None, solver=lbfgs; total time=   4.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ....................C=1, penalty=None, solver=lbfgs; total time=   4.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .....................C=1, penalty=None, solver=saga; total time= 1.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .....................C=1, penalty=None, solver=saga; total time= 1.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .....................C=1, penalty=None, solver=saga; total time= 1.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .....................C=1, penalty=None, solver=saga; total time= 1.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .....................C=1, penalty=None, solver=saga; total time= 1.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:204: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................C=1, penalty=None, solver=newton-cg; total time=  41.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:204: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................C=1, penalty=None, solver=newton-cg; total time= 1.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:204: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................C=1, penalty=None, solver=newton-cg; total time=  44.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:204: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................C=1, penalty=None, solver=newton-cg; total time=  35.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:204: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................C=1, penalty=None, solver=newton-cg; total time= 1.0min\n",
      "[CV] END .....................C=10, penalty=l2, solver=lbfgs; total time=   3.2s\n",
      "[CV] END .....................C=10, penalty=l2, solver=lbfgs; total time=   3.1s\n",
      "[CV] END .....................C=10, penalty=l2, solver=lbfgs; total time=   3.3s\n",
      "[CV] END .....................C=10, penalty=l2, solver=lbfgs; total time=   3.1s\n",
      "[CV] END .....................C=10, penalty=l2, solver=lbfgs; total time=   3.5s\n",
      "[CV] END ......................C=10, penalty=l2, solver=saga; total time=  22.0s\n",
      "[CV] END ......................C=10, penalty=l2, solver=saga; total time=  18.8s\n",
      "[CV] END ......................C=10, penalty=l2, solver=saga; total time=  18.5s\n",
      "[CV] END ......................C=10, penalty=l2, solver=saga; total time=  19.8s\n",
      "[CV] END ......................C=10, penalty=l2, solver=saga; total time=  22.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:425: LineSearchWarning: Rounding errors prevent the line search from converging\n",
      "  warn(msg, LineSearchWarning)\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:204: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .................C=10, penalty=l2, solver=newton-cg; total time=   6.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:204: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .................C=10, penalty=l2, solver=newton-cg; total time=   4.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:204: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .................C=10, penalty=l2, solver=newton-cg; total time=   4.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:204: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .................C=10, penalty=l2, solver=newton-cg; total time=   4.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:204: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .................C=10, penalty=l2, solver=newton-cg; total time=   4.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...................C=10, penalty=None, solver=lbfgs; total time=   4.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...................C=10, penalty=None, solver=lbfgs; total time=   4.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...................C=10, penalty=None, solver=lbfgs; total time=   4.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...................C=10, penalty=None, solver=lbfgs; total time=   4.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...................C=10, penalty=None, solver=lbfgs; total time=   4.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ....................C=10, penalty=None, solver=saga; total time= 1.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ....................C=10, penalty=None, solver=saga; total time= 1.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ....................C=10, penalty=None, solver=saga; total time= 1.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ....................C=10, penalty=None, solver=saga; total time= 1.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ....................C=10, penalty=None, solver=saga; total time= 1.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:204: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...............C=10, penalty=None, solver=newton-cg; total time=  41.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:204: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...............C=10, penalty=None, solver=newton-cg; total time= 1.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:204: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...............C=10, penalty=None, solver=newton-cg; total time=  43.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:204: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...............C=10, penalty=None, solver=newton-cg; total time=  35.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:204: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...............C=10, penalty=None, solver=newton-cg; total time= 1.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ....................C=100, penalty=l2, solver=lbfgs; total time=   4.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ....................C=100, penalty=l2, solver=lbfgs; total time=   4.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ....................C=100, penalty=l2, solver=lbfgs; total time=   4.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ....................C=100, penalty=l2, solver=lbfgs; total time=   4.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ....................C=100, penalty=l2, solver=lbfgs; total time=   4.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .....................C=100, penalty=l2, solver=saga; total time= 1.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .....................C=100, penalty=l2, solver=saga; total time= 1.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .....................C=100, penalty=l2, solver=saga; total time= 1.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .....................C=100, penalty=l2, solver=saga; total time= 1.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .....................C=100, penalty=l2, solver=saga; total time= 1.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:204: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................C=100, penalty=l2, solver=newton-cg; total time=   7.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:204: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................C=100, penalty=l2, solver=newton-cg; total time=   7.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:204: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................C=100, penalty=l2, solver=newton-cg; total time=   8.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:204: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................C=100, penalty=l2, solver=newton-cg; total time=   8.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:204: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................C=100, penalty=l2, solver=newton-cg; total time=  12.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..................C=100, penalty=None, solver=lbfgs; total time=   4.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..................C=100, penalty=None, solver=lbfgs; total time=   4.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..................C=100, penalty=None, solver=lbfgs; total time=   4.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..................C=100, penalty=None, solver=lbfgs; total time=   4.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..................C=100, penalty=None, solver=lbfgs; total time=   4.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...................C=100, penalty=None, solver=saga; total time= 1.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...................C=100, penalty=None, solver=saga; total time= 1.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...................C=100, penalty=None, solver=saga; total time= 1.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...................C=100, penalty=None, solver=saga; total time= 1.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...................C=100, penalty=None, solver=saga; total time= 1.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:204: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............C=100, penalty=None, solver=newton-cg; total time=  41.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:204: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............C=100, penalty=None, solver=newton-cg; total time= 1.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:204: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............C=100, penalty=None, solver=newton-cg; total time=  43.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:204: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............C=100, penalty=None, solver=newton-cg; total time=  35.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:204: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............C=100, penalty=None, solver=newton-cg; total time= 1.0min\n",
      "Best Parameters:  {'C': 100, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "Best Score:  0.47904984423676017\n",
      "Accuracy on Test Set:  0.10352941176470588\n",
      "Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      1615\n",
      "           1       0.10      1.00      0.19       352\n",
      "           2       0.00      0.00      0.00        60\n",
      "           3       0.00      0.00      0.00       263\n",
      "           4       0.00      0.00      0.00       495\n",
      "           5       0.00      0.00      0.00        99\n",
      "           6       0.00      0.00      0.00       516\n",
      "\n",
      "    accuracy                           0.10      3400\n",
      "   macro avg       0.01      0.14      0.03      3400\n",
      "weighted avg       0.01      0.10      0.02      3400\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:204: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Define the parameter grid for Logistic Regression\n",
    "param_grid = {\n",
    "    'penalty': ['l2', None],  # Norm used in the penalization\n",
    "    'C': [0.01, 0.1, 1, 10, 100],  # Inverse of regularization strength\n",
    "    'solver': ['lbfgs', 'saga', 'newton-cg']  # Algorithm to use in the optimization problem\n",
    "}\n",
    "\n",
    "# Note: 'saga' solver supports both l1 and l2 penalty, while 'lbfgs' and 'newton-cg' support only l2.\n",
    "# Make sure the combinations of solver and penalty are compatible.\n",
    "\n",
    "# Initialize the Logistic Regression classifier\n",
    "logreg = LogisticRegression(max_iter=1000, multi_class='multinomial')\n",
    "\n",
    "# Initialize GridSearchCV object with Logistic Regression classifier and the parameter grid\n",
    "grid_search = GridSearchCV(estimator=logreg, param_grid=param_grid, cv=5, scoring='accuracy', verbose=2)\n",
    "\n",
    "# Fit the model with the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters and the best score\n",
    "print(\"Best Parameters: \", grid_search.best_params_)\n",
    "print(\"Best Score: \", grid_search.best_score_)\n",
    "\n",
    "# Predict on the test set with the best parameters\n",
    "y_pred = grid_search.predict(X_test)\n",
    "\n",
    "# Evaluate the classifier with the best parameters\n",
    "print(\"Accuracy on Test Set: \", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report: \")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54abb777",
   "metadata": {},
   "source": [
    "### Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7dc93ead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 90 candidates, totalling 450 fits\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=2; total time=   7.6s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=2; total time=   9.3s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=2; total time=   8.9s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=2; total time=   8.0s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=2; total time=   8.8s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=5; total time=   7.5s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=5; total time=   9.2s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=5; total time=   8.8s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=5; total time=   7.9s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=5; total time=   8.7s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=10; total time=   7.4s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=10; total time=   9.1s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=10; total time=   8.7s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=10; total time=   7.8s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=10; total time=   8.6s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=2, min_samples_split=2; total time=   7.2s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=2, min_samples_split=2; total time=   8.9s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=2, min_samples_split=2; total time=   8.4s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=2, min_samples_split=2; total time=   7.6s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=2, min_samples_split=2; total time=   8.4s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=2, min_samples_split=5; total time=   7.2s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=2, min_samples_split=5; total time=   8.9s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=2, min_samples_split=5; total time=   8.5s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=2, min_samples_split=5; total time=   7.6s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=2, min_samples_split=5; total time=   8.5s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=2, min_samples_split=10; total time=   7.2s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=2, min_samples_split=10; total time=   8.9s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=2, min_samples_split=10; total time=   8.3s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=2, min_samples_split=10; total time=   7.4s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=2, min_samples_split=10; total time=   8.4s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=4, min_samples_split=2; total time=   6.9s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=4, min_samples_split=2; total time=   8.2s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=4, min_samples_split=2; total time=   7.6s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=4, min_samples_split=2; total time=   6.8s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=4, min_samples_split=2; total time=   7.8s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=4, min_samples_split=5; total time=   6.7s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=4, min_samples_split=5; total time=   8.3s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=4, min_samples_split=5; total time=   7.6s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=4, min_samples_split=5; total time=   7.0s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=4, min_samples_split=5; total time=   7.7s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=4, min_samples_split=10; total time=   6.9s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=4, min_samples_split=10; total time=   8.3s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=4, min_samples_split=10; total time=   7.6s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=4, min_samples_split=10; total time=   6.9s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=4, min_samples_split=10; total time=   7.7s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=2; total time=   3.8s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=2; total time=   3.9s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=2; total time=   3.8s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=2; total time=   3.8s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=2; total time=   3.8s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=5; total time=   3.8s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=5; total time=   3.9s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=5; total time=   3.8s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=5; total time=   3.8s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=5; total time=   3.9s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=10; total time=   3.8s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=10; total time=   3.9s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=10; total time=   3.8s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=10; total time=   3.9s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=10; total time=   3.8s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=2, min_samples_split=2; total time=   3.8s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=2, min_samples_split=2; total time=   3.8s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=2, min_samples_split=2; total time=   3.9s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=2, min_samples_split=2; total time=   3.8s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=2, min_samples_split=2; total time=   3.8s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=2, min_samples_split=5; total time=   3.8s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=2, min_samples_split=5; total time=   3.9s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=2, min_samples_split=5; total time=   3.8s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=2, min_samples_split=5; total time=   3.8s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=2, min_samples_split=5; total time=   3.8s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=2, min_samples_split=10; total time=   3.8s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=2, min_samples_split=10; total time=   3.8s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=2, min_samples_split=10; total time=   3.8s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=2, min_samples_split=10; total time=   3.8s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=2, min_samples_split=10; total time=   3.8s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=4, min_samples_split=2; total time=   3.7s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=4, min_samples_split=2; total time=   3.8s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=4, min_samples_split=2; total time=   3.8s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=4, min_samples_split=2; total time=   3.8s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=4, min_samples_split=2; total time=   3.8s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=4, min_samples_split=5; total time=   3.8s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=4, min_samples_split=5; total time=   3.8s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=4, min_samples_split=5; total time=   3.8s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=4, min_samples_split=5; total time=   3.7s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=4, min_samples_split=5; total time=   3.8s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=4, min_samples_split=10; total time=   3.8s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=4, min_samples_split=10; total time=   3.9s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=4, min_samples_split=10; total time=   3.8s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=4, min_samples_split=10; total time=   3.8s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=4, min_samples_split=10; total time=   3.8s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=1, min_samples_split=2; total time=   6.3s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=1, min_samples_split=2; total time=   6.6s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=1, min_samples_split=2; total time=   6.6s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=1, min_samples_split=2; total time=   6.3s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=1, min_samples_split=2; total time=   6.5s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=1, min_samples_split=5; total time=   6.2s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=1, min_samples_split=5; total time=   6.5s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=1, min_samples_split=5; total time=   6.5s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=1, min_samples_split=5; total time=   6.3s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=1, min_samples_split=5; total time=   6.3s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=1, min_samples_split=10; total time=   6.2s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=1, min_samples_split=10; total time=   6.6s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=1, min_samples_split=10; total time=   6.6s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=1, min_samples_split=10; total time=   6.1s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=1, min_samples_split=10; total time=   6.2s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=2, min_samples_split=2; total time=   6.2s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=2, min_samples_split=2; total time=   6.5s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=2, min_samples_split=2; total time=   6.5s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=2, min_samples_split=2; total time=   6.2s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=2, min_samples_split=2; total time=   6.2s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=2, min_samples_split=5; total time=   6.2s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=2, min_samples_split=5; total time=   6.5s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=2, min_samples_split=5; total time=   6.5s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=2, min_samples_split=5; total time=   6.2s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=2, min_samples_split=5; total time=   6.3s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=2, min_samples_split=10; total time=   6.1s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=2, min_samples_split=10; total time=   6.5s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=2, min_samples_split=10; total time=   6.5s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=2, min_samples_split=10; total time=   6.1s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=2, min_samples_split=10; total time=   6.2s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=4, min_samples_split=2; total time=   5.9s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=4, min_samples_split=2; total time=   6.4s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=4, min_samples_split=2; total time=   6.4s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=4, min_samples_split=2; total time=   6.0s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=4, min_samples_split=2; total time=   6.1s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=4, min_samples_split=5; total time=   5.9s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=4, min_samples_split=5; total time=   6.4s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=4, min_samples_split=5; total time=   6.3s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=4, min_samples_split=5; total time=   6.0s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=4, min_samples_split=5; total time=   6.1s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=4, min_samples_split=10; total time=   5.9s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=4, min_samples_split=10; total time=   6.3s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=4, min_samples_split=10; total time=   6.3s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=4, min_samples_split=10; total time=   5.9s\n",
      "[CV] END criterion=gini, max_depth=20, min_samples_leaf=4, min_samples_split=10; total time=   6.1s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=1, min_samples_split=2; total time=   7.3s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=1, min_samples_split=2; total time=   8.2s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=1, min_samples_split=2; total time=   8.0s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=1, min_samples_split=2; total time=   7.4s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=1, min_samples_split=2; total time=   7.6s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=1, min_samples_split=5; total time=   7.2s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=1, min_samples_split=5; total time=   8.0s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=1, min_samples_split=5; total time=   8.0s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=1, min_samples_split=5; total time=   7.2s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=1, min_samples_split=5; total time=   7.5s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=1, min_samples_split=10; total time=   7.1s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=1, min_samples_split=10; total time=   8.1s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=1, min_samples_split=10; total time=   7.9s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=1, min_samples_split=10; total time=   7.1s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=1, min_samples_split=10; total time=   7.5s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=2, min_samples_split=2; total time=   7.1s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=2, min_samples_split=2; total time=   8.0s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=2, min_samples_split=2; total time=   7.8s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=2, min_samples_split=2; total time=   7.1s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=2, min_samples_split=2; total time=   7.5s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=2, min_samples_split=5; total time=   7.0s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=2, min_samples_split=5; total time=   7.9s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=2, min_samples_split=5; total time=   7.7s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=2, min_samples_split=5; total time=   7.1s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=2, min_samples_split=5; total time=   7.4s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=2, min_samples_split=10; total time=   7.0s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=2, min_samples_split=10; total time=   7.9s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=2, min_samples_split=10; total time=   7.8s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=2, min_samples_split=10; total time=   7.0s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=2, min_samples_split=10; total time=   7.4s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=4, min_samples_split=2; total time=   6.6s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=4, min_samples_split=2; total time=   7.6s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=4, min_samples_split=2; total time=   7.3s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=4, min_samples_split=2; total time=   6.6s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=4, min_samples_split=2; total time=   7.1s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=4, min_samples_split=5; total time=   6.7s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=4, min_samples_split=5; total time=   7.5s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=4, min_samples_split=5; total time=   7.3s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=4, min_samples_split=5; total time=   6.7s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=4, min_samples_split=5; total time=   7.1s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=4, min_samples_split=10; total time=   6.6s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=4, min_samples_split=10; total time=   7.6s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=4, min_samples_split=10; total time=   7.3s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=4, min_samples_split=10; total time=   6.7s\n",
      "[CV] END criterion=gini, max_depth=30, min_samples_leaf=4, min_samples_split=10; total time=   7.0s\n",
      "[CV] END criterion=gini, max_depth=40, min_samples_leaf=1, min_samples_split=2; total time=   7.6s\n",
      "[CV] END criterion=gini, max_depth=40, min_samples_leaf=1, min_samples_split=2; total time=   8.8s\n",
      "[CV] END criterion=gini, max_depth=40, min_samples_leaf=1, min_samples_split=2; total time=   8.7s\n",
      "[CV] END criterion=gini, max_depth=40, min_samples_leaf=1, min_samples_split=2; total time=   7.7s\n",
      "[CV] END criterion=gini, max_depth=40, min_samples_leaf=1, min_samples_split=2; total time=   8.3s\n",
      "[CV] END criterion=gini, max_depth=40, min_samples_leaf=1, min_samples_split=5; total time=   7.5s\n",
      "[CV] END criterion=gini, max_depth=40, min_samples_leaf=1, min_samples_split=5; total time=   8.9s\n",
      "[CV] END criterion=gini, max_depth=40, min_samples_leaf=1, min_samples_split=5; total time=   8.5s\n",
      "[CV] END criterion=gini, max_depth=40, min_samples_leaf=1, min_samples_split=5; total time=   7.7s\n",
      "[CV] END criterion=gini, max_depth=40, min_samples_leaf=1, min_samples_split=5; total time=   8.1s\n",
      "[CV] END criterion=gini, max_depth=40, min_samples_leaf=1, min_samples_split=10; total time=   7.5s\n",
      "[CV] END criterion=gini, max_depth=40, min_samples_leaf=1, min_samples_split=10; total time=   8.7s\n",
      "[CV] END criterion=gini, max_depth=40, min_samples_leaf=1, min_samples_split=10; total time=   8.4s\n",
      "[CV] END criterion=gini, max_depth=40, min_samples_leaf=1, min_samples_split=10; total time=   7.5s\n",
      "[CV] END criterion=gini, max_depth=40, min_samples_leaf=1, min_samples_split=10; total time=   8.1s\n",
      "[CV] END criterion=gini, max_depth=40, min_samples_leaf=2, min_samples_split=2; total time=   7.3s\n",
      "[CV] END criterion=gini, max_depth=40, min_samples_leaf=2, min_samples_split=2; total time=   8.6s\n",
      "[CV] END criterion=gini, max_depth=40, min_samples_leaf=2, min_samples_split=2; total time=   8.2s\n",
      "[CV] END criterion=gini, max_depth=40, min_samples_leaf=2, min_samples_split=2; total time=   7.5s\n",
      "[CV] END criterion=gini, max_depth=40, min_samples_leaf=2, min_samples_split=2; total time=   7.9s\n",
      "[CV] END criterion=gini, max_depth=40, min_samples_leaf=2, min_samples_split=5; total time=   7.3s\n",
      "[CV] END criterion=gini, max_depth=40, min_samples_leaf=2, min_samples_split=5; total time=   8.6s\n",
      "[CV] END criterion=gini, max_depth=40, min_samples_leaf=2, min_samples_split=5; total time=   8.2s\n",
      "[CV] END criterion=gini, max_depth=40, min_samples_leaf=2, min_samples_split=5; total time=   7.5s\n",
      "[CV] END criterion=gini, max_depth=40, min_samples_leaf=2, min_samples_split=5; total time=   7.9s\n",
      "[CV] END criterion=gini, max_depth=40, min_samples_leaf=2, min_samples_split=10; total time=   7.2s\n",
      "[CV] END criterion=gini, max_depth=40, min_samples_leaf=2, min_samples_split=10; total time=   8.6s\n",
      "[CV] END criterion=gini, max_depth=40, min_samples_leaf=2, min_samples_split=10; total time=   8.4s\n",
      "[CV] END criterion=gini, max_depth=40, min_samples_leaf=2, min_samples_split=10; total time=   7.5s\n",
      "[CV] END criterion=gini, max_depth=40, min_samples_leaf=2, min_samples_split=10; total time=   8.1s\n",
      "[CV] END criterion=gini, max_depth=40, min_samples_leaf=4, min_samples_split=2; total time=   7.0s\n",
      "[CV] END criterion=gini, max_depth=40, min_samples_leaf=4, min_samples_split=2; total time=   8.1s\n",
      "[CV] END criterion=gini, max_depth=40, min_samples_leaf=4, min_samples_split=2; total time=   7.8s\n",
      "[CV] END criterion=gini, max_depth=40, min_samples_leaf=4, min_samples_split=2; total time=   6.9s\n",
      "[CV] END criterion=gini, max_depth=40, min_samples_leaf=4, min_samples_split=2; total time=   7.5s\n",
      "[CV] END criterion=gini, max_depth=40, min_samples_leaf=4, min_samples_split=5; total time=   6.8s\n",
      "[CV] END criterion=gini, max_depth=40, min_samples_leaf=4, min_samples_split=5; total time=   8.0s\n",
      "[CV] END criterion=gini, max_depth=40, min_samples_leaf=4, min_samples_split=5; total time=   7.7s\n",
      "[CV] END criterion=gini, max_depth=40, min_samples_leaf=4, min_samples_split=5; total time=   7.0s\n",
      "[CV] END criterion=gini, max_depth=40, min_samples_leaf=4, min_samples_split=5; total time=   7.5s\n",
      "[CV] END criterion=gini, max_depth=40, min_samples_leaf=4, min_samples_split=10; total time=   6.8s\n",
      "[CV] END criterion=gini, max_depth=40, min_samples_leaf=4, min_samples_split=10; total time=   8.0s\n",
      "[CV] END criterion=gini, max_depth=40, min_samples_leaf=4, min_samples_split=10; total time=   7.7s\n",
      "[CV] END criterion=gini, max_depth=40, min_samples_leaf=4, min_samples_split=10; total time=   6.8s\n",
      "[CV] END criterion=gini, max_depth=40, min_samples_leaf=4, min_samples_split=10; total time=   7.4s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=2; total time=  11.1s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=2; total time=  11.2s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=2; total time=  11.6s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=2; total time=  11.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=2; total time=  10.3s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=5; total time=  11.1s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=5; total time=  11.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=5; total time=  11.6s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=5; total time=  10.9s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=5; total time=  10.3s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=10; total time=  11.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=10; total time=  11.1s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=10; total time=  11.5s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=10; total time=  10.8s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=10; total time=  10.2s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=2, min_samples_split=2; total time=  11.4s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=2, min_samples_split=2; total time=  11.5s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=2, min_samples_split=2; total time=  12.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=2, min_samples_split=2; total time=  11.1s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=2, min_samples_split=2; total time=  10.2s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=2, min_samples_split=5; total time=  11.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=2, min_samples_split=5; total time=  10.9s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=2, min_samples_split=5; total time=  11.5s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=2, min_samples_split=5; total time=  10.6s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=2, min_samples_split=5; total time=  10.1s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=2, min_samples_split=10; total time=  10.9s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=2, min_samples_split=10; total time=  10.7s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=2, min_samples_split=10; total time=  11.3s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=2, min_samples_split=10; total time=  10.6s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=2, min_samples_split=10; total time=   9.9s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=4, min_samples_split=2; total time=  10.6s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=4, min_samples_split=2; total time=  10.5s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=4, min_samples_split=2; total time=  11.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=4, min_samples_split=2; total time=  10.3s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=4, min_samples_split=2; total time=   9.7s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=4, min_samples_split=5; total time=  10.6s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=4, min_samples_split=5; total time=  10.6s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=4, min_samples_split=5; total time=  11.2s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=4, min_samples_split=5; total time=  10.3s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=4, min_samples_split=5; total time=   9.7s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=4, min_samples_split=10; total time=  10.5s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=4, min_samples_split=10; total time=  10.6s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=4, min_samples_split=10; total time=  11.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=4, min_samples_split=10; total time=  10.2s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=4, min_samples_split=10; total time=   9.6s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=2; total time=   7.2s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=2; total time=   7.2s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=2; total time=   7.2s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=2; total time=   7.2s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=2; total time=   7.1s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=5; total time=   7.1s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=5; total time=   7.2s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=5; total time=   7.2s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=5; total time=   7.2s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=5; total time=   7.1s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=10; total time=   7.1s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=10; total time=   7.2s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=10; total time=   7.2s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=10; total time=   7.1s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=10; total time=   7.2s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=2; total time=   7.1s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=2; total time=   7.2s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=2; total time=   7.1s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=2; total time=   7.1s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=2; total time=   7.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=5; total time=   7.2s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=5; total time=   7.2s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=5; total time=   7.2s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=5; total time=   7.1s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=5; total time=   7.1s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=10; total time=   7.1s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=10; total time=   7.2s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=10; total time=   7.1s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=10; total time=   7.2s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=10; total time=   7.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=4, min_samples_split=2; total time=   7.1s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=4, min_samples_split=2; total time=   7.2s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=4, min_samples_split=2; total time=   7.1s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=4, min_samples_split=2; total time=   7.1s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=4, min_samples_split=2; total time=   7.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=4, min_samples_split=5; total time=   7.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=4, min_samples_split=5; total time=   7.1s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=4, min_samples_split=5; total time=   7.1s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=4, min_samples_split=5; total time=   7.1s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=4, min_samples_split=5; total time=   7.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=4, min_samples_split=10; total time=   7.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=4, min_samples_split=10; total time=   7.1s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=4, min_samples_split=10; total time=   7.1s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=4, min_samples_split=10; total time=   7.1s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=4, min_samples_split=10; total time=   7.0s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=1, min_samples_split=2; total time=  10.6s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=1, min_samples_split=2; total time=  10.6s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=1, min_samples_split=2; total time=  10.7s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=1, min_samples_split=2; total time=  10.6s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=1, min_samples_split=2; total time=   9.9s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=1, min_samples_split=5; total time=  10.6s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=1, min_samples_split=5; total time=  10.5s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=1, min_samples_split=5; total time=  10.8s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=1, min_samples_split=5; total time=  10.6s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=1, min_samples_split=5; total time=   9.9s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=1, min_samples_split=10; total time=  10.5s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=1, min_samples_split=10; total time=  10.4s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=1, min_samples_split=10; total time=  10.5s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=1, min_samples_split=10; total time=  10.4s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=1, min_samples_split=10; total time=   9.7s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=2, min_samples_split=2; total time=  10.6s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=2, min_samples_split=2; total time=  10.5s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=2, min_samples_split=2; total time=  10.5s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=2, min_samples_split=2; total time=  10.3s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=2, min_samples_split=2; total time=   9.8s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=2, min_samples_split=5; total time=  10.5s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=2, min_samples_split=5; total time=  10.4s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=2, min_samples_split=5; total time=  10.6s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=2, min_samples_split=5; total time=  10.4s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=2, min_samples_split=5; total time=   9.7s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=2, min_samples_split=10; total time=  10.4s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=2, min_samples_split=10; total time=  10.3s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=2, min_samples_split=10; total time=  10.4s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=2, min_samples_split=10; total time=  10.2s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=2, min_samples_split=10; total time=   9.6s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=4, min_samples_split=2; total time=  10.2s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=4, min_samples_split=2; total time=  10.1s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=4, min_samples_split=2; total time=  10.3s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=4, min_samples_split=2; total time=  10.0s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=4, min_samples_split=2; total time=   9.4s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=4, min_samples_split=5; total time=  10.2s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=4, min_samples_split=5; total time=  10.0s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=4, min_samples_split=5; total time=  10.2s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=4, min_samples_split=5; total time=  10.1s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=4, min_samples_split=5; total time=   9.4s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=4, min_samples_split=10; total time=  10.3s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=4, min_samples_split=10; total time=  10.0s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=4, min_samples_split=10; total time=  10.2s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=4, min_samples_split=10; total time=  10.0s\n",
      "[CV] END criterion=entropy, max_depth=20, min_samples_leaf=4, min_samples_split=10; total time=   9.3s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=1, min_samples_split=2; total time=  11.0s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=1, min_samples_split=2; total time=  10.9s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=1, min_samples_split=2; total time=  11.6s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=1, min_samples_split=2; total time=  10.7s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=1, min_samples_split=2; total time=  10.1s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=1, min_samples_split=5; total time=  11.0s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=1, min_samples_split=5; total time=  10.9s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=1, min_samples_split=5; total time=  11.4s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=1, min_samples_split=5; total time=  10.7s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=1, min_samples_split=5; total time=  10.1s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=1, min_samples_split=10; total time=  10.9s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=1, min_samples_split=10; total time=  10.7s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=1, min_samples_split=10; total time=  11.3s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=1, min_samples_split=10; total time=  10.5s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=1, min_samples_split=10; total time=   9.9s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=2, min_samples_split=2; total time=  10.9s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=2, min_samples_split=2; total time=  10.9s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=2, min_samples_split=2; total time=  11.3s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=2, min_samples_split=2; total time=  10.9s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=2, min_samples_split=2; total time=  10.0s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=2, min_samples_split=5; total time=  10.8s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=2, min_samples_split=5; total time=  10.7s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=2, min_samples_split=5; total time=  11.3s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=2, min_samples_split=5; total time=  10.5s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=2, min_samples_split=5; total time=  10.0s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=2, min_samples_split=10; total time=  10.8s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=2, min_samples_split=10; total time=  10.6s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=2, min_samples_split=10; total time=  11.1s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=2, min_samples_split=10; total time=  10.4s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=2, min_samples_split=10; total time=   9.8s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=4, min_samples_split=2; total time=  10.5s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=4, min_samples_split=2; total time=  10.5s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=4, min_samples_split=2; total time=  10.9s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=4, min_samples_split=2; total time=  10.1s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=4, min_samples_split=2; total time=   9.6s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=4, min_samples_split=5; total time=  10.4s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=4, min_samples_split=5; total time=  10.5s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=4, min_samples_split=5; total time=  10.9s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=4, min_samples_split=5; total time=  10.2s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=4, min_samples_split=5; total time=   9.6s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=4, min_samples_split=10; total time=  10.5s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=4, min_samples_split=10; total time=  10.3s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=4, min_samples_split=10; total time=  10.9s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=4, min_samples_split=10; total time=  10.1s\n",
      "[CV] END criterion=entropy, max_depth=30, min_samples_leaf=4, min_samples_split=10; total time=   9.5s\n",
      "[CV] END criterion=entropy, max_depth=40, min_samples_leaf=1, min_samples_split=2; total time=  11.1s\n",
      "[CV] END criterion=entropy, max_depth=40, min_samples_leaf=1, min_samples_split=2; total time=  11.0s\n",
      "[CV] END criterion=entropy, max_depth=40, min_samples_leaf=1, min_samples_split=2; total time=  11.5s\n",
      "[CV] END criterion=entropy, max_depth=40, min_samples_leaf=1, min_samples_split=2; total time=  10.9s\n",
      "[CV] END criterion=entropy, max_depth=40, min_samples_leaf=1, min_samples_split=2; total time=  10.2s\n",
      "[CV] END criterion=entropy, max_depth=40, min_samples_leaf=1, min_samples_split=5; total time=  11.0s\n",
      "[CV] END criterion=entropy, max_depth=40, min_samples_leaf=1, min_samples_split=5; total time=  10.9s\n",
      "[CV] END criterion=entropy, max_depth=40, min_samples_leaf=1, min_samples_split=5; total time=  11.5s\n",
      "[CV] END criterion=entropy, max_depth=40, min_samples_leaf=1, min_samples_split=5; total time=  10.7s\n",
      "[CV] END criterion=entropy, max_depth=40, min_samples_leaf=1, min_samples_split=5; total time=  10.1s\n",
      "[CV] END criterion=entropy, max_depth=40, min_samples_leaf=1, min_samples_split=10; total time=  10.8s\n",
      "[CV] END criterion=entropy, max_depth=40, min_samples_leaf=1, min_samples_split=10; total time=  10.7s\n",
      "[CV] END criterion=entropy, max_depth=40, min_samples_leaf=1, min_samples_split=10; total time=  11.2s\n",
      "[CV] END criterion=entropy, max_depth=40, min_samples_leaf=1, min_samples_split=10; total time=  10.6s\n",
      "[CV] END criterion=entropy, max_depth=40, min_samples_leaf=1, min_samples_split=10; total time=   9.9s\n",
      "[CV] END criterion=entropy, max_depth=40, min_samples_leaf=2, min_samples_split=2; total time=  10.8s\n",
      "[CV] END criterion=entropy, max_depth=40, min_samples_leaf=2, min_samples_split=2; total time=  10.8s\n",
      "[CV] END criterion=entropy, max_depth=40, min_samples_leaf=2, min_samples_split=2; total time=  11.4s\n",
      "[CV] END criterion=entropy, max_depth=40, min_samples_leaf=2, min_samples_split=2; total time=  10.6s\n",
      "[CV] END criterion=entropy, max_depth=40, min_samples_leaf=2, min_samples_split=2; total time=   9.9s\n",
      "[CV] END criterion=entropy, max_depth=40, min_samples_leaf=2, min_samples_split=5; total time=  10.9s\n",
      "[CV] END criterion=entropy, max_depth=40, min_samples_leaf=2, min_samples_split=5; total time=  10.8s\n",
      "[CV] END criterion=entropy, max_depth=40, min_samples_leaf=2, min_samples_split=5; total time=  11.3s\n",
      "[CV] END criterion=entropy, max_depth=40, min_samples_leaf=2, min_samples_split=5; total time=  10.6s\n",
      "[CV] END criterion=entropy, max_depth=40, min_samples_leaf=2, min_samples_split=5; total time=   9.9s\n",
      "[CV] END criterion=entropy, max_depth=40, min_samples_leaf=2, min_samples_split=10; total time=  10.7s\n",
      "[CV] END criterion=entropy, max_depth=40, min_samples_leaf=2, min_samples_split=10; total time=  10.6s\n",
      "[CV] END criterion=entropy, max_depth=40, min_samples_leaf=2, min_samples_split=10; total time=  11.3s\n",
      "[CV] END criterion=entropy, max_depth=40, min_samples_leaf=2, min_samples_split=10; total time=  10.4s\n",
      "[CV] END criterion=entropy, max_depth=40, min_samples_leaf=2, min_samples_split=10; total time=   9.8s\n",
      "[CV] END criterion=entropy, max_depth=40, min_samples_leaf=4, min_samples_split=2; total time=  10.5s\n",
      "[CV] END criterion=entropy, max_depth=40, min_samples_leaf=4, min_samples_split=2; total time=  10.4s\n",
      "[CV] END criterion=entropy, max_depth=40, min_samples_leaf=4, min_samples_split=2; total time=  10.9s\n",
      "[CV] END criterion=entropy, max_depth=40, min_samples_leaf=4, min_samples_split=2; total time=  10.2s\n",
      "[CV] END criterion=entropy, max_depth=40, min_samples_leaf=4, min_samples_split=2; total time=   9.6s\n",
      "[CV] END criterion=entropy, max_depth=40, min_samples_leaf=4, min_samples_split=5; total time=  10.5s\n",
      "[CV] END criterion=entropy, max_depth=40, min_samples_leaf=4, min_samples_split=5; total time=  10.5s\n",
      "[CV] END criterion=entropy, max_depth=40, min_samples_leaf=4, min_samples_split=5; total time=  11.0s\n",
      "[CV] END criterion=entropy, max_depth=40, min_samples_leaf=4, min_samples_split=5; total time=  10.2s\n",
      "[CV] END criterion=entropy, max_depth=40, min_samples_leaf=4, min_samples_split=5; total time=   9.6s\n",
      "[CV] END criterion=entropy, max_depth=40, min_samples_leaf=4, min_samples_split=10; total time=  10.5s\n",
      "[CV] END criterion=entropy, max_depth=40, min_samples_leaf=4, min_samples_split=10; total time=  10.4s\n",
      "[CV] END criterion=entropy, max_depth=40, min_samples_leaf=4, min_samples_split=10; total time=  11.0s\n",
      "[CV] END criterion=entropy, max_depth=40, min_samples_leaf=4, min_samples_split=10; total time=  10.2s\n",
      "[CV] END criterion=entropy, max_depth=40, min_samples_leaf=4, min_samples_split=10; total time=   9.5s\n",
      "Best Parameters:  {'criterion': 'gini', 'max_depth': 10, 'min_samples_leaf': 4, 'min_samples_split': 2}\n",
      "Best Score:  0.44135514018691585\n",
      "Accuracy on Test Set:  0.25558823529411767\n",
      "Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.30      0.37      1615\n",
      "           1       0.09      0.04      0.05       352\n",
      "           2       0.00      0.00      0.00        60\n",
      "           3       0.00      0.00      0.00       263\n",
      "           4       0.13      0.02      0.03       495\n",
      "           5       0.00      0.00      0.00        99\n",
      "           6       0.16      0.69      0.26       516\n",
      "\n",
      "    accuracy                           0.26      3400\n",
      "   macro avg       0.13      0.15      0.10      3400\n",
      "weighted avg       0.29      0.26      0.23      3400\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "ename": "NotFittedError",
     "evalue": "This DecisionTreeClassifier instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 35\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClassification Report: \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28mprint\u001b[39m(classification_report(y_test, y_pred))\n\u001b[1;32m---> 35\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m decision_tree\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# Evaluating the model\u001b[39;00m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccuracy:\u001b[39m\u001b[38;5;124m\"\u001b[39m, accuracy_score(y_test, y_pred))\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:499\u001b[0m, in \u001b[0;36mBaseDecisionTree.predict\u001b[1;34m(self, X, check_input)\u001b[0m\n\u001b[0;32m    476\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m    477\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Predict class or regression value for X.\u001b[39;00m\n\u001b[0;32m    478\u001b[0m \n\u001b[0;32m    479\u001b[0m \u001b[38;5;124;03m    For a classification model, the predicted class for each sample in X is\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[38;5;124;03m        The predicted classes, or the predict values.\u001b[39;00m\n\u001b[0;32m    498\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 499\u001b[0m     check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    500\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_X_predict(X, check_input)\n\u001b[0;32m    501\u001b[0m     proba \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtree_\u001b[38;5;241m.\u001b[39mpredict(X)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1462\u001b[0m, in \u001b[0;36mcheck_is_fitted\u001b[1;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[0;32m   1459\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m is not an estimator instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (estimator))\n\u001b[0;32m   1461\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_fitted(estimator, attributes, all_or_any):\n\u001b[1;32m-> 1462\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NotFittedError(msg \u001b[38;5;241m%\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mtype\u001b[39m(estimator)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m})\n",
      "\u001b[1;31mNotFittedError\u001b[0m: This DecisionTreeClassifier instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator."
     ]
    }
   ],
   "source": [
    "# Initialize the Decision Tree classifier\n",
    "decision_tree = DecisionTreeClassifier(max_depth=None, criterion='gini', random_state=42)\n",
    "\n",
    "# Fitting the Decision Tree to the Training set\n",
    "decision_tree.fit(X_train, y_train)\n",
    "\n",
    "# Predicting the Test set results# Define the parameter grid for Decision Tree\n",
    "param_grid = {\n",
    "    'max_depth': [None, 10, 20, 30, 40],  # Maximum depth of the tree\n",
    "    'min_samples_split': [2, 5, 10],  # Minimum number of samples required to split an internal node\n",
    "    'min_samples_leaf': [1, 2, 4],  # Minimum number of samples required to be at a leaf node\n",
    "    'criterion': ['gini', 'entropy']  # Function to measure the quality of a split\n",
    "}\n",
    "\n",
    "# Initialize the Decision Tree classifier\n",
    "decision_tree = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Initialize GridSearchCV object with Decision Tree classifier and the parameter grid\n",
    "grid_search = GridSearchCV(estimator=decision_tree, param_grid=param_grid, cv=5, scoring='accuracy', verbose=2)\n",
    "\n",
    "# Fit the model with the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters and the best score\n",
    "print(\"Best Parameters: \", grid_search.best_params_)\n",
    "print(\"Best Score: \", grid_search.best_score_)\n",
    "\n",
    "# Predict on the test set with the best parameters\n",
    "y_pred = grid_search.predict(X_test)\n",
    "\n",
    "# Evaluate the classifier with the best parameters\n",
    "print(\"Accuracy on Test Set: \", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report: \")\n",
    "print(classification_report(y_test, y_pred))\n",
    "y_pred = decision_tree.predict(X_test)\n",
    "\n",
    "# Evaluating the model\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524eb3b1",
   "metadata": {},
   "source": [
    "### Fully Connected Layers - Jon Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e33e2d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmotionClassifier(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(EmotionClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc3 = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)  # Output without activation; softmax will be applied externally if needed\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5a4377e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "# Wraps tensors into a dataset. Used to combine the input features and labels into a single dataset object for both training and testing data.\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "# Provides an iterable over the given dataset, supporting automatic batching, sampling, shuffling, and multiprocess data loading.\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a7fa9566",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EmotionClassifier(input_size=X_train.shape[1], hidden_size=256, num_classes=len(set(y_train)))\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "059628c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/250], Loss: 1.6391, Accuracy: 47.5%\n",
      "Epoch [10/250], Loss: 1.7074, Accuracy: 47.5%\n",
      "Epoch [20/250], Loss: 1.2881, Accuracy: 44.5%\n",
      "Epoch [30/250], Loss: 1.7067, Accuracy: 44.26470588235294%\n",
      "Epoch [40/250], Loss: 1.4469, Accuracy: 44.55882352941177%\n",
      "Epoch [50/250], Loss: 1.6461, Accuracy: 44.470588235294116%\n",
      "Epoch [60/250], Loss: 1.2734, Accuracy: 44.35294117647059%\n",
      "Epoch [70/250], Loss: 1.7703, Accuracy: 44.3235294117647%\n",
      "Epoch [80/250], Loss: 1.4375, Accuracy: 44.05882352941177%\n",
      "Epoch [90/250], Loss: 1.3367, Accuracy: 44.205882352941174%\n",
      "Epoch [100/250], Loss: 1.5072, Accuracy: 44.35294117647059%\n",
      "Epoch [110/250], Loss: 1.5495, Accuracy: 44.3235294117647%\n",
      "Epoch [120/250], Loss: 1.2539, Accuracy: 44.44117647058823%\n",
      "Epoch [130/250], Loss: 1.3615, Accuracy: 43.38235294117647%\n",
      "Epoch [140/250], Loss: 1.4137, Accuracy: 43.529411764705884%\n",
      "Epoch [150/250], Loss: 1.3289, Accuracy: 42.588235294117645%\n",
      "Epoch [160/250], Loss: 1.3698, Accuracy: 44.411764705882355%\n",
      "Epoch [170/250], Loss: 1.1888, Accuracy: 41.6764705882353%\n",
      "Epoch [180/250], Loss: 1.1442, Accuracy: 40.85294117647059%\n",
      "Epoch [190/250], Loss: 1.2486, Accuracy: 40.26470588235294%\n",
      "Epoch [200/250], Loss: 1.3925, Accuracy: 41.529411764705884%\n",
      "Epoch [210/250], Loss: 1.1019, Accuracy: 40.85294117647059%\n",
      "Epoch [220/250], Loss: 1.4703, Accuracy: 43.0%\n",
      "Epoch [230/250], Loss: 1.3494, Accuracy: 42.0%\n",
      "Epoch [240/250], Loss: 1.1669, Accuracy: 43.26470588235294%\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 250\n",
    "accuracy_list = []\n",
    "loss_list = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for inputs, labels in train_loader:\n",
    "        optimizer.zero_grad()  # Reset gradients\n",
    "        outputs = model(inputs)  # Forward pass\n",
    "        loss = criterion(outputs, labels)  # Compute loss\n",
    "        loss.backward()  # Backward pass\n",
    "        optimizer.step()  # Update weights\n",
    "\n",
    "    # After updating weights in each epoch, add code to evaluate on the test set or a validation set\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        # Initialize variables to track accuracy, for example\n",
    "        correct, total = 0, 0\n",
    "        for inputs, labels in test_loader:\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    accuracy = 100 * correct / total\n",
    "\n",
    "    accuracy_list.append(accuracy)\n",
    "    loss_list.append(loss.item())\n",
    "    \n",
    "    model.train()  # Set the model back to training mode\n",
    "    if epoch % 10 == 0:\n",
    "        print(f'Epoch [{epoch}/{num_epochs}], Loss: {loss.item():.4f}, Accuracy: {accuracy}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "445fd933",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Assuming 'accuracy_list' contains the accuracy values for each epoch\n",
    "x = np.arange(len(accuracy_list))  # Using np.arange instead of range for array operations\n",
    "y = np.array(accuracy_list)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(x, y, marker='o', linestyle='', color='b', label='Accuracy per Epoch')\n",
    "\n",
    "# Compute the coefficients for the line of best fit\n",
    "coefficients = np.polyfit(x, y, 1)\n",
    "# Generate the values for the line of best fit\n",
    "polynomial = np.poly1d(coefficients)\n",
    "y_fit = polynomial(x)\n",
    "\n",
    "# Plot the line of best fit\n",
    "plt.plot(x, y_fit, 'r-', label='Line of Best Fit')\n",
    "\n",
    "plt.title('Accuracy per Epoch')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6bbbf577",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = range(len(loss_list))\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(x, loss_list, marker='o', linestyle='', color='g')\n",
    "\n",
    "# Compute the coefficients for the line of best fit\n",
    "coefficients = np.polyfit(x, loss_list, 1)\n",
    "# Generate the values for the line of best fit\n",
    "polynomial = np.poly1d(coefficients)\n",
    "y_fit = polynomial(x)\n",
    "\n",
    "# Plot the line of best fit\n",
    "plt.plot(x, y_fit, 'r-', label='Line of Best Fit')\n",
    "\n",
    "plt.title('Loss per Epoch')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb49ec03",
   "metadata": {},
   "source": [
    "### Fully Connected Layers - Elijah Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e38f697",
   "metadata": {},
   "source": [
    "FC layers referenced from https://towardsdatascience.com/math-neural-network-from-scratch-in-python-d6da9f29ce65"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9f69cca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base class\n",
    "class Layer:\n",
    "    def __init__(self):\n",
    "        self.input = None\n",
    "        self.output = None\n",
    "\n",
    "    # computes the output Y of a layer for a given input X\n",
    "    def forward_propagation(self, input):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    # computes dE/dX for a given dE/dY (and update parameters if any)\n",
    "    def backward_propagation(self, output_error, learning_rate):\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ed9d44ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# inherit from base class Layer\n",
    "class FCLayer(Layer):\n",
    "    # input_size = number of input neurons\n",
    "    # output_size = number of output neurons\n",
    "    def __init__(self, input_size, output_size):\n",
    "        self.weights = np.random.rand(input_size, output_size) - 0.5\n",
    "        self.bias = np.random.rand(1, output_size) - 0.5\n",
    "\n",
    "    # returns output for a given input\n",
    "    def forward_propagation(self, input_data):\n",
    "        self.input = input_data\n",
    "        self.output = np.dot(self.input, self.weights) + self.bias\n",
    "        return self.output\n",
    "\n",
    "    # computes dE/dW, dE/dB for a given output_error=dE/dY. Returns input_error=dE/dX.\n",
    "    def backward_propagation(self, output_error, learning_rate):\n",
    "        input_error = np.dot(output_error, self.weights.T)\n",
    "        weights_error = np.dot(self.input.T, output_error)\n",
    "        # dBias = output_error\n",
    "\n",
    "        # update parameters\n",
    "        self.weights -= learning_rate * weights_error\n",
    "        self.bias -= learning_rate * output_error\n",
    "        return input_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "65754259",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inherit from base class Layer\n",
    "class ActivationLayer(Layer):\n",
    "    def __init__(self, activation, activation_prime):\n",
    "        self.activation = activation\n",
    "        self.activation_prime = activation_prime\n",
    "\n",
    "    # returns the activated input\n",
    "    def forward_propagation(self, input_data):\n",
    "        self.input = input_data\n",
    "        self.output = self.activation(self.input)\n",
    "        return self.output\n",
    "\n",
    "    # Returns input_error=dE/dX for a given output_error=dE/dY.\n",
    "    # learning_rate is not used because there is no \"learnable\" parameters.\n",
    "    def backward_propagation(self, output_error, learning_rate):\n",
    "        return self.activation_prime(self.input) * output_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "09c17113",
   "metadata": {},
   "outputs": [],
   "source": [
    "# activation function and its derivative\n",
    "def tanh(x):\n",
    "    return np.tanh(x)\n",
    "\n",
    "def tanh_prime(x):\n",
    "    return 1-np.tanh(x)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c0edfa0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function and its derivative\n",
    "def mse(y_true, y_pred):\n",
    "    return np.mean(np.power(y_true-y_pred, 2))\n",
    "\n",
    "def mse_prime(y_true, y_pred):\n",
    "    return 2*(y_pred-y_true)/y_true.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "44d431ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network:\n",
    "    def __init__(self):\n",
    "        self.layers = []\n",
    "        self.loss = None\n",
    "        self.loss_prime = None\n",
    "\n",
    "    # add layer to network\n",
    "    def add(self, layer):\n",
    "        self.layers.append(layer)\n",
    "\n",
    "    # set loss to use\n",
    "    def use(self, loss, loss_prime):\n",
    "        self.loss = loss\n",
    "        self.loss_prime = loss_prime\n",
    "\n",
    "    # predict output for given input\n",
    "    def predict(self, input_data):\n",
    "        # sample dimension first\n",
    "        samples = len(input_data)\n",
    "        result = []\n",
    "\n",
    "        # run network over all samples\n",
    "        for i in range(samples):\n",
    "            # forward propagation\n",
    "            output = input_data[i]\n",
    "            for layer in self.layers:\n",
    "                output = layer.forward_propagation(output)\n",
    "            result.append(output)\n",
    "\n",
    "        return result\n",
    "\n",
    "    # train the network\n",
    "    def fit(self, x_train, y_train, epochs, learning_rate):\n",
    "        # sample dimension first\n",
    "        samples = len(x_train)\n",
    "\n",
    "        # training loop\n",
    "        for i in range(epochs):\n",
    "            err = 0\n",
    "            for j in range(samples):\n",
    "                # forward propagation\n",
    "                output = x_train[j]\n",
    "                for layer in self.layers:\n",
    "                    output = layer.forward_propagation(output)\n",
    "\n",
    "                # compute loss (for display purpose only)\n",
    "                err += self.loss(y_train[j], output)\n",
    "\n",
    "                # backward propagation\n",
    "                error = self.loss_prime(y_train[j], output)\n",
    "                for layer in reversed(self.layers):\n",
    "                    error = layer.backward_propagation(error, learning_rate)\n",
    "\n",
    "            # calculate average error on all samples\n",
    "            err /= samples\n",
    "            print('epoch %d/%d   error=%f' % (i+1, epochs, err))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0bb7521c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (1,0) and (1,0) not aligned: 0 (dim 1) != 1 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# train\u001b[39;00m\n\u001b[0;32m      9\u001b[0m net\u001b[38;5;241m.\u001b[39muse(mse, mse_prime)\n\u001b[1;32m---> 10\u001b[0m net\u001b[38;5;241m.\u001b[39mfit(X_train, y_train, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m, learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# test\u001b[39;00m\n\u001b[0;32m     13\u001b[0m out \u001b[38;5;241m=\u001b[39m net\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "Cell \u001b[1;32mIn[27], line 44\u001b[0m, in \u001b[0;36mNetwork.fit\u001b[1;34m(self, x_train, y_train, epochs, learning_rate)\u001b[0m\n\u001b[0;32m     42\u001b[0m output \u001b[38;5;241m=\u001b[39m x_train[j]\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[1;32m---> 44\u001b[0m     output \u001b[38;5;241m=\u001b[39m layer\u001b[38;5;241m.\u001b[39mforward_propagation(output)\n\u001b[0;32m     46\u001b[0m \u001b[38;5;66;03m# compute loss (for display purpose only)\u001b[39;00m\n\u001b[0;32m     47\u001b[0m err \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss(y_train[j], output)\n",
      "Cell \u001b[1;32mIn[23], line 14\u001b[0m, in \u001b[0;36mFCLayer.forward_propagation\u001b[1;34m(self, input_data)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward_propagation\u001b[39m(\u001b[38;5;28mself\u001b[39m, input_data):\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput \u001b[38;5;241m=\u001b[39m input_data\n\u001b[1;32m---> 14\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput\n",
      "File \u001b[1;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mdot\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: shapes (1,0) and (1,0) not aligned: 0 (dim 1) != 1 (dim 0)"
     ]
    }
   ],
   "source": [
    "# network\n",
    "net = Network()\n",
    "net.add(FCLayer(300, 0))\n",
    "net.add(ActivationLayer(tanh, tanh_prime))\n",
    "net.add(FCLayer(1,0))\n",
    "net.add(ActivationLayer(tanh, tanh_prime))\n",
    "\n",
    "# train\n",
    "net.use(mse, mse_prime)\n",
    "net.fit(X_train, y_train, epochs=1000, learning_rate=0.1)\n",
    "\n",
    "# test\n",
    "out = net.predict(X_test)\n",
    "print(out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
